{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1tOS7oWba4s"
   },
   "source": [
    "# Large language models (LLMs): Part II\n",
    "\n",
    "Author: Archit Vasan , including materials on LLMs by Varuni Sastri, and discussion/editorial work by Taylor Childers, Carlo Graziani, Bethany Lusch, and Venkat Vishwanath (Argonne)\n",
    "\n",
    "Some inspiration from the blog post \"The Illustrated Transformer\" by Jay Alammar, highly recommended reading.\n",
    "\n",
    "Before you begin, make sure that you have your environment set up and your repo refreshed, as described in previous lessons, and reviewed in the accompanying 'Readme.md' file. Make sure that you select the kernel 'datascience/conda-2023-01-10' at the top-left of the Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "1. Training and inference using Hugging Face\n",
    "2. Elements of an LLM\n",
    "3. Attention mechanisms\n",
    "4. Positional encoding\n",
    "5. Output layers\n",
    "6. Training loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM training and inference using HuggingFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/hf-logo-with-title.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "HuggingFace is a platform and community that provides open-source library tools and resources like pre-trained models and datasets.\n",
    "Refer to the following links for more information :\n",
    "\n",
    "https://huggingface.co/docs/hub/index\n",
    "\n",
    "https://huggingface.co/docs/transformers/en/index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warning: _Large Language Models are only as good as their training data. They have no ethics, no judgement, or editing ability. We will be using some pretrained models from Hugging Face which used wide samples of internet hosted text. The datasets have not been strictly filtered to restrict all malign content so the generated text may be surprisingly dark or questionable. They do not reflect our core values and are only used for demonstration purposes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HTTP_PROXY\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
    "os.environ[\"HTTPS_PROXY\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
    "os.environ[\"http_proxy\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
    "os.environ[\"https_proxy\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
    "os.environ[\"ftp_proxy\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "We can use the Huggingface pipeline with a pretrained GPT2 model to generate text given a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 18:20:01.524291: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages/h5py/__init__.py:36: UserWarning: h5py is running against HDF5 1.12.2 when it was built against 1.12.1, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n",
      "/soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages/transformers/generation/utils.py:1186: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'My cats really wanted to eat me, and I was not interested.\" She said. \"And I'},\n",
       " {'generated_text': 'My cats really wanted to have my cat do this,\" he said.\\n\\nWhile he\\'d have'},\n",
       " {'generated_text': 'My cats really wanted to play with me,\" explained Catz. \"It was a great opportunity for'},\n",
       " {'generated_text': \"My cats really wanted to kill themselves, but that's what is going down in their minds and in\"},\n",
       " {'generated_text': 'My cats really wanted to be with me. They needed someone who could care for them, even if'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForCausalLM, AutoConfig\n",
    "input_text = \"My cats really wanted to\"\n",
    "from transformers import pipeline\n",
    "generator = pipeline(\"text-generation\", model=\"openai-community/gpt2\")\n",
    "generator(input_text, max_length=20, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also load in our own dataset and train a model with this data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: accelerate in /home/j3gu/.local/lib/python3.10/site-packages (0.28.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from accelerate) (5.9.4)\n",
      "Requirement already satisfied: pyyaml in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from accelerate) (1.13.0a0+git49444c3)\n",
      "Requirement already satisfied: huggingface-hub in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from accelerate) (0.12.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/j3gu/.local/lib/python3.10/site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.4.0)\n",
      "Requirement already satisfied: filelock in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from huggingface-hub->accelerate) (3.9.0)\n",
      "Requirement already satisfied: requests in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.64.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2022.12.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextDataset,DataCollatorForLanguageModeling\n",
    "\n",
    "def load_dataset(train_path,test_path,tokenizer):\n",
    "    train_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=train_path,\n",
    "          block_size=128) \n",
    "    test_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=test_path,\n",
    "          block_size=128)   \n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=False,\n",
    "    )\n",
    "    return train_dataset,test_dataset,data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages/transformers/data/datasets/language_modeling.py:54: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n",
    "\n",
    "train_dataset,test_dataset,data_collator = load_dataset('dataset/train_input.txt','dataset/test_input.txt', tokenizer)\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2\", #The output directory\n",
    "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
    "    num_train_epochs=3, # number of training epochs\n",
    "    per_device_train_batch_size=32, # batch size for training\n",
    "    per_device_eval_batch_size=64,  # batch size for evaluation\n",
    "    eval_steps = 40, # Number of update steps between two evaluations.\n",
    "    save_steps=80, # after # steps model is saved \n",
    "    warmup_steps=50,# number of warmup steps for learning rate scheduler\n",
    "    prediction_loss_only=True,\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is going on below the hood?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two components that are \"black-boxes\" here:\n",
    "1. The method for tokenization\n",
    "2. The model that generates novel text.\n",
    "\n",
    "Carlo Graziani already gave a great explanation of tokenization last week and how this affects embeddings (https://github.com/argonne-lcf/ai-science-training-series/blob/main/04_intro_to_llms/Sequential_Data_Models.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we will take a closer look at how the model is designed to deal with language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look inside GPT2! GPT2 incorporates the `GPT2LMHeadModel` architecture so let's inspect this more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/j3gu/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json\n",
      "Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/j3gu/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/model.safetensors\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at openai-community/gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at /home/j3gu/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "model = GPT2LMHeadModel.from_pretrained('openai-community/gpt2')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General elements of an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-2 is an example of the popular Transformer architecture. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cig2mvfguetQ"
   },
   "source": [
    "<img src=\"images/decoder_only_block.png\" alt=\"Drawing\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gray section in this figure is the Transfomer Decoder and it is the main mechanism GPT2 uses to encode context of language into its predictions.\n",
    "\n",
    "<img src=\"images/transformer-decoder-intro.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Transformer-Decoder is composed of Decoder blocks stacked ontop of each other where each contains two types of layers: \n",
    "1. Masked Self-Attention and \n",
    "2. Feed Forward Neural Networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have already discussed Feed Forward Neural Networks in detail in the other lectures in this series. To review this, please look at https://github.com/argonne-lcf/ai-science-training-series/blob/main/02_intro_neural_networks/01_introduction_mnist.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture, we will \n",
    "* First, discuss attention mechanisms at length as this is arguably the greatest contribution by Transformers.\n",
    "* Second, extend the discussion from last week (https://github.com/argonne-lcf/ai-science-training-series/blob/main/04_intro_to_llms/Sequential_Data_Models.ipynb) on embedding input data while taking into account position.\n",
    "* Third, discuss outputting real text/sequences from the models.\n",
    "* Fourth, build a training loop for a mini-LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's set up all the imports we will need**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x14d86f8dcb90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## IMPORTS\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 32 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 64\n",
    "n_head = 4 ## so head_size = 16 why is the total head_size 16?\n",
    "n_layer = 4\n",
    "dropout = 0.0\n",
    "# ------------\n",
    "\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BowLYFlCrDrr"
   },
   "source": [
    "## Attention mechanisms\n",
    "\n",
    "Suppose the following sentence is an input sentence we want to translate using an LLM:\n",
    "\n",
    "`‚ÄùThe animal didn't cross the street because it was too tired‚Äù`\n",
    "\n",
    "Last week, Carlo mentioned that the Transformer learns an embedding of all words allowing interpretation of meanings of words.\n",
    "\n",
    "<img src=\"images/viz-bert-voc-verbs.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "So, if the model did a good job in token embedding, it will \"know\" what all the words in this sentence mean. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But to understand a full sentence, the model also need to understand what each word means in relation to other words.\n",
    "\n",
    "For example, when we read the sentence:\n",
    "`‚ÄùThe animal didn't cross the street because it was too tired‚Äù`\n",
    "we know intuitively that the word `\"it\"` refers to `\"animal\"`, the state for `\"it\"` is `\"tired\"`, and the associated action is `\"didn't cross\"`.\n",
    "\n",
    "However, the model needs a way to learn all of this information in a simple yet generalizable way.\n",
    "What makes Transformers particularly powerful compared to earlier sequential architectures is how it encodes context with the **self-attention mechanism**.\n",
    "\n",
    "As the model processes each word in the input sequence, attention looks at other positions in the input sequence for clues to a better understanding for this word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/transformer_self-attention_visualization.png\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self-attention mechanisms use 3 vectors to encode the context of a word in a sequence with another word:\n",
    "1. Query: the word representation we score other words against using the other word's keys\n",
    "2. Key: labels for the words in a sequence that we match against the query\n",
    "3. Value: actual word representation. We will use the queries and keys to score the word's relevance to the query, and multiply this by the value. \n",
    "\n",
    "An analogy provided by Jay Alammar is thinking about attention as choosing a file from a file cabinet according to information on a post-it note. You can use the post-it note (query) to identify the folder (key) that most matches the topic you are looking up. Then you access the contents of the file (value) according to its relevance to your query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGbAi0cJ7x3a"
   },
   "source": [
    "Image credit: https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/self-attention-example-folders-3.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our models, we can encode queries, keys, and values using simple linear layers with the same size (`sequence length, head_size`). During the training process, these layers will be updated to best encode context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 32 # channels\n",
    "head_size = 16\n",
    "\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 32, 0.001, 64, 4, 4, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print([batch_size, block_size, learning_rate, n_embd, n_head, n_layer, dropout])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jzf9VE_AqWeR"
   },
   "source": [
    "The algorithm for self-attention is as follows:\n",
    "\n",
    "1. Generate query, key and value vectors for each word\n",
    "2. Calculate a score for each word in the input sentence against each other.\n",
    "3. Divide the scores by the square root of the dimension of the key vectors to stabilize the gradients. This is then passed through a softmax operation.\n",
    "4. Multiply each value vector by the softmax score.\n",
    "5. Sum up the weighted value vectors to produce the output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/self-attention-output.png\" alt=\"Drawing\" style=\"width: 450px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOwm-NkXA8U3"
   },
   "source": [
    "Image credit: https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how attention is performed in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32 # batch, time, channels\n",
    "x = torch.randn(B,T,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# Here we want the wei to be data dependent - ie gather info from the past but in a data dependant way\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)   # (B, T, 16) # each token here (totally B*T) produce a key and query in parallel and independently\n",
    "q = query(x) # (B, T, 16)\n",
    "v = value(x)\n",
    "\n",
    "wei =  q @ k.transpose(-2, -1) * head_size**-0.5 # (B, T, 16) @ (B, 16, T) ---> (B, T, T). #\n",
    "wei = F.softmax(wei, dim=-1) # exponentiate and normalize giving a nice distibution that sums to 1 and\n",
    "                             # now it tells us that in a data dependent manner how much of info to aggregate from\n",
    "\n",
    "out = wei @ v # aggregate the attention scores and value vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0618, -0.0091, -0.3488,  0.3208,  0.2971, -0.1573, -0.0561,  0.1068,\n",
      "          0.0368,  0.0139, -0.0017,  0.3110,  0.1404, -0.0158,  0.1853,  0.4290],\n",
      "        [ 0.1578, -0.0971, -0.4256,  0.3538,  0.3621, -0.2392, -0.0536,  0.1759,\n",
      "          0.1115,  0.0282, -0.0649,  0.3641,  0.1928,  0.0261,  0.2162,  0.3758],\n",
      "        [ 0.1293,  0.0759, -0.2946,  0.2292,  0.2215, -0.0710, -0.0107,  0.1616,\n",
      "         -0.0930, -0.0877,  0.0567,  0.1899,  0.0311, -0.0894,  0.0309,  0.5471],\n",
      "        [ 0.1247,  0.1400, -0.2436,  0.1819,  0.1976,  0.0338, -0.0028,  0.1124,\n",
      "         -0.1477, -0.0748,  0.0650,  0.1392, -0.0314, -0.0989,  0.0613,  0.5433],\n",
      "        [ 0.0667,  0.1845, -0.2135,  0.2813,  0.2064,  0.0873,  0.0084,  0.2055,\n",
      "         -0.1130, -0.1466,  0.0459,  0.1923, -0.0275, -0.1107,  0.0065,  0.4674],\n",
      "        [ 0.1924,  0.1693, -0.1568,  0.2284,  0.1620,  0.0737,  0.0443,  0.2519,\n",
      "         -0.1912, -0.1979,  0.0832,  0.0713, -0.0826, -0.0848, -0.1047,  0.6089],\n",
      "        [ 0.1184,  0.0884, -0.2652,  0.2560,  0.1840,  0.0284, -0.0621,  0.1181,\n",
      "         -0.0880,  0.0104,  0.1123,  0.1850,  0.0369, -0.0730,  0.0663,  0.5242],\n",
      "        [ 0.1243,  0.0453, -0.3412,  0.2709,  0.2335, -0.0948, -0.0421,  0.2143,\n",
      "         -0.0330, -0.0313,  0.0520,  0.2378,  0.1084, -0.0959,  0.0300,  0.4707]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(out[0])\n",
    "out[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4lwyFlxKW6oA"
   },
   "source": [
    "### Multi-head attention\n",
    "\n",
    "In practice, multiple attention heads are used which\n",
    "1. Expands the model‚Äôs ability to focus on different positions and prevent the attention to be dominated by the word itself.\n",
    "2. Have multiple ‚Äúrepresentation subspaces‚Äù. Have multiple sets of Query/Key/Value weight matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/transformer_multi-headed_self-attention-recap.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oHsezdVBIaf"
   },
   "source": [
    "Image credit: https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see attention mechanisms in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the powerful visualization tool bertviz, which allows an interactive experience of the attention mechanisms. Normally these mechanisms are abstracted away but this will allow us to inspect our model in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bertviz in /home/j3gu/.local/lib/python3.10/site-packages (1.4.0)\n",
      "Requirement already satisfied: transformers>=2.0 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from bertviz) (4.26.0)\n",
      "Requirement already satisfied: torch>=1.0 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from bertviz) (1.13.0a0+git49444c3)\n",
      "Requirement already satisfied: tqdm in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from bertviz) (4.64.1)\n",
      "Requirement already satisfied: boto3 in /home/j3gu/.local/lib/python3.10/site-packages (from bertviz) (1.34.56)\n",
      "Requirement already satisfied: requests in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from bertviz) (2.28.1)\n",
      "Requirement already satisfied: regex in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from bertviz) (2022.10.31)\n",
      "Requirement already satisfied: sentencepiece in /home/j3gu/.local/lib/python3.10/site-packages (from bertviz) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from torch>=1.0->bertviz) (4.4.0)\n",
      "Requirement already satisfied: filelock in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from transformers>=2.0->bertviz) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from transformers>=2.0->bertviz) (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from transformers>=2.0->bertviz) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from transformers>=2.0->bertviz) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from transformers>=2.0->bertviz) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from transformers>=2.0->bertviz) (0.13.2)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.56 in /home/j3gu/.local/lib/python3.10/site-packages (from boto3->bertviz) (1.34.56)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/j3gu/.local/lib/python3.10/site-packages (from boto3->bertviz) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/j3gu/.local/lib/python3.10/site-packages (from boto3->bertviz) (0.10.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from requests->bertviz) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from requests->bertviz) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from requests->bertviz) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from requests->bertviz) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.56->boto3->bertviz) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from packaging>=20.0->transformers>=2.0->bertviz) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.56->boto3->bertviz) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install bertviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load in the model, GPT2 and look at the attention mechanisms. \n",
    "\n",
    "**Hint... click on the different blocks in the visualization to see the attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "      \n",
       "        <div id=\"bertviz-fbc5c2e7d0654600999365aa5a3d8d2c\" style=\"font-family:'Helvetica Neue', Helvetica, Arial, sans-serif;\">\n",
       "            <span style=\"user-select:none\">\n",
       "                \n",
       "            </span>\n",
       "            <div id='vis'></div>\n",
       "        </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "/**\n",
       " * @fileoverview Transformer Visualization D3 javascript code.\n",
       " *\n",
       " * Based on: https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/visualization/attention.js\n",
       " *\n",
       " * Change log:\n",
       " *\n",
       " * 02/01/19  Jesse Vig   Initial implementation\n",
       " * 12/31/20  Jesse Vig   Support multiple visualizations in single notebook.\n",
       " * 01/19/21  Jesse Vig   Support light/dark modes\n",
       " * 02/06/21  Jesse Vig   Move require config from separate jupyter notebook step\n",
       " * 05/03/21  Jesse Vig   Adjust visualization height dynamically\n",
       " * 03/23/22  Daniel SC   Update requirement URLs for d3 and jQuery (source of bug not allowing end result to be displayed on browsers)\n",
       " **/\n",
       "\n",
       "require.config({\n",
       "  paths: {\n",
       "      d3: 'https://cdnjs.cloudflare.com/ajax/libs/d3/5.7.0/d3.min',\n",
       "    jquery: 'https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
       "  }\n",
       "});\n",
       "\n",
       "requirejs(['jquery', 'd3'], function($, d3) {\n",
       "\n",
       "        const params = {\"attention\": [{\"name\": null, \"attn\": [[[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.961219847202301, 0.038780149072408676, 0.0, 0.0, 0.0, 0.0], [0.7466979026794434, 0.11987314373254776, 0.1334289014339447, 0.0, 0.0, 0.0], [0.5885030031204224, 0.13792067766189575, 0.212137371301651, 0.06143897399306297, 0.0, 0.0], [0.6570857763290405, 0.08996301889419556, 0.12751281261444092, 0.08361563086509705, 0.041822850704193115, 0.0], [0.2728874385356903, 0.11203353852033615, 0.1663985401391983, 0.08467111736536026, 0.16952736675739288, 0.19448210299015045]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010616563260555267, 0.9893833994865417, 0.0, 0.0, 0.0, 0.0], [0.0024677535984665155, 0.008448007516562939, 0.9890841841697693, 0.0, 0.0, 0.0], [0.0001232847134815529, 0.0018733182223513722, 0.013126976788043976, 0.9848763942718506, 0.0, 0.0], [0.0010669564362615347, 0.001136627048254013, 0.003034998197108507, 0.0015735096530988812, 0.9931879043579102, 0.0], [0.00019791982776951045, 0.0010528112761676311, 0.0015437351539731026, 0.0009642760851420462, 3.4924432839034125e-05, 0.9962062835693359]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.47578439116477966, 0.524215579032898, 0.0, 0.0, 0.0, 0.0], [0.5906045436859131, 0.2486611008644104, 0.16073434054851532, 0.0, 0.0, 0.0], [0.5529289841651917, 0.18856702744960785, 0.14457571506500244, 0.11392831057310104, 0.0, 0.0], [0.45094072818756104, 0.16486799716949463, 0.17318038642406464, 0.11748014390468597, 0.09353074431419373, 0.0], [0.4257245659828186, 0.1732865273952484, 0.15651953220367432, 0.07022649794816971, 0.0808701142668724, 0.09337282180786133]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6133623123168945, 0.38663768768310547, 0.0, 0.0, 0.0, 0.0], [0.06098509579896927, 0.03253461793065071, 0.9064802527427673, 0.0, 0.0, 0.0], [0.006717085838317871, 0.0004012881254311651, 0.7572958469390869, 0.23558568954467773, 0.0, 0.0], [0.03722766041755676, 0.002948855282738805, 0.10081092268228531, 0.04142269119620323, 0.8175898790359497, 0.0], [0.04989781975746155, 0.00030758307548239827, 0.0024198265746235847, 0.0034334994852542877, 0.0006823898293077946, 0.9432588815689087]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9489555954933167, 0.051044441759586334, 0.0, 0.0, 0.0, 0.0], [0.6821408867835999, 0.1395241767168045, 0.17833495140075684, 0.0, 0.0, 0.0], [0.20366324484348297, 0.05641487240791321, 0.06399301439523697, 0.6759288311004639, 0.0, 0.0], [0.3419547975063324, 0.06725440919399261, 0.07926183938980103, 0.1783619523048401, 0.3331669867038727, 0.0], [0.09464015811681747, 0.0074282134883105755, 0.006983973551541567, 0.0071843694895505905, 0.018724264577031136, 0.865039050579071]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.33834606409072876, 0.6616539359092712, 0.0, 0.0, 0.0, 0.0], [0.07855993509292603, 0.006165449041873217, 0.9152746200561523, 0.0, 0.0, 0.0], [0.01677597686648369, 0.0004037705948576331, 0.003340460592880845, 0.9794798493385315, 0.0, 0.0], [0.027600426226854324, 0.00044415233423933387, 0.0006541680195368826, 0.0002266185765620321, 0.971074640750885, 0.0], [0.010248198173940182, 3.701553578139283e-05, 0.00016064041119534522, 2.7341819077264518e-05, 1.0187304724240676e-05, 0.98951655626297]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.982503354549408, 0.017496665939688683, 0.0, 0.0, 0.0, 0.0], [0.8874197006225586, 0.05467939004302025, 0.05790085718035698, 0.0, 0.0, 0.0], [0.6849910616874695, 0.1228068619966507, 0.04972026124596596, 0.14248186349868774, 0.0, 0.0], [0.6015856862068176, 0.09881888329982758, 0.07070108503103256, 0.16652540862560272, 0.06236903741955757, 0.0], [0.3232504427433014, 0.12567411363124847, 0.04432179778814316, 0.07076980918645859, 0.06606649607419968, 0.36991727352142334]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9191647171974182, 0.0808352455496788, 0.0, 0.0, 0.0, 0.0], [0.45986413955688477, 0.39703112840652466, 0.14310479164123535, 0.0, 0.0, 0.0], [0.3003872334957123, 0.22181738913059235, 0.38161516189575195, 0.09618020057678223, 0.0, 0.0], [0.18963925540447235, 0.1376371532678604, 0.20173484086990356, 0.23632164299488068, 0.23466713726520538, 0.0], [0.15410441160202026, 0.09489496797323227, 0.11902562528848648, 0.10277965664863586, 0.4317220449447632, 0.09747327119112015]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.364999920129776, 0.6350001096725464, 0.0, 0.0, 0.0, 0.0], [0.24595215916633606, 0.5519201755523682, 0.20212766528129578, 0.0, 0.0, 0.0], [0.2721358835697174, 0.40738627314567566, 0.25186213850975037, 0.06861574947834015, 0.0, 0.0], [0.10242555290460587, 0.16683615744113922, 0.524804949760437, 0.05445462837815285, 0.15147870779037476, 0.0], [0.25029507279396057, 0.22198128700256348, 0.18899968266487122, 0.10677118599414825, 0.1303267478942871, 0.10162602365016937]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6990506649017334, 0.3009493350982666, 0.0, 0.0, 0.0, 0.0], [0.5107942819595337, 0.2948642075061798, 0.1943415403366089, 0.0, 0.0, 0.0], [0.4604707360267639, 0.2805190980434418, 0.19174803793430328, 0.0672621801495552, 0.0, 0.0], [0.37648412585258484, 0.21120662987232208, 0.20214538276195526, 0.10207021236419678, 0.10809355974197388, 0.0], [0.30138441920280457, 0.20456179976463318, 0.18250338733196259, 0.11019382625818253, 0.1629127413034439, 0.03844383731484413]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7131582498550415, 0.2868417799472809, 0.0, 0.0, 0.0, 0.0], [0.4058799147605896, 0.18063297867774963, 0.41348710656166077, 0.0, 0.0, 0.0], [0.265546053647995, 0.1698586493730545, 0.3358593285083771, 0.228736013174057, 0.0, 0.0], [0.31385406851768494, 0.1831669807434082, 0.14928358793258667, 0.05377671495079994, 0.29991865158081055, 0.0], [0.20466560125350952, 0.18731118738651276, 0.15959151089191437, 0.06381776183843613, 0.03642302006483078, 0.34819093346595764]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6586242914199829, 0.3413757383823395, 0.0, 0.0, 0.0, 0.0], [0.5917776226997375, 0.3160035014152527, 0.0922188088297844, 0.0, 0.0, 0.0], [0.5477152466773987, 0.23586955666542053, 0.061456020921468735, 0.1549593061208725, 0.0, 0.0], [0.4587061107158661, 0.22439992427825928, 0.07887422293424606, 0.0992034301161766, 0.13881628215312958, 0.0], [0.32743722200393677, 0.19600819051265717, 0.068057119846344, 0.0892510637640953, 0.11618079245090485, 0.20306548476219177]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9961552023887634, 0.0038448425475507975, 0.0, 0.0, 0.0, 0.0], [0.8594854474067688, 0.06906110048294067, 0.07145342975854874, 0.0, 0.0, 0.0], [0.3800053000450134, 0.04127567633986473, 0.5496612787246704, 0.029057776555418968, 0.0, 0.0], [0.21445226669311523, 0.05088742449879646, 0.4317440092563629, 0.25869303941726685, 0.044223275035619736, 0.0], [0.11175256222486496, 0.017593080177903175, 0.027507441118359566, 0.04086771607398987, 0.7754669785499573, 0.026812179014086723]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9285967946052551, 0.07140326499938965, 0.0, 0.0, 0.0, 0.0], [0.6077286005020142, 0.3121427297592163, 0.08012867718935013, 0.0, 0.0, 0.0], [0.4942909777164459, 0.28503698110580444, 0.11849315464496613, 0.10217894613742828, 0.0, 0.0], [0.4183879494667053, 0.23117904365062714, 0.0834062322974205, 0.11365949362516403, 0.1533672958612442, 0.0], [0.42215850949287415, 0.12917140126228333, 0.08740927278995514, 0.1016375944018364, 0.21230268478393555, 0.04732053726911545]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9786475896835327, 0.02135237120091915, 0.0, 0.0, 0.0, 0.0], [0.7749121785163879, 0.06510371714830399, 0.15998409688472748, 0.0, 0.0, 0.0], [0.6484923362731934, 0.07483134418725967, 0.14751605689525604, 0.12916021049022675, 0.0, 0.0], [0.5224639773368835, 0.06921815127134323, 0.13823404908180237, 0.1110658198595047, 0.15901805460453033, 0.0], [0.3964517116546631, 0.07325823605060577, 0.12938153743743896, 0.1064242571592331, 0.14864002168178558, 0.1458442211151123]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5525906085968018, 0.44740936160087585, 0.0, 0.0, 0.0, 0.0], [0.5585009455680847, 0.2176259458065033, 0.22387312352657318, 0.0, 0.0, 0.0], [0.5143128633499146, 0.15964674949645996, 0.15491968393325806, 0.1711207628250122, 0.0, 0.0], [0.5039961338043213, 0.11401888728141785, 0.11974027007818222, 0.12552587687969208, 0.13671889901161194, 0.0], [0.5061842799186707, 0.08567393571138382, 0.08903021365404129, 0.09759818762540817, 0.1027572825551033, 0.11875619739294052]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9242545366287231, 0.07574543356895447, 0.0, 0.0, 0.0, 0.0], [0.8257425427436829, 0.07932533323764801, 0.09493216127157211, 0.0, 0.0, 0.0], [0.7306380271911621, 0.0857183039188385, 0.08043931424617767, 0.10320431739091873, 0.0, 0.0], [0.6383238434791565, 0.07886394113302231, 0.07815027981996536, 0.08758097141981125, 0.1170809343457222, 0.0], [0.5552157163619995, 0.07409121096134186, 0.06834889203310013, 0.07778600603342056, 0.09999319165945053, 0.12456497550010681]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8578913807868958, 0.14210854470729828, 0.0, 0.0, 0.0, 0.0], [0.6423038244247437, 0.166290283203125, 0.19140593707561493, 0.0, 0.0, 0.0], [0.5530979633331299, 0.10609274357557297, 0.07821257412433624, 0.26259663701057434, 0.0, 0.0], [0.40121692419052124, 0.12223611027002335, 0.1934729963541031, 0.14164622128009796, 0.14142780005931854, 0.0], [0.40212565660476685, 0.18450751900672913, 0.07516805827617645, 0.05849048122763634, 0.1444634348154068, 0.13524490594863892]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9791558980941772, 0.020844051614403725, 0.0, 0.0, 0.0, 0.0], [0.8829841613769531, 0.06233249977231026, 0.05468335747718811, 0.0, 0.0, 0.0], [0.8105455040931702, 0.08617085963487625, 0.07321777194738388, 0.03006584383547306, 0.0, 0.0], [0.6819812059402466, 0.04990820586681366, 0.08296552300453186, 0.08369525521993637, 0.10144983977079391, 0.0], [0.4056689441204071, 0.07337666302919388, 0.08601408451795578, 0.061709366738796234, 0.13226434588432312, 0.2409665435552597]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9670190811157227, 0.03298088163137436, 0.0, 0.0, 0.0, 0.0], [0.8449064493179321, 0.0851450264453888, 0.06994850933551788, 0.0, 0.0, 0.0], [0.7123572826385498, 0.07896047830581665, 0.055410757660865784, 0.15327158570289612, 0.0, 0.0], [0.6402613520622253, 0.0739755630493164, 0.044393062591552734, 0.14322125911712646, 0.09814881533384323, 0.0], [0.5073903799057007, 0.07523059099912643, 0.07754647731781006, 0.11362491548061371, 0.13947951793670654, 0.08672808855772018]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8487569093704224, 0.1512431502342224, 0.0, 0.0, 0.0, 0.0], [0.8415648937225342, 0.12107233703136444, 0.03736274689435959, 0.0, 0.0, 0.0], [0.7505517601966858, 0.11348944902420044, 0.06179959326982498, 0.07415912300348282, 0.0, 0.0], [0.6614719033241272, 0.10242646187543869, 0.052934251725673676, 0.07529708743095398, 0.10787025839090347, 0.0], [0.6014202237129211, 0.11340376734733582, 0.05631929263472557, 0.07096721231937408, 0.10906282067298889, 0.04882663115859032]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9445484280586243, 0.05545158311724663, 0.0, 0.0, 0.0, 0.0], [0.8874568939208984, 0.05474215745925903, 0.0578010231256485, 0.0, 0.0, 0.0], [0.8281888961791992, 0.06895001977682114, 0.059034693986177444, 0.0438263975083828, 0.0, 0.0], [0.6429892778396606, 0.0674755647778511, 0.11629703640937805, 0.05417950078845024, 0.11905858665704727, 0.0], [0.7367823719978333, 0.056119054555892944, 0.06857288628816605, 0.034219540655612946, 0.0787537544965744, 0.02555238828063011]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0002913394710049033, 0.9997085928916931, 0.0, 0.0, 0.0, 0.0], [0.0007981209782883525, 0.5288336873054504, 0.4703682065010071, 0.0, 0.0, 0.0], [0.0007648481405340135, 0.34519824385643005, 0.3085267245769501, 0.34551018476486206, 0.0, 0.0], [0.0010283143492415547, 0.241359144449234, 0.23320138454437256, 0.2555713355541229, 0.2688397467136383, 0.0], [0.0009746829164214432, 0.17789699137210846, 0.16743157804012299, 0.1858760118484497, 0.18734444677829742, 0.28047630190849304]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.824492871761322, 0.17550717294216156, 0.0, 0.0, 0.0, 0.0], [0.12386877834796906, 0.044499922543764114, 0.8316312432289124, 0.0, 0.0, 0.0], [0.07924355566501617, 0.01296587660908699, 0.0015277155907824636, 0.9062628149986267, 0.0, 0.0], [0.08806384354829788, 0.0213409923017025, 0.0028886159416288137, 0.002845379989594221, 0.884861171245575, 0.0], [0.09983218461275101, 0.03363388776779175, 0.0054999832063913345, 0.002433052286505699, 0.0015082412865012884, 0.8570926189422607]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9646892547607422, 0.03531072288751602, 0.0, 0.0, 0.0, 0.0], [0.7529157400131226, 0.08733473718166351, 0.15974950790405273, 0.0, 0.0, 0.0], [0.4202282726764679, 0.09195102006196976, 0.23549850285053253, 0.25232216715812683, 0.0, 0.0], [0.30848920345306396, 0.05908140912652016, 0.38391315937042236, 0.15659146010875702, 0.09192468225955963, 0.0], [0.44790443778038025, 0.04329312965273857, 0.0796918049454689, 0.11081931740045547, 0.22124572098255157, 0.09704558551311493]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.991096019744873, 0.008904009126126766, 0.0, 0.0, 0.0, 0.0], [0.9697675704956055, 0.026084503158926964, 0.004147922620177269, 0.0, 0.0, 0.0], [0.9082901477813721, 0.033206019550561905, 0.00942116230726242, 0.049082688987255096, 0.0, 0.0], [0.8949133157730103, 0.05544555187225342, 0.005577624775469303, 0.03150692582130432, 0.012556522153317928, 0.0], [0.8497740030288696, 0.028890123590826988, 0.0036647915840148926, 0.03751987963914871, 0.038427725434303284, 0.04172350466251373]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9984525442123413, 0.0015474462416023016, 0.0, 0.0, 0.0, 0.0], [0.48947831988334656, 0.4812193810939789, 0.029302269220352173, 0.0, 0.0, 0.0], [0.11772153526544571, 0.13121186196804047, 0.6702314615249634, 0.08083520829677582, 0.0, 0.0], [0.13043689727783203, 0.04068669304251671, 0.2652038037776947, 0.4114362895488739, 0.15223638713359833, 0.0], [0.12661904096603394, 0.03275119513273239, 0.03567872568964958, 0.06039190664887428, 0.6021825075149536, 0.1423766165971756]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9805176854133606, 0.019482342526316643, 0.0, 0.0, 0.0, 0.0], [0.7948849201202393, 0.12061909586191177, 0.08449601382017136, 0.0, 0.0, 0.0], [0.5612356066703796, 0.15743127465248108, 0.20339730381965637, 0.0779358446598053, 0.0, 0.0], [0.42583736777305603, 0.10742014646530151, 0.15123659372329712, 0.08755031228065491, 0.22795552015304565, 0.0], [0.24752654135227203, 0.024188270792365074, 0.03039524517953396, 0.08586956560611725, 0.5714336633682251, 0.040586672723293304]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9887767434120178, 0.011223225854337215, 0.0, 0.0, 0.0, 0.0], [0.7572693228721619, 0.22317346930503845, 0.019557112827897072, 0.0, 0.0, 0.0], [0.5341880321502686, 0.22107566893100739, 0.1762184202671051, 0.06851787120103836, 0.0, 0.0], [0.17095312476158142, 0.0822940468788147, 0.576022207736969, 0.11097585409879684, 0.059754710644483566, 0.0], [0.2487109899520874, 0.08880793303251266, 0.08980197459459305, 0.09729334712028503, 0.4413093626499176, 0.03407646715641022]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8422133326530457, 0.15778663754463196, 0.0, 0.0, 0.0, 0.0], [0.468412846326828, 0.46105360984802246, 0.07053359597921371, 0.0, 0.0, 0.0], [0.2588140666484833, 0.4635888636112213, 0.18503506481647491, 0.09256205707788467, 0.0, 0.0], [0.18399578332901, 0.29154160618782043, 0.17031098902225494, 0.27173006534576416, 0.08242159336805344, 0.0], [0.1646990180015564, 0.2472696155309677, 0.08770562708377838, 0.22575001418590546, 0.1774536371231079, 0.09712201356887817]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9919946193695068, 0.008005390875041485, 0.0, 0.0, 0.0, 0.0], [0.9068724513053894, 0.044065121561288834, 0.04906242713332176, 0.0, 0.0, 0.0], [0.8582221865653992, 0.055348269641399384, 0.040419407188892365, 0.046010036021471024, 0.0, 0.0], [0.7855252623558044, 0.041242364794015884, 0.08369296044111252, 0.04887620359659195, 0.040663279592990875, 0.0], [0.7856317162513733, 0.05014643445611, 0.04751267284154892, 0.027365952730178833, 0.05614755302667618, 0.03319567069411278]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9041035175323486, 0.09589648246765137, 0.0, 0.0, 0.0, 0.0], [0.5862312912940979, 0.07199832051992416, 0.34177035093307495, 0.0, 0.0, 0.0], [0.3878960907459259, 0.04660807177424431, 0.20278996229171753, 0.36270591616630554, 0.0, 0.0], [0.2665242552757263, 0.024533024057745934, 0.12211935967206955, 0.20041218400001526, 0.386411190032959, 0.0], [0.23357485234737396, 0.02053728699684143, 0.09610321372747421, 0.13062246143817902, 0.22990450263023376, 0.289257675409317]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9639912247657776, 0.036008793860673904, 0.0, 0.0, 0.0, 0.0], [0.7075552344322205, 0.2542775869369507, 0.038167137652635574, 0.0, 0.0, 0.0], [0.2566526234149933, 0.20589298009872437, 0.01665665954351425, 0.5207977294921875, 0.0, 0.0], [0.1037939190864563, 0.04639088362455368, 0.008698614314198494, 0.7866851687431335, 0.05443140119314194, 0.0], [0.2214341163635254, 0.03379744663834572, 0.029023902490735054, 0.541292130947113, 0.15286092460155487, 0.021591555327177048]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9891703724861145, 0.010829661041498184, 0.0, 0.0, 0.0, 0.0], [0.7913155555725098, 0.12309625744819641, 0.08558809012174606, 0.0, 0.0, 0.0], [0.2954600155353546, 0.15808308124542236, 0.4217240810394287, 0.1247328370809555, 0.0, 0.0], [0.23440983891487122, 0.09886523336172104, 0.33160170912742615, 0.1971396654844284, 0.1379835456609726, 0.0], [0.19728390872478485, 0.05741839483380318, 0.06909029185771942, 0.16469819843769073, 0.2797277867794037, 0.23178131878376007]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9359127879142761, 0.0640871673822403, 0.0, 0.0, 0.0, 0.0], [0.7888627648353577, 0.08673475682735443, 0.12440246343612671, 0.0, 0.0, 0.0], [0.6535118818283081, 0.07573551684617996, 0.09732568264007568, 0.17342689633369446, 0.0, 0.0], [0.522276759147644, 0.058278825134038925, 0.09920477122068405, 0.17020836472511292, 0.15003129839897156, 0.0], [0.4108840823173523, 0.047306034713983536, 0.07265672832727432, 0.10560744255781174, 0.10550004243850708, 0.25804558396339417]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9683833122253418, 0.03161672502756119, 0.0, 0.0, 0.0, 0.0], [0.8965396881103516, 0.038870569318532944, 0.06458976864814758, 0.0, 0.0, 0.0], [0.8264952898025513, 0.03213464096188545, 0.05196719989180565, 0.0894029513001442, 0.0, 0.0], [0.7718173265457153, 0.030402837321162224, 0.045827414840459824, 0.07118473201990128, 0.08076759427785873, 0.0], [0.7292331457138062, 0.021699821576476097, 0.033074747771024704, 0.04720093309879303, 0.06474557518959045, 0.10404567420482635]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9979567527770996, 0.0020432830788195133, 0.0, 0.0, 0.0, 0.0], [0.955294132232666, 0.00802531372755766, 0.03668047487735748, 0.0, 0.0, 0.0], [0.9254710078239441, 0.002755576279014349, 0.0020629852078855038, 0.06971040368080139, 0.0, 0.0], [0.8660576939582825, 0.0038883681409060955, 0.0006785982404835522, 0.0006981453043408692, 0.1286771297454834, 0.0], [0.8455929160118103, 0.0037804055027663708, 0.000253423087997362, 6.0270751419011503e-05, 0.00011820747749879956, 0.15019479393959045]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9262455105781555, 0.07375453412532806, 0.0, 0.0, 0.0, 0.0], [0.7717157006263733, 0.16241952776908875, 0.06586471945047379, 0.0, 0.0, 0.0], [0.8167637586593628, 0.07807160913944244, 0.06324034929275513, 0.041924238204956055, 0.0, 0.0], [0.6867184638977051, 0.07755157351493835, 0.10056912153959274, 0.05955080687999725, 0.07561002671718597, 0.0], [0.6421161890029907, 0.11014898866415024, 0.07688194513320923, 0.054033469408750534, 0.10333634912967682, 0.013483096845448017]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9395954608917236, 0.060404520481824875, 0.0, 0.0, 0.0, 0.0], [0.23004619777202606, 0.6617380380630493, 0.1082158014178276, 0.0, 0.0, 0.0], [0.2670227289199829, 0.3607950508594513, 0.3249626159667969, 0.047219593077898026, 0.0, 0.0], [0.595201313495636, 0.12269274890422821, 0.06302059441804886, 0.08916817605495453, 0.12991715967655182, 0.0], [0.10284596681594849, 0.02938011661171913, 0.013739082030951977, 0.045860596001148224, 0.7698501348495483, 0.03832406550645828]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9040980935096741, 0.09590194374322891, 0.0, 0.0, 0.0, 0.0], [0.357237845659256, 0.6274612545967102, 0.015300876460969448, 0.0, 0.0, 0.0], [0.5917996764183044, 0.2764042019844055, 0.10476048290729523, 0.027035649865865707, 0.0, 0.0], [0.7254403829574585, 0.04983152449131012, 0.014982940629124641, 0.1778142899274826, 0.031930916011333466, 0.0], [0.7612743973731995, 0.06158972904086113, 0.005942251533269882, 0.01642685756087303, 0.1267806589603424, 0.0279861893504858]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9947587847709656, 0.005241230130195618, 0.0, 0.0, 0.0, 0.0], [0.9632415771484375, 0.017816413193941116, 0.018942030146718025, 0.0, 0.0, 0.0], [0.9671078324317932, 0.008509586565196514, 0.00856222677975893, 0.015820473432540894, 0.0, 0.0], [0.9340996146202087, 0.011952387169003487, 0.02018021047115326, 0.02675083465874195, 0.0070168930105865, 0.0], [0.9587237238883972, 0.004657115787267685, 0.003326789475977421, 0.006545313633978367, 0.010182461701333523, 0.016564540565013885]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9769991040229797, 0.023000910878181458, 0.0, 0.0, 0.0, 0.0], [0.7917609214782715, 0.1753319948911667, 0.032907065004110336, 0.0, 0.0, 0.0], [0.7949192523956299, 0.10531841963529587, 0.040218502283096313, 0.05954383686184883, 0.0, 0.0], [0.7097718715667725, 0.10552527755498886, 0.06597573310136795, 0.05765606462955475, 0.061070989817380905, 0.0], [0.7506601214408875, 0.026514461264014244, 0.021576043218374252, 0.034296683967113495, 0.08494450151920319, 0.08200812339782715]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.983751654624939, 0.016248304396867752, 0.0, 0.0, 0.0, 0.0], [0.5615494847297668, 0.08956841379404068, 0.3488820493221283, 0.0, 0.0, 0.0], [0.32929039001464844, 0.024114903062582016, 0.5428059697151184, 0.10378880053758621, 0.0, 0.0], [0.34330207109451294, 0.01308644749224186, 0.5121983289718628, 0.11146228760480881, 0.019950881600379944, 0.0], [0.4792812764644623, 0.01733359508216381, 0.1180536150932312, 0.06130281835794449, 0.20071913301944733, 0.12330964207649231]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9908847212791443, 0.009115329943597317, 0.0, 0.0, 0.0, 0.0], [0.5282707214355469, 0.3292262554168701, 0.1425030380487442, 0.0, 0.0, 0.0], [0.48788541555404663, 0.23368670046329498, 0.17578084766864777, 0.10264702141284943, 0.0, 0.0], [0.31444698572158813, 0.18065163493156433, 0.168714240193367, 0.09506598114967346, 0.24112118780612946, 0.0], [0.5168765187263489, 0.035897161811590195, 0.026188155636191368, 0.04039734974503517, 0.18791745603084564, 0.1927233189344406]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8750308156013489, 0.12496919929981232, 0.0, 0.0, 0.0, 0.0], [0.4550614655017853, 0.4900427758693695, 0.05489582195878029, 0.0, 0.0, 0.0], [0.2933720052242279, 0.5449907183647156, 0.09444297850131989, 0.06719419360160828, 0.0, 0.0], [0.489708811044693, 0.2720997631549835, 0.06861965358257294, 0.14694802463054657, 0.022623788565397263, 0.0], [0.4729066491127014, 0.08103099465370178, 0.016052134335041046, 0.30672287940979004, 0.10120721161365509, 0.022080255672335625]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9630220532417297, 0.03697792813181877, 0.0, 0.0, 0.0, 0.0], [0.7557195425033569, 0.16436372697353363, 0.07991670072078705, 0.0, 0.0, 0.0], [0.6947705745697021, 0.08409853279590607, 0.0638260766863823, 0.15730486810207367, 0.0, 0.0], [0.5821147561073303, 0.03297805413603783, 0.07936596870422363, 0.19441406428813934, 0.11112712323665619, 0.0], [0.5974540710449219, 0.04261096194386482, 0.06919723749160767, 0.14563441276550293, 0.12481734901666641, 0.020285936072468758]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9957822561264038, 0.004217816516757011, 0.0, 0.0, 0.0, 0.0], [0.9312832951545715, 0.010560247115790844, 0.05815650522708893, 0.0, 0.0, 0.0], [0.8435326814651489, 0.015695005655288696, 0.045751139521598816, 0.09502115100622177, 0.0, 0.0], [0.772409975528717, 0.011981245130300522, 0.03504609689116478, 0.03876771405339241, 0.14179500937461853, 0.0], [0.7642908692359924, 0.009868789464235306, 0.00812275055795908, 0.013314393348991871, 0.04824395477771759, 0.15615922212600708]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9701177477836609, 0.02988232672214508, 0.0, 0.0, 0.0, 0.0], [0.6564007997512817, 0.22506150603294373, 0.11853761970996857, 0.0, 0.0, 0.0], [0.6958062648773193, 0.14701850712299347, 0.07145983725786209, 0.08571550250053406, 0.0, 0.0], [0.6353274583816528, 0.1346064656972885, 0.030994214117527008, 0.056916315108537674, 0.1421555131673813, 0.0], [0.6779401898384094, 0.053654152899980545, 0.01800631172955036, 0.06284520775079727, 0.1103820651769638, 0.07717210054397583]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9822334051132202, 0.017766647040843964, 0.0, 0.0, 0.0, 0.0], [0.9037663340568542, 0.06541544198989868, 0.03081829659640789, 0.0, 0.0, 0.0], [0.8119193911552429, 0.03679030388593674, 0.060560714453458786, 0.09072960168123245, 0.0, 0.0], [0.40546438097953796, 0.10383912175893784, 0.10211236774921417, 0.35434210300445557, 0.03424208238720894, 0.0], [0.22824221849441528, 0.017278727144002914, 0.05055465176701546, 0.6015752553939819, 0.09411764144897461, 0.008231506682932377]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9873148202896118, 0.012685136869549751, 0.0, 0.0, 0.0, 0.0], [0.35445743799209595, 0.5317603349685669, 0.11378221958875656, 0.0, 0.0, 0.0], [0.07823363691568375, 0.7221359014511108, 0.10936623811721802, 0.090264230966568, 0.0, 0.0], [0.21967869997024536, 0.4048435091972351, 0.12358088046312332, 0.20018866658210754, 0.051708199083805084, 0.0], [0.36089760065078735, 0.10459021478891373, 0.06983799487352371, 0.2976483404636383, 0.13869903981685638, 0.02832675166428089]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9732162356376648, 0.0267837755382061, 0.0, 0.0, 0.0, 0.0], [0.9167553782463074, 0.061452705413103104, 0.02179192565381527, 0.0, 0.0, 0.0], [0.8543081283569336, 0.08049600571393967, 0.030334919691085815, 0.03486092761158943, 0.0, 0.0], [0.8919214606285095, 0.04280779883265495, 0.022045055404305458, 0.023470671847462654, 0.01975487545132637, 0.0], [0.8116763234138489, 0.03413533419370651, 0.03567665070295334, 0.04748587682843208, 0.0253971628844738, 0.04562860727310181]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9502761960029602, 0.04972382262349129, 0.0, 0.0, 0.0, 0.0], [0.7637454271316528, 0.2007361352443695, 0.03551840782165527, 0.0, 0.0, 0.0], [0.6279097199440002, 0.03768139332532883, 0.1994536966085434, 0.13495522737503052, 0.0, 0.0], [0.6397060751914978, 0.027007432654500008, 0.09082036465406418, 0.20653828978538513, 0.03592785820364952, 0.0], [0.4559425115585327, 0.021641194820404053, 0.12939567863941193, 0.21800927817821503, 0.10379841923713684, 0.07121295481920242]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9498406648635864, 0.050159383565187454, 0.0, 0.0, 0.0, 0.0], [0.8688724637031555, 0.0872218981385231, 0.043905653059482574, 0.0, 0.0, 0.0], [0.6937950253486633, 0.06359200924634933, 0.091790571808815, 0.15082231163978577, 0.0, 0.0], [0.7266597151756287, 0.04389883577823639, 0.04683985933661461, 0.09851823002099991, 0.08408336341381073, 0.0], [0.7848998308181763, 0.037147827446460724, 0.012907838448882103, 0.01053939200937748, 0.12079165875911713, 0.03371351957321167]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9891054034233093, 0.01089458167552948, 0.0, 0.0, 0.0, 0.0], [0.8929519653320312, 0.08700055629014969, 0.02004752680659294, 0.0, 0.0, 0.0], [0.7891124486923218, 0.09797251224517822, 0.08633202314376831, 0.026582980528473854, 0.0, 0.0], [0.8850635886192322, 0.03645012155175209, 0.05395457148551941, 0.01237727515399456, 0.012154522351920605, 0.0], [0.6861329674720764, 0.05720378831028938, 0.011636304669082165, 0.021660611033439636, 0.1748800277709961, 0.048486363142728806]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9396191835403442, 0.06038080155849457, 0.0, 0.0, 0.0, 0.0], [0.7851794958114624, 0.19751444458961487, 0.017306052148342133, 0.0, 0.0, 0.0], [0.7660509943962097, 0.15444670617580414, 0.03188290074467659, 0.04761936888098717, 0.0, 0.0], [0.703522801399231, 0.05171430483460426, 0.07760990411043167, 0.1533905267715454, 0.013762423768639565, 0.0], [0.7121888399124146, 0.04994234815239906, 0.03772548958659172, 0.08649132400751114, 0.06541401147842407, 0.04823806509375572]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.974072277545929, 0.025927715003490448, 0.0, 0.0, 0.0, 0.0], [0.792539656162262, 0.01171559002250433, 0.19574476778507233, 0.0, 0.0, 0.0], [0.5106770992279053, 0.007296787109225988, 0.039619915187358856, 0.4424062669277191, 0.0, 0.0], [0.5862472057342529, 0.012099712155759335, 0.024585209786891937, 0.06737840175628662, 0.30968940258026123, 0.0], [0.30196306109428406, 0.007724012713879347, 0.011518122628331184, 0.046947259455919266, 0.22146707773208618, 0.41038045287132263]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9744554162025452, 0.02554464340209961, 0.0, 0.0, 0.0, 0.0], [0.9769195318222046, 0.015048524364829063, 0.008031901903450489, 0.0, 0.0, 0.0], [0.9060619473457336, 0.025875424966216087, 0.025954782962799072, 0.04210779070854187, 0.0, 0.0], [0.9400081038475037, 0.00555665697902441, 0.005828304681926966, 0.031757812947034836, 0.016849134117364883, 0.0], [0.9105738401412964, 0.0019752182997763157, 0.008646721951663494, 0.013360846787691116, 0.03543964773416519, 0.030003678053617477]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9791666865348816, 0.020833350718021393, 0.0, 0.0, 0.0, 0.0], [0.8444858193397522, 0.13507869839668274, 0.020435383543372154, 0.0, 0.0, 0.0], [0.7903086543083191, 0.14559169113636017, 0.037529975175857544, 0.026569725945591927, 0.0, 0.0], [0.7298924326896667, 0.056496407836675644, 0.032735615968704224, 0.10400459170341492, 0.07687094807624817, 0.0], [0.5684185028076172, 0.04388832300901413, 0.026293467730283737, 0.0811714455485344, 0.24314835667610168, 0.037079911679029465]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9499868154525757, 0.05001320689916611, 0.0, 0.0, 0.0, 0.0], [0.9336170554161072, 0.05848868936300278, 0.007894262671470642, 0.0, 0.0, 0.0], [0.7897834181785583, 0.11071821302175522, 0.05360178276896477, 0.04589657858014107, 0.0, 0.0], [0.885930061340332, 0.05752986669540405, 0.01374326553195715, 0.0033877466339617968, 0.03940902277827263, 0.0], [0.9337607622146606, 0.02647063508629799, 0.004523396957665682, 0.0061904797330498695, 0.014132906682789326, 0.014921708963811398]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.8521224554035598e-09, 0.0, 0.0, 0.0, 0.0], [6.6758907451003324e-06, 0.9999804496765137, 1.2841281204600818e-05, 0.0, 0.0, 0.0], [2.2194194926328237e-08, 2.6684581211355862e-09, 0.9999971389770508, 2.8136880700913025e-06, 0.0, 0.0], [1.0145409987671883e-06, 4.464065739284706e-08, 0.00035356366424821317, 0.9993677735328674, 0.0002776293840724975, 0.0], [9.436550429953172e-10, 1.382057315812979e-11, 5.017835036369434e-10, 2.965183876213473e-09, 0.9999971389770508, 2.8644042231462663e-06]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9948632121086121, 0.005136783700436354, 0.0, 0.0, 0.0, 0.0], [0.9274215698242188, 0.01832387037575245, 0.05425456911325455, 0.0, 0.0, 0.0], [0.9678993225097656, 0.004143435508012772, 0.004314453341066837, 0.023642776533961296, 0.0, 0.0], [0.8999068737030029, 0.001467161695472896, 0.00029133574571460485, 0.002585014794021845, 0.09574954956769943, 0.0], [0.9386115670204163, 0.00022248300956562161, 0.0006146665546111763, 0.0015495637198910117, 0.030689461156725883, 0.028312424197793007]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9999959468841553, 4.042720775032649e-06, 0.0, 0.0, 0.0, 0.0], [0.9982761144638062, 3.2613831990602193e-06, 0.001720669330097735, 0.0, 0.0, 0.0], [0.9998809099197388, 5.328835683826583e-08, 6.376215537784446e-07, 0.00011847059795400128, 0.0, 0.0], [0.9996154308319092, 3.473169556400535e-07, 3.8920820344401363e-08, 4.468433303372876e-07, 0.00038369710091501474, 0.0], [0.9994840621948242, 1.655020476221125e-08, 2.8715557931491276e-08, 1.0638284493325045e-06, 0.0002126671897713095, 0.00030212008277885616]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9514135718345642, 0.048586405813694, 0.0, 0.0, 0.0, 0.0], [0.5749948024749756, 0.39028096199035645, 0.03472418338060379, 0.0, 0.0, 0.0], [0.7442318201065063, 0.1752411425113678, 0.0756477490067482, 0.004879283253103495, 0.0, 0.0], [0.5232070684432983, 0.09429339319467545, 0.1138191670179367, 0.19979268312454224, 0.06888769567012787, 0.0], [0.47472575306892395, 0.05636607110500336, 0.04530389606952667, 0.06967321783304214, 0.3098014295101166, 0.0441296212375164]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8734648823738098, 0.12653514742851257, 0.0, 0.0, 0.0, 0.0], [0.6097912788391113, 0.3541727066040039, 0.036036062985658646, 0.0, 0.0, 0.0], [0.45984190702438354, 0.38697871565818787, 0.0996011346578598, 0.05357823893427849, 0.0, 0.0], [0.572220504283905, 0.23636263608932495, 0.08344558626413345, 0.06921917200088501, 0.03875211998820305, 0.0], [0.5143564343452454, 0.16723087430000305, 0.09019406139850616, 0.0765448659658432, 0.10578085482120514, 0.04589281603693962]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.981228768825531, 0.018771231174468994, 0.0, 0.0, 0.0, 0.0], [0.6142941117286682, 0.3503977954387665, 0.0353081189095974, 0.0, 0.0, 0.0], [0.5770686268806458, 0.32858458161354065, 0.05508256331086159, 0.03926428034901619, 0.0, 0.0], [0.17188192903995514, 0.011042501777410507, 0.054578714072704315, 0.7326585650444031, 0.029838265851140022, 0.0], [0.3783015012741089, 0.017070062458515167, 0.021754134446382523, 0.4409688115119934, 0.06093813106417656, 0.08096737414598465]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9923112392425537, 0.007688735146075487, 0.0, 0.0, 0.0, 0.0], [0.9498787522315979, 0.016709784045815468, 0.03341152146458626, 0.0, 0.0, 0.0], [0.9961295127868652, 0.0008787295082584023, 0.0006868162308819592, 0.0023048371076583862, 0.0, 0.0], [0.9935757517814636, 0.0032634998206049204, 0.0009993825806304812, 0.00027932299417443573, 0.0018820574041455984, 0.0], [0.9907532930374146, 0.00021344318520277739, 0.0004595233185682446, 0.0007905619568191469, 0.004424723796546459, 0.003358350833877921]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9647740125656128, 0.03522596135735512, 0.0, 0.0, 0.0, 0.0], [0.8194130063056946, 0.1365436613559723, 0.04404333233833313, 0.0, 0.0, 0.0], [0.7584245800971985, 0.006878929678350687, 0.20653395354747772, 0.028162529692053795, 0.0, 0.0], [0.5298128128051758, 0.002678812015801668, 0.07857988774776459, 0.3598373234272003, 0.02909109927713871, 0.0], [0.7544413208961487, 0.00036782227107323706, 0.0019713479559868574, 0.00324004958383739, 0.1942344754934311, 0.04574500769376755]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9749131202697754, 0.02508680149912834, 0.0, 0.0, 0.0, 0.0], [0.9306471943855286, 0.05705660209059715, 0.012296222150325775, 0.0, 0.0, 0.0], [0.9305251836776733, 0.052770983427762985, 0.01111945416778326, 0.005584415514022112, 0.0, 0.0], [0.8863320350646973, 0.01292418036609888, 0.017724711447954178, 0.06150198355317116, 0.021517015993595123, 0.0], [0.791684627532959, 0.015036096796393394, 0.0317479707300663, 0.03392200171947479, 0.03707978501915932, 0.09052948653697968]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9608501195907593, 0.039149850606918335, 0.0, 0.0, 0.0, 0.0], [0.9121272563934326, 0.02257651649415493, 0.06529619544744492, 0.0, 0.0, 0.0], [0.9364108443260193, 0.015584447421133518, 0.024544963613152504, 0.02345985174179077, 0.0, 0.0], [0.9454620480537415, 0.006762288510799408, 0.022026237100362778, 0.009137796238064766, 0.016611700877547264, 0.0], [0.8346164226531982, 0.001881699077785015, 0.00560904573649168, 0.01887359470129013, 0.12449200451374054, 0.014527074061334133]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9964227080345154, 0.0035772807896137238, 0.0, 0.0, 0.0, 0.0], [0.9713928699493408, 0.024453025311231613, 0.004154058638960123, 0.0, 0.0, 0.0], [0.9735792279243469, 0.019003381952643394, 0.003664410673081875, 0.0037529165856540203, 0.0, 0.0], [0.9586312174797058, 0.007116180844604969, 0.009218388237059116, 0.022725583985447884, 0.0023084774147719145, 0.0], [0.973607063293457, 0.008490582928061485, 0.0032512471079826355, 0.003606445388868451, 0.004877461586147547, 0.006167212035506964]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.97598797082901, 0.024011990055441856, 0.0, 0.0, 0.0, 0.0], [0.9460638165473938, 0.04211375489830971, 0.011822436936199665, 0.0, 0.0, 0.0], [0.8446813225746155, 0.04293116182088852, 0.05218198522925377, 0.06020559370517731, 0.0, 0.0], [0.9378372430801392, 0.03354858607053757, 0.008826455101370811, 0.0028792242519557476, 0.016908427700400352, 0.0], [0.8124931454658508, 0.02696753479540348, 0.05999218672513962, 0.03445731848478317, 0.011011860333383083, 0.05507794767618179]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9001203775405884, 0.09987961500883102, 0.0, 0.0, 0.0, 0.0], [0.627193033695221, 0.07988718152046204, 0.29291975498199463, 0.0, 0.0, 0.0], [0.7624077796936035, 0.02734432928264141, 0.038679543882608414, 0.17156831920146942, 0.0, 0.0], [0.7995968461036682, 0.014336260966956615, 0.01437566988170147, 0.025438452139496803, 0.14625284075737, 0.0], [0.7851970791816711, 0.04204057529568672, 0.025253651663661003, 0.02908395044505596, 0.029306314885616302, 0.08911846578121185]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9954467415809631, 0.0045532057993113995, 0.0, 0.0, 0.0, 0.0], [0.9356001615524292, 0.04476744681596756, 0.019632352516055107, 0.0, 0.0, 0.0], [0.5605552792549133, 0.09861977398395538, 0.29983264207839966, 0.040992289781570435, 0.0, 0.0], [0.5893709659576416, 0.11000988632440567, 0.08033622056245804, 0.16754034161567688, 0.05274256691336632, 0.0], [0.22305884957313538, 0.05680817365646362, 0.05467984080314636, 0.24733951687812805, 0.3111244738101959, 0.1069890558719635]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9301451444625854, 0.06985488533973694, 0.0, 0.0, 0.0, 0.0], [0.8936478495597839, 0.08535721153020859, 0.020994966849684715, 0.0, 0.0, 0.0], [0.8404538035392761, 0.10619214922189713, 0.02363673783838749, 0.029717326164245605, 0.0, 0.0], [0.8927386403083801, 0.024784674867987633, 0.008319000713527203, 0.05165454372763634, 0.022503145039081573, 0.0], [0.8646610975265503, 0.009503193199634552, 0.0024329854641109705, 0.04796753078699112, 0.04273205250501633, 0.03270319849252701]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9859625697135925, 0.014037408865988255, 0.0, 0.0, 0.0, 0.0], [0.9702037572860718, 0.0168070700019598, 0.012989125214517117, 0.0, 0.0, 0.0], [0.9524770379066467, 0.016064459457993507, 0.013456220738589764, 0.018002323806285858, 0.0, 0.0], [0.9332928657531738, 0.01897200010716915, 0.02014683373272419, 0.017023753374814987, 0.010564540512859821, 0.0], [0.9113592505455017, 0.012528638355433941, 0.02209620550274849, 0.01751861348748207, 0.018517911434173584, 0.01797938533127308]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9681769013404846, 0.03182310611009598, 0.0, 0.0, 0.0, 0.0], [0.9096417427062988, 0.07916690409183502, 0.011191264726221561, 0.0, 0.0, 0.0], [0.8379932045936584, 0.13078266382217407, 0.012140989303588867, 0.019083037972450256, 0.0, 0.0], [0.9116525053977966, 0.05451957508921623, 0.009499342180788517, 0.00746585289016366, 0.01686275750398636, 0.0], [0.8510289192199707, 0.07338211685419083, 0.008022507652640343, 0.009083161130547523, 0.04261006414890289, 0.015873271971940994]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9799023866653442, 0.020097682252526283, 0.0, 0.0, 0.0, 0.0], [0.9558742642402649, 0.029063312336802483, 0.015062497928738594, 0.0, 0.0, 0.0], [0.7943133115768433, 0.06074100360274315, 0.06907659024000168, 0.07586916536092758, 0.0, 0.0], [0.5494324564933777, 0.03154711425304413, 0.05482015758752823, 0.05788077041506767, 0.3063195049762726, 0.0], [0.6453980803489685, 0.010770943015813828, 0.017528092488646507, 0.02157985046505928, 0.24958276748657227, 0.05514020845293999]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9506809115409851, 0.0493190623819828, 0.0, 0.0, 0.0, 0.0], [0.8553215265274048, 0.09256264567375183, 0.05211575701832771, 0.0, 0.0, 0.0], [0.850852370262146, 0.04734604433178902, 0.044177331030368805, 0.057624250650405884, 0.0, 0.0], [0.7697131633758545, 0.02788589708507061, 0.031017286702990532, 0.06842502951622009, 0.1029587835073471, 0.0], [0.7931903004646301, 0.04052198305726051, 0.029242033138871193, 0.04478124529123306, 0.04894689470529556, 0.04331749677658081]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9770310521125793, 0.02296893112361431, 0.0, 0.0, 0.0, 0.0], [0.9429817199707031, 0.017321482300758362, 0.03969680890440941, 0.0, 0.0, 0.0], [0.9144344925880432, 0.008583576418459415, 0.013035810552537441, 0.06394599378108978, 0.0, 0.0], [0.9222429990768433, 0.0036440351977944374, 0.003740275977179408, 0.010410364717245102, 0.05996239185333252, 0.0], [0.9198879599571228, 0.0030822583939880133, 0.0034827394410967827, 0.004206796642392874, 0.02125428058207035, 0.048085976392030716]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.977458119392395, 0.022541873157024384, 0.0, 0.0, 0.0, 0.0], [0.8929325342178345, 0.07475466281175613, 0.032312843948602676, 0.0, 0.0, 0.0], [0.8423511385917664, 0.05980278551578522, 0.03740081936120987, 0.06044524535536766, 0.0, 0.0], [0.7674624919891357, 0.03536349534988403, 0.042155250906944275, 0.06658654659986496, 0.08843226730823517, 0.0], [0.6182611584663391, 0.01611059531569481, 0.020167622715234756, 0.03868892416357994, 0.23147016763687134, 0.07530155777931213]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9634856581687927, 0.036514393985271454, 0.0, 0.0, 0.0, 0.0], [0.4363938570022583, 0.522637128829956, 0.04096902906894684, 0.0, 0.0, 0.0], [0.3608614206314087, 0.35129693150520325, 0.2655103802680969, 0.022331148386001587, 0.0, 0.0], [0.3942921757698059, 0.021704670041799545, 0.07794328778982162, 0.37168896198272705, 0.1343708038330078, 0.0], [0.6310713887214661, 0.01698400266468525, 0.025942081585526466, 0.08615949749946594, 0.2183200567960739, 0.021522950381040573]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9988250136375427, 0.0011750265257433057, 0.0, 0.0, 0.0, 0.0], [0.9944871068000793, 0.0004826401418540627, 0.0050302306190133095, 0.0, 0.0, 0.0], [0.9981209635734558, 2.705173392314464e-05, 0.0001130745149566792, 0.0017389442073181272, 0.0, 0.0], [0.9982239603996277, 6.83655816828832e-05, 0.00010199935059063137, 6.028370262356475e-05, 0.0015453165397047997, 0.0], [0.9982888102531433, 1.055222810464329e-06, 3.2781026675365865e-05, 0.00013038977340329438, 0.0006605894886888564, 0.0008863684488460422]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9936710596084595, 0.006328921765089035, 0.0, 0.0, 0.0, 0.0], [0.9727688431739807, 0.0018561368342489004, 0.025375060737133026, 0.0, 0.0, 0.0], [0.9724299907684326, 0.0019586149137467146, 0.011192461475729942, 0.014418890699744225, 0.0, 0.0], [0.9782041311264038, 0.0009589138207957149, 0.0018706483533605933, 0.006326568778604269, 0.012639678083360195, 0.0], [0.9592596888542175, 0.0024555064737796783, 0.00161241355817765, 0.005019655916839838, 0.006687097251415253, 0.024965662509202957]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9629000425338745, 0.03709998354315758, 0.0, 0.0, 0.0, 0.0], [0.36801934242248535, 0.6152258515357971, 0.016754813492298126, 0.0, 0.0, 0.0], [0.3173511326313019, 0.6140013337135315, 0.05375149846076965, 0.014896026812493801, 0.0, 0.0], [0.48987284302711487, 0.21071474254131317, 0.04693019017577171, 0.20700432360172272, 0.04547784850001335, 0.0], [0.48774227499961853, 0.1769528090953827, 0.06915216147899628, 0.09849268198013306, 0.12091436982154846, 0.046745721250772476]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9794419407844543, 0.020558049902319908, 0.0, 0.0, 0.0, 0.0], [0.6677903532981873, 0.31032365560531616, 0.021886007860302925, 0.0, 0.0, 0.0], [0.7118757367134094, 0.11108540743589401, 0.14187385141849518, 0.03516504913568497, 0.0, 0.0], [0.4501457214355469, 0.04036055505275726, 0.040458209812641144, 0.388570100069046, 0.08046531677246094, 0.0], [0.49346262216567993, 0.013696977868676186, 0.008126799948513508, 0.13074499368667603, 0.3086138069629669, 0.04535480588674545]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9846054315567017, 0.015394587069749832, 0.0, 0.0, 0.0, 0.0], [0.9806739091873169, 0.007713791914284229, 0.011612347327172756, 0.0, 0.0, 0.0], [0.932663083076477, 0.01957838423550129, 0.02410353161394596, 0.023654978722333908, 0.0, 0.0], [0.9422016739845276, 0.0009538981830701232, 0.0010898025939241052, 0.00319337984547019, 0.05256118252873421, 0.0], [0.9352930784225464, 0.0010279357666149735, 0.004444425459951162, 0.001637140172533691, 0.010590963996946812, 0.04700646549463272]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9985783100128174, 0.0014216724084690213, 0.0, 0.0, 0.0, 0.0], [0.9893348813056946, 0.0011178902350366116, 0.00954714696854353, 0.0, 0.0, 0.0], [0.9979978203773499, 7.997050124686211e-05, 0.00013218850654084235, 0.0017900333041325212, 0.0, 0.0], [0.9986976385116577, 4.1044117097044364e-05, 3.8683547245454974e-06, 2.3676282580709085e-05, 0.0012337174266576767, 0.0], [0.9971563816070557, 1.852225250331685e-05, 1.8826559653462027e-06, 2.7900125132873654e-05, 0.0006533482228405774, 0.0021419788245111704]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9768233299255371, 0.023176640272140503, 0.0, 0.0, 0.0, 0.0], [0.9194678068161011, 0.05088186264038086, 0.029650341719388962, 0.0, 0.0, 0.0], [0.8474554419517517, 0.06100169196724892, 0.04372376948595047, 0.04781914874911308, 0.0, 0.0], [0.8011623620986938, 0.041866958141326904, 0.04375807195901871, 0.041894737631082535, 0.07131782174110413, 0.0], [0.8031871914863586, 0.02450493723154068, 0.017323585227131844, 0.04744395986199379, 0.06109930947422981, 0.046441152691841125]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9829428195953369, 0.01705716922879219, 0.0, 0.0, 0.0, 0.0], [0.8863736987113953, 0.09492647647857666, 0.018699750304222107, 0.0, 0.0, 0.0], [0.9231085777282715, 0.03696346655488014, 0.032198335975408554, 0.007729663979262114, 0.0, 0.0], [0.9068527221679688, 0.016046639531850815, 0.014310522936284542, 0.04543786868453026, 0.017352323979139328, 0.0], [0.6555973887443542, 0.05091019719839096, 0.028384855017066002, 0.1256549060344696, 0.10546853393316269, 0.03398407623171806]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9502318501472473, 0.049768079072237015, 0.0, 0.0, 0.0, 0.0], [0.8829865455627441, 0.1000962108373642, 0.01691717840731144, 0.0, 0.0, 0.0], [0.8057457804679871, 0.14463546872138977, 0.03018922731280327, 0.019429458305239677, 0.0, 0.0], [0.8706230521202087, 0.032440632581710815, 0.026951627805829048, 0.04410304129123688, 0.025881657376885414, 0.0], [0.688364565372467, 0.009681451134383678, 0.016449343413114548, 0.0987110361456871, 0.08971209079027176, 0.09708156436681747]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9792683124542236, 0.02073168195784092, 0.0, 0.0, 0.0, 0.0], [0.9523284435272217, 0.025933818891644478, 0.021737735718488693, 0.0, 0.0, 0.0], [0.9144353270530701, 0.017671240493655205, 0.022358495742082596, 0.04553484544157982, 0.0, 0.0], [0.9448292851448059, 0.006467597559094429, 0.006386063527315855, 0.03263096138834953, 0.00968620739877224, 0.0], [0.9347906112670898, 0.007862505502998829, 0.007788175716996193, 0.021432818844914436, 0.008491144515573978, 0.01963483914732933]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.983370304107666, 0.016629677265882492, 0.0, 0.0, 0.0, 0.0], [0.963111400604248, 0.009229931980371475, 0.027658598497509956, 0.0, 0.0, 0.0], [0.9706628322601318, 0.0041494048200547695, 0.0068131014704704285, 0.018374638631939888, 0.0, 0.0], [0.987951934337616, 0.002165885642170906, 0.00034901127219200134, 0.001583816367201507, 0.00794942770153284, 0.0], [0.9457950592041016, 0.014583553187549114, 0.0003652951563708484, 0.0009569536778144538, 0.013621564954519272, 0.02467755414545536]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9878059029579163, 0.01219407469034195, 0.0, 0.0, 0.0, 0.0], [0.87103670835495, 0.09448163211345673, 0.03448161482810974, 0.0, 0.0, 0.0], [0.6309783458709717, 0.11090382188558578, 0.1923021823167801, 0.06581564992666245, 0.0, 0.0], [0.5360490083694458, 0.04618944972753525, 0.13605308532714844, 0.26455509662628174, 0.017153292894363403, 0.0], [0.8287520408630371, 0.023732755333185196, 0.02008037269115448, 0.07245264202356339, 0.030431220307946205, 0.024550989270210266]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8995685577392578, 0.10043150931596756, 0.0, 0.0, 0.0, 0.0], [0.270343542098999, 0.6504329442977905, 0.07922357320785522, 0.0, 0.0, 0.0], [0.20541730523109436, 0.5892508625984192, 0.18085837364196777, 0.024473490193486214, 0.0, 0.0], [0.5573861002922058, 0.1774134784936905, 0.08806808292865753, 0.09881848096847534, 0.07831384986639023, 0.0], [0.5922912359237671, 0.08700639009475708, 0.05643285810947418, 0.05685883015394211, 0.12181518226861954, 0.08559554070234299]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9316380620002747, 0.06836195290088654, 0.0, 0.0, 0.0, 0.0], [0.9572945833206177, 0.026243582367897034, 0.0164618119597435, 0.0, 0.0, 0.0], [0.9880544543266296, 0.00427332753315568, 0.002954584313556552, 0.004717645235359669, 0.0, 0.0], [0.99403977394104, 0.0009413420339114964, 0.0004739820142276585, 0.00011646930943243206, 0.004428447224199772, 0.0], [0.9806035161018372, 2.5468933017691597e-05, 0.00016239412070717663, 0.0001476418401580304, 0.0013442443450912833, 0.017716845497488976]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.993178129196167, 0.006821857299655676, 0.0, 0.0, 0.0, 0.0], [0.9756524562835693, 0.01318411435931921, 0.011163423769176006, 0.0, 0.0, 0.0], [0.9418966770172119, 0.004721744451671839, 0.0023818055633455515, 0.050999753177165985, 0.0, 0.0], [0.9905040860176086, 0.0022848136723041534, 6.198462506290525e-05, 0.0005984465242363513, 0.006550676189363003, 0.0], [0.9697660207748413, 0.0008878845837898552, 0.00023466735729016364, 0.0017040816601365805, 0.004128355998545885, 0.02327893301844597]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9716231822967529, 0.02837684564292431, 0.0, 0.0, 0.0, 0.0], [0.9223619699478149, 0.028907248750329018, 0.048730745911598206, 0.0, 0.0, 0.0], [0.8426317572593689, 0.023872116580605507, 0.04748132824897766, 0.08601479232311249, 0.0, 0.0], [0.8521121740341187, 0.020744236186146736, 0.04494619369506836, 0.05765002593398094, 0.02454746514558792, 0.0], [0.8800725936889648, 0.022448532283306122, 0.018235722556710243, 0.01925482600927353, 0.015854258090257645, 0.044134121388196945]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9412723779678345, 0.058727629482746124, 0.0, 0.0, 0.0, 0.0], [0.916313886642456, 0.05759201943874359, 0.02609400637447834, 0.0, 0.0, 0.0], [0.8392423391342163, 0.057690516114234924, 0.01382902916520834, 0.08923812955617905, 0.0, 0.0], [0.8987162113189697, 0.0134778693318367, 0.0003456450067460537, 0.003298751311376691, 0.08416149020195007, 0.0], [0.8701692223548889, 0.002700856188312173, 0.00143499206751585, 0.0056661744602024555, 0.08874300867319107, 0.031285665929317474]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9656725525856018, 0.03432750701904297, 0.0, 0.0, 0.0, 0.0], [0.9178615808486938, 0.062257930636405945, 0.019880469888448715, 0.0, 0.0, 0.0], [0.823314905166626, 0.06282395124435425, 0.03670429438352585, 0.07715693861246109, 0.0, 0.0], [0.8501748442649841, 0.03816927224397659, 0.03196492791175842, 0.0516013503074646, 0.02808968350291252, 0.0], [0.6572404503822327, 0.05877397954463959, 0.04336007311940193, 0.09013211727142334, 0.08146599680185318, 0.06902744621038437]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9162061810493469, 0.0837937667965889, 0.0, 0.0, 0.0, 0.0], [0.9451773762702942, 0.04099284112453461, 0.013829832896590233, 0.0, 0.0, 0.0], [0.8928355574607849, 0.05368670076131821, 0.017596954479813576, 0.03588071092963219, 0.0, 0.0], [0.8337052464485168, 0.04799601063132286, 0.033513229340314865, 0.04680858924984932, 0.03797686845064163, 0.0], [0.8167192339897156, 0.06337132304906845, 0.013286277651786804, 0.020469767972826958, 0.025292355567216873, 0.06086111441254616]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9525133371353149, 0.04748663306236267, 0.0, 0.0, 0.0, 0.0], [0.3019869327545166, 0.6520938873291016, 0.04591925069689751, 0.0, 0.0, 0.0], [0.285582959651947, 0.556952178478241, 0.1444743126630783, 0.012990524061024189, 0.0, 0.0], [0.843804121017456, 0.032251205295324326, 0.03954290598630905, 0.06848159432411194, 0.015920041128993034, 0.0], [0.6664940714836121, 0.06095913052558899, 0.04064354673027992, 0.06804485619068146, 0.09186329692602158, 0.07199501991271973]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9682655334472656, 0.031734466552734375, 0.0, 0.0, 0.0, 0.0], [0.738521933555603, 0.22856839001178741, 0.032909639179706573, 0.0, 0.0, 0.0], [0.5946676135063171, 0.2303314357995987, 0.14867636561393738, 0.02632458508014679, 0.0, 0.0], [0.6339254975318909, 0.05813034623861313, 0.09654320776462555, 0.14291946589946747, 0.06848153471946716, 0.0], [0.40375572443008423, 0.08945391327142715, 0.07635112851858139, 0.25587135553359985, 0.1433039754629135, 0.03126389905810356]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9869793653488159, 0.013020593672990799, 0.0, 0.0, 0.0, 0.0], [0.8631385564804077, 0.1105666309595108, 0.02629482001066208, 0.0, 0.0, 0.0], [0.9488080143928528, 0.028614996001124382, 0.006535546388477087, 0.016041526570916176, 0.0, 0.0], [0.9672170877456665, 0.006604980677366257, 0.00045171406236477196, 0.004844417329877615, 0.020881708711385727, 0.0], [0.9354621171951294, 0.02047806605696678, 0.0011700231116265059, 0.007056943140923977, 0.0163181871175766, 0.019514625892043114]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9846673011779785, 0.015332723967730999, 0.0, 0.0, 0.0, 0.0], [0.9052747488021851, 0.08373606950044632, 0.010989243164658546, 0.0, 0.0, 0.0], [0.8145939111709595, 0.04283742979168892, 0.10568301379680634, 0.03688570484519005, 0.0, 0.0], [0.23519809544086456, 0.012018457986414433, 0.05280117318034172, 0.6516180038452148, 0.04836418479681015, 0.0], [0.31818512082099915, 0.018632443621754646, 0.03948190063238144, 0.3755541741847992, 0.20787373185157776, 0.04027257487177849]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9811733365058899, 0.018826685845851898, 0.0, 0.0, 0.0, 0.0], [0.8618939518928528, 0.06479164958000183, 0.07331438362598419, 0.0, 0.0, 0.0], [0.7664540410041809, 0.07330425828695297, 0.10353513062000275, 0.056706514209508896, 0.0, 0.0], [0.8128499984741211, 0.03215480223298073, 0.059005625545978546, 0.05416511744260788, 0.04182446748018265, 0.0], [0.8687856197357178, 0.026987861841917038, 0.02047000452876091, 0.01629738137125969, 0.03218390792608261, 0.03527523949742317]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9264583587646484, 0.07354167848825455, 0.0, 0.0, 0.0, 0.0], [0.8403540849685669, 0.06373751163482666, 0.09590838104486465, 0.0, 0.0, 0.0], [0.7330995798110962, 0.06451118737459183, 0.10380073636770248, 0.09858842939138412, 0.0, 0.0], [0.9143612384796143, 0.008257776498794556, 0.007320381235331297, 0.017966248095035553, 0.05209439620375633, 0.0], [0.8971915245056152, 0.008555498905479908, 0.007019453682005405, 0.014860544353723526, 0.03399762138724327, 0.03837529569864273]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9180347919464111, 0.08196526020765305, 0.0, 0.0, 0.0, 0.0], [0.8328666687011719, 0.1219901517033577, 0.04514322429895401, 0.0, 0.0, 0.0], [0.7994157075881958, 0.0874413549900055, 0.03605784848332405, 0.07708510011434555, 0.0, 0.0], [0.880984902381897, 0.020749641582369804, 0.020554615184664726, 0.017120830714702606, 0.06058995798230171, 0.0], [0.745303213596344, 0.044334057718515396, 0.022549288347363472, 0.0331527441740036, 0.03357058763504028, 0.12109009176492691]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9867060780525208, 0.013293893076479435, 0.0, 0.0, 0.0, 0.0], [0.982177734375, 0.012414131313562393, 0.005408108700066805, 0.0, 0.0, 0.0], [0.9630486369132996, 0.015290752984583378, 0.010345698334276676, 0.0113149369135499, 0.0, 0.0], [0.9213568568229675, 0.014132463373243809, 0.017639216035604477, 0.016567690297961235, 0.030303770676255226, 0.0], [0.9373326301574707, 0.009064299054443836, 0.007548365276306868, 0.006576443091034889, 0.011827622540295124, 0.027650514617562294]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9951004385948181, 0.00489962799474597, 0.0, 0.0, 0.0, 0.0], [0.9476007223129272, 0.041407931596040726, 0.010991275310516357, 0.0, 0.0, 0.0], [0.9142175316810608, 0.023523783311247826, 0.039145033806562424, 0.023113621398806572, 0.0, 0.0], [0.9534738659858704, 0.008932933211326599, 0.015272765420377254, 0.007908251136541367, 0.014412266202270985, 0.0], [0.9427101016044617, 0.00823307130485773, 0.004650997929275036, 0.004178107250481844, 0.005463531706482172, 0.03476419299840927]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9543376564979553, 0.045662373304367065, 0.0, 0.0, 0.0, 0.0], [0.9696040749549866, 0.01954760029911995, 0.01084828469902277, 0.0, 0.0, 0.0], [0.9710449576377869, 0.012425386346876621, 0.008068876340985298, 0.008460716344416142, 0.0, 0.0], [0.9726192951202393, 0.002697656163945794, 0.00044831327977590263, 0.0013814778067171574, 0.022853154689073563, 0.0], [0.9675466418266296, 0.009613442234694958, 0.003203035332262516, 0.00424883933737874, 0.007442260626703501, 0.00794589426368475]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9887008666992188, 0.011299116536974907, 0.0, 0.0, 0.0, 0.0], [0.9382632374763489, 0.04204244911670685, 0.019694412127137184, 0.0, 0.0, 0.0], [0.8351995944976807, 0.03487853705883026, 0.05134471505880356, 0.07857715338468552, 0.0, 0.0], [0.9042676687240601, 0.010541575029492378, 0.016426723450422287, 0.025921987369656563, 0.04284200444817543, 0.0], [0.8913140892982483, 0.00891267228871584, 0.005010711494833231, 0.008175632916390896, 0.013514749705791473, 0.07307209819555283]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8693912029266357, 0.13060881197452545, 0.0, 0.0, 0.0, 0.0], [0.3507988452911377, 0.606351912021637, 0.04284917935729027, 0.0, 0.0, 0.0], [0.35475659370422363, 0.3502019941806793, 0.24722407758235931, 0.04781729355454445, 0.0, 0.0], [0.35370609164237976, 0.03527737781405449, 0.09567111730575562, 0.449796199798584, 0.06554921716451645, 0.0], [0.4132595360279083, 0.09055527299642563, 0.05286579951643944, 0.174679696559906, 0.173848956823349, 0.09479076415300369]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9629756212234497, 0.037024300545454025, 0.0, 0.0, 0.0, 0.0], [0.9756426811218262, 0.01965854875743389, 0.004698706325143576, 0.0, 0.0, 0.0], [0.9775736927986145, 0.013286248780786991, 0.0025590297300368547, 0.006581062916666269, 0.0, 0.0], [0.9870142936706543, 0.007388236932456493, 0.0009579154429957271, 0.0018318220973014832, 0.0028077505994588137, 0.0], [0.9409245848655701, 0.016633737832307816, 0.0022979143541306257, 0.0058906711637973785, 0.0055129327811300755, 0.02874022163450718]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.962827205657959, 0.037172831594944, 0.0, 0.0, 0.0, 0.0], [0.9582237601280212, 0.024641817435622215, 0.017134377732872963, 0.0, 0.0, 0.0], [0.9351300001144409, 0.015331573784351349, 0.014810982160270214, 0.034727465361356735, 0.0, 0.0], [0.9225171208381653, 0.010528750717639923, 0.011010154150426388, 0.01944003626704216, 0.036503832787275314, 0.0], [0.8420165777206421, 0.04357199743390083, 0.007488282397389412, 0.01496153138577938, 0.02385285682976246, 0.06810864061117172]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9926387071609497, 0.00736132962629199, 0.0, 0.0, 0.0, 0.0], [0.9957393407821655, 0.0033469819463789463, 0.000913690309971571, 0.0, 0.0, 0.0], [0.9869900345802307, 0.001974786864593625, 0.001524551771581173, 0.009510699659585953, 0.0, 0.0], [0.9933527708053589, 0.001020324882119894, 0.00034337223041802645, 0.0010291127255186439, 0.004254369530826807, 0.0], [0.9749016761779785, 0.00043480272870510817, 0.0004306558985263109, 0.0012364407302811742, 0.0015347707085311413, 0.021461669355630875]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9897475242614746, 0.010252462700009346, 0.0, 0.0, 0.0, 0.0], [0.9790639281272888, 0.01650906540453434, 0.0044270907528698444, 0.0, 0.0, 0.0], [0.9521436095237732, 0.029432358220219612, 0.008943161927163601, 0.009480923414230347, 0.0, 0.0], [0.939594030380249, 0.021510960534214973, 0.010278552770614624, 0.004555229097604752, 0.024061163887381554, 0.0], [0.9205074906349182, 0.016153652220964432, 0.010818594135344028, 0.01664440892636776, 0.014566398225724697, 0.021309375762939453]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9898501634597778, 0.010149780660867691, 0.0, 0.0, 0.0, 0.0], [0.9820910096168518, 0.006907520350068808, 0.011001535691320896, 0.0, 0.0, 0.0], [0.9684997200965881, 0.008987602777779102, 0.015342563390731812, 0.007170087192207575, 0.0, 0.0], [0.9274120330810547, 0.009485266171395779, 0.022066107019782066, 0.03222890570759773, 0.008807653561234474, 0.0], [0.900665819644928, 0.021623756736516953, 0.013808279298245907, 0.009843860752880573, 0.008521373383700848, 0.04553695768117905]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9954444169998169, 0.004555588588118553, 0.0, 0.0, 0.0, 0.0], [0.995254397392273, 0.002460238989442587, 0.002285485854372382, 0.0, 0.0, 0.0], [0.9862446188926697, 0.0015168144600465894, 0.004072288051247597, 0.008166354149580002, 0.0, 0.0], [0.9889963865280151, 0.001226040069013834, 0.0007996349013410509, 0.0006774227367714047, 0.008300574496388435, 0.0], [0.9865202903747559, 0.00039427157025784254, 0.0009571771952323616, 0.0004954367759637535, 0.0009604979422874749, 0.010672281496226788]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9821295142173767, 0.017870500683784485, 0.0, 0.0, 0.0, 0.0], [0.7489436268806458, 0.22002726793289185, 0.031029189005494118, 0.0, 0.0, 0.0], [0.28547799587249756, 0.21125678718090057, 0.47871601581573486, 0.024549242109060287, 0.0, 0.0], [0.8056644201278687, 0.026974644511938095, 0.04302806034684181, 0.06993705034255981, 0.05439583212137222, 0.0], [0.3307209014892578, 0.022326624020934105, 0.016627125442028046, 0.08019453287124634, 0.41574832797050476, 0.13438253104686737]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9697746634483337, 0.030225319787859917, 0.0, 0.0, 0.0, 0.0], [0.9800565838813782, 0.015018894337117672, 0.004924521781504154, 0.0, 0.0, 0.0], [0.9237861037254333, 0.052764780819416046, 0.00630240747705102, 0.017146753147244453, 0.0, 0.0], [0.9451844096183777, 0.03618047758936882, 0.001989208161830902, 0.003958724904805422, 0.012687299400568008, 0.0], [0.9633325934410095, 0.018662991002202034, 0.0030418417882174253, 0.007070912979543209, 0.0050094155594706535, 0.002882065251469612]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9873244762420654, 0.012675459496676922, 0.0, 0.0, 0.0, 0.0], [0.9904569983482361, 0.0055419523268938065, 0.004001122899353504, 0.0, 0.0, 0.0], [0.9814971685409546, 0.004653455223888159, 0.003725277027115226, 0.010124054737389088, 0.0, 0.0], [0.9744365811347961, 0.004632251337170601, 0.002379992976784706, 0.006518087349832058, 0.012033028528094292, 0.0], [0.9624497294425964, 0.0033743639942258596, 0.0013198587112128735, 0.0017275003483518958, 0.002944675739854574, 0.028183799237012863]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9807674288749695, 0.01923258602619171, 0.0, 0.0, 0.0, 0.0], [0.9664245843887329, 0.015413926914334297, 0.018161438405513763, 0.0, 0.0, 0.0], [0.9632682204246521, 0.004538117907941341, 0.002925391308963299, 0.029268190264701843, 0.0, 0.0], [0.9562349319458008, 0.0012223608791828156, 0.0005304080550558865, 0.00867149606347084, 0.03334089741110802, 0.0], [0.9657101035118103, 0.0009808284230530262, 0.0016686266753822565, 0.002634831238538027, 0.005866361316293478, 0.023139292374253273]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9639716148376465, 0.036028459668159485, 0.0, 0.0, 0.0, 0.0], [0.9562800526618958, 0.03373315557837486, 0.009986846707761288, 0.0, 0.0, 0.0], [0.8539998531341553, 0.08073022216558456, 0.03334445133805275, 0.031925540417432785, 0.0, 0.0], [0.9547491073608398, 0.009605025872588158, 0.004146162886172533, 0.0020133228972554207, 0.029486361891031265, 0.0], [0.9331137537956238, 0.028699662536382675, 0.005477475933730602, 0.006368075497448444, 0.012613046914339066, 0.013728085905313492]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9392993450164795, 0.06070063263177872, 0.0, 0.0, 0.0, 0.0], [0.9298391342163086, 0.061895377933979034, 0.008265496231615543, 0.0, 0.0, 0.0], [0.8471823334693909, 0.09035038203001022, 0.01763608679175377, 0.044831156730651855, 0.0, 0.0], [0.8857703804969788, 0.03918175399303436, 0.007867704145610332, 0.02276589721441269, 0.04441439360380173, 0.0], [0.8563280701637268, 0.10088995099067688, 0.006531452294439077, 0.008485927246510983, 0.007368441205471754, 0.020396249368786812]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8353264331817627, 0.1646735519170761, 0.0, 0.0, 0.0, 0.0], [0.6160858869552612, 0.3137648403644562, 0.07014927268028259, 0.0, 0.0, 0.0], [0.34316325187683105, 0.2758493721485138, 0.1196604073047638, 0.26132699847221375, 0.0, 0.0], [0.5908172130584717, 0.050290752202272415, 0.041665926575660706, 0.2199493646621704, 0.0972767099738121, 0.0], [0.8481413125991821, 0.06318090111017227, 0.014733693562448025, 0.055267371237277985, 0.00901501253247261, 0.009661628864705563]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9627319574356079, 0.03726799786090851, 0.0, 0.0, 0.0, 0.0], [0.7757522463798523, 0.1799626499414444, 0.044285036623477936, 0.0, 0.0, 0.0], [0.6317060589790344, 0.24380716681480408, 0.10925652086734772, 0.015230235643684864, 0.0, 0.0], [0.9539909958839417, 0.018182311207056046, 0.011601822450757027, 0.012299076654016972, 0.003925766795873642, 0.0], [0.40356943011283875, 0.14237558841705322, 0.05661217123270035, 0.1975736767053604, 0.0929921343922615, 0.10687707364559174]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9802619218826294, 0.019738124683499336, 0.0, 0.0, 0.0, 0.0], [0.9873908162117004, 0.007800452411174774, 0.004808681085705757, 0.0, 0.0, 0.0], [0.9283918738365173, 0.008301235735416412, 0.01330565195530653, 0.05000120773911476, 0.0, 0.0], [0.8981055021286011, 0.015591299161314964, 0.010177576914429665, 0.039987027645111084, 0.0361386202275753, 0.0], [0.9753499031066895, 0.00035433052107691765, 0.0005866039427928627, 0.0011877501383423805, 0.0010750899091362953, 0.021446440368890762]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9295330047607422, 0.07046692818403244, 0.0, 0.0, 0.0, 0.0], [0.9361506104469299, 0.04116682708263397, 0.022682538256049156, 0.0, 0.0, 0.0], [0.8486821055412292, 0.05802798643708229, 0.024856165051460266, 0.0684337466955185, 0.0, 0.0], [0.8661180734634399, 0.02232467755675316, 0.010369130410254002, 0.02600197121500969, 0.07518619298934937, 0.0], [0.8074421882629395, 0.044382549822330475, 0.01849711686372757, 0.03357789292931557, 0.018561245873570442, 0.07753907144069672]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9680535197257996, 0.03194643557071686, 0.0, 0.0, 0.0, 0.0], [0.9693689942359924, 0.02568492479622364, 0.004946070723235607, 0.0, 0.0, 0.0], [0.9620568156242371, 0.022552406415343285, 0.005471326876431704, 0.009919456206262112, 0.0, 0.0], [0.9727528095245361, 0.010137127712368965, 0.000757327419705689, 0.0028828983195126057, 0.013469807803630829, 0.0], [0.9624635577201843, 0.0031109037809073925, 0.0010007602395489812, 0.0019475930603221059, 0.008266227319836617, 0.02321087196469307]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8542501330375671, 0.14574992656707764, 0.0, 0.0, 0.0, 0.0], [0.9725967645645142, 0.014116315171122551, 0.01328685600310564, 0.0, 0.0, 0.0], [0.9257621765136719, 0.03257262706756592, 0.01461210660636425, 0.027053095400333405, 0.0, 0.0], [0.7923423051834106, 0.027305101975798607, 0.01880674995481968, 0.13854165375232697, 0.023004096001386642, 0.0], [0.6152060627937317, 0.02665526419878006, 0.029352931305766106, 0.05590886250138283, 0.11611279845237732, 0.15676409006118774]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9804654121398926, 0.019534552469849586, 0.0, 0.0, 0.0, 0.0], [0.9882452487945557, 0.007509466726332903, 0.004245325922966003, 0.0, 0.0, 0.0], [0.9584206938743591, 0.0109635591506958, 0.010456060990691185, 0.020159708335995674, 0.0, 0.0], [0.9604811668395996, 0.007182627450674772, 0.003072339342907071, 0.006898913532495499, 0.02236509881913662, 0.0], [0.966888964176178, 0.0032812939025461674, 0.00550054432824254, 0.004234083462506533, 0.005038043484091759, 0.015057181939482689]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9498194456100464, 0.05018055811524391, 0.0, 0.0, 0.0, 0.0], [0.9781363606452942, 0.016430046409368515, 0.0054335566237568855, 0.0, 0.0, 0.0], [0.8618696331977844, 0.036093585193157196, 0.07555554062128067, 0.026481209322810173, 0.0, 0.0], [0.5449837446212769, 0.015411133877933025, 0.023516526445746422, 0.25743600726127625, 0.15865260362625122, 0.0], [0.9571874737739563, 0.0030803855042904615, 0.0014446862041950226, 0.006861559115350246, 0.014818714000284672, 0.01660723052918911]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6156560778617859, 0.3843439519405365, 0.0, 0.0, 0.0, 0.0], [0.36760634183883667, 0.42816370725631714, 0.20423001050949097, 0.0, 0.0, 0.0], [0.16471554338932037, 0.4136792719364166, 0.2509237229824066, 0.17068152129650116, 0.0, 0.0], [0.4184456169605255, 0.1524762362241745, 0.10305401682853699, 0.11071498692035675, 0.21530911326408386, 0.0], [0.19686934351921082, 0.2014620453119278, 0.12827259302139282, 0.09203246980905533, 0.09167550504207611, 0.2896881103515625]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9027364253997803, 0.09726352989673615, 0.0, 0.0, 0.0, 0.0], [0.9736634492874146, 0.014004302211105824, 0.01233230996876955, 0.0, 0.0, 0.0], [0.8504456281661987, 0.05690572410821915, 0.032060906291007996, 0.06058764085173607, 0.0, 0.0], [0.7661210298538208, 0.03530392050743103, 0.03433045372366905, 0.09675204753875732, 0.06749245524406433, 0.0], [0.8650374412536621, 0.020085260272026062, 0.01149806659668684, 0.01855834573507309, 0.018430285155773163, 0.06639053672552109]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9653082489967346, 0.03469168767333031, 0.0, 0.0, 0.0, 0.0], [0.9816323518753052, 0.014176066033542156, 0.004191514104604721, 0.0, 0.0, 0.0], [0.9275256395339966, 0.04737218841910362, 0.01152826938778162, 0.013573966920375824, 0.0, 0.0], [0.9293117523193359, 0.025833239778876305, 0.007227106485515833, 0.014300585724413395, 0.02332727052271366, 0.0], [0.8895062804222107, 0.04689619690179825, 0.0047171092592179775, 0.006286581978201866, 0.00609014043584466, 0.04650374501943588]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8938026428222656, 0.10619727522134781, 0.0, 0.0, 0.0, 0.0], [0.8221707940101624, 0.06304481625556946, 0.11478441953659058, 0.0, 0.0, 0.0], [0.5047380924224854, 0.15375731885433197, 0.2277037501335144, 0.11380083113908768, 0.0, 0.0], [0.4082071781158447, 0.09066355973482132, 0.11696872115135193, 0.24553199112415314, 0.13862857222557068, 0.0], [0.7291035652160645, 0.06638889014720917, 0.023112818598747253, 0.031103096902370453, 0.057143256068229675, 0.09314827620983124]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9247531890869141, 0.07524678111076355, 0.0, 0.0, 0.0, 0.0], [0.8957376480102539, 0.06989553570747375, 0.03436679765582085, 0.0, 0.0, 0.0], [0.7924937605857849, 0.0960114598274231, 0.05509118735790253, 0.056403566151857376, 0.0, 0.0], [0.7891505360603333, 0.07880303263664246, 0.03840155899524689, 0.05396979674696922, 0.03967496380209923, 0.0], [0.7807856798171997, 0.0799354612827301, 0.042531758546829224, 0.03234211727976799, 0.0178169384598732, 0.046588052064180374]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9480886459350586, 0.05191127583384514, 0.0, 0.0, 0.0, 0.0], [0.863694965839386, 0.04756204038858414, 0.08874296396970749, 0.0, 0.0, 0.0], [0.9341371059417725, 0.022224076092243195, 0.022624483332037926, 0.021014342084527016, 0.0, 0.0], [0.9588143229484558, 0.008020909503102303, 0.004490078426897526, 0.005862293299287558, 0.022812429815530777, 0.0], [0.9385918378829956, 0.021227721124887466, 0.0048724692314863205, 0.010940189473330975, 0.009524582885205746, 0.014843451790511608]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9763734340667725, 0.023626558482646942, 0.0, 0.0, 0.0, 0.0], [0.9884802103042603, 0.005189393647015095, 0.0063303736969828606, 0.0, 0.0, 0.0], [0.9477092027664185, 0.0179851483553648, 0.010156610049307346, 0.024149026721715927, 0.0, 0.0], [0.967192530632019, 0.006552813574671745, 0.0033227826934307814, 0.00556332478299737, 0.017368387430906296, 0.0], [0.9584562182426453, 0.007502961438149214, 0.0051363310776650906, 0.008071648888289928, 0.005997124593704939, 0.014835843816399574]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.884070873260498, 0.11592914164066315, 0.0, 0.0, 0.0, 0.0], [0.9931254386901855, 0.005070806015282869, 0.0018038019770756364, 0.0, 0.0, 0.0], [0.9534159302711487, 0.02382904477417469, 0.007748977281153202, 0.015006075613200665, 0.0, 0.0], [0.9151289463043213, 0.010873105376958847, 0.013190957717597485, 0.011050421744585037, 0.04975655674934387, 0.0], [0.8769673109054565, 0.03385210782289505, 0.00848648976534605, 0.009969149716198444, 0.03468578681349754, 0.036039214581251144]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0003709519514814019, 0.999629020690918, 0.0, 0.0, 0.0, 0.0], [6.525027856696397e-05, 0.3737829029560089, 0.6261518597602844, 0.0, 0.0, 0.0], [4.606018774211407e-05, 0.210508793592453, 0.4115968942642212, 0.3778482675552368, 0.0, 0.0], [4.753069515572861e-05, 0.11616954207420349, 0.23264272511005402, 0.3985331058502197, 0.2526070475578308, 0.0], [1.247641534973809e-06, 0.14819711446762085, 0.15813173353672028, 0.30074331164360046, 0.11939018964767456, 0.27353641390800476]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.971555769443512, 0.028444187715649605, 0.0, 0.0, 0.0, 0.0], [0.9529065489768982, 0.03233075141906738, 0.014762768521904945, 0.0, 0.0, 0.0], [0.9343128204345703, 0.02351292595267296, 0.02049802988767624, 0.021676240488886833, 0.0, 0.0], [0.9529678225517273, 0.00855141133069992, 0.004359325394034386, 0.008064556866884232, 0.026056913658976555, 0.0], [0.9653593897819519, 0.008487647399306297, 0.003499280195683241, 0.002721576252952218, 0.0032828773837536573, 0.016649367287755013]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8630780577659607, 0.13692188262939453, 0.0, 0.0, 0.0, 0.0], [0.7696157097816467, 0.0851333811879158, 0.14525099098682404, 0.0, 0.0, 0.0], [0.7133337259292603, 0.10170899331569672, 0.11931268870830536, 0.06564456224441528, 0.0, 0.0], [0.7186222076416016, 0.05444284901022911, 0.01386815495789051, 0.07808027416467667, 0.13498654961585999, 0.0], [0.7990148663520813, 0.05805593729019165, 0.009447019547224045, 0.017770467326045036, 0.02113853208720684, 0.09457314014434814]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9518988728523254, 0.048101115971803665, 0.0, 0.0, 0.0, 0.0], [0.8580653071403503, 0.02944577857851982, 0.11248888075351715, 0.0, 0.0, 0.0], [0.6577738523483276, 0.08513449877500534, 0.1261308640241623, 0.1309608370065689, 0.0, 0.0], [0.8087368607521057, 0.0323016420006752, 0.01841817982494831, 0.06856140494346619, 0.07198194414377213, 0.0], [0.6683295965194702, 0.13281384110450745, 0.021880635991692543, 0.02787741646170616, 0.04923408478498459, 0.0998644009232521]]]], \"left_text\": [\"No\", \",\", \" I\", \" am\", \" your\", \" father\"], \"right_text\": [\"No\", \",\", \" I\", \" am\", \" your\", \" father\"]}], \"default_filter\": \"0\", \"display_mode\": \"dark\", \"root_div_id\": \"bertviz-fbc5c2e7d0654600999365aa5a3d8d2c\", \"include_layers\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], \"include_heads\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], \"total_heads\": 12}; // HACK: {\"attention\": [{\"name\": null, \"attn\": [[[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.961219847202301, 0.038780149072408676, 0.0, 0.0, 0.0, 0.0], [0.7466979026794434, 0.11987314373254776, 0.1334289014339447, 0.0, 0.0, 0.0], [0.5885030031204224, 0.13792067766189575, 0.212137371301651, 0.06143897399306297, 0.0, 0.0], [0.6570857763290405, 0.08996301889419556, 0.12751281261444092, 0.08361563086509705, 0.041822850704193115, 0.0], [0.2728874385356903, 0.11203353852033615, 0.1663985401391983, 0.08467111736536026, 0.16952736675739288, 0.19448210299015045]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010616563260555267, 0.9893833994865417, 0.0, 0.0, 0.0, 0.0], [0.0024677535984665155, 0.008448007516562939, 0.9890841841697693, 0.0, 0.0, 0.0], [0.0001232847134815529, 0.0018733182223513722, 0.013126976788043976, 0.9848763942718506, 0.0, 0.0], [0.0010669564362615347, 0.001136627048254013, 0.003034998197108507, 0.0015735096530988812, 0.9931879043579102, 0.0], [0.00019791982776951045, 0.0010528112761676311, 0.0015437351539731026, 0.0009642760851420462, 3.4924432839034125e-05, 0.9962062835693359]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.47578439116477966, 0.524215579032898, 0.0, 0.0, 0.0, 0.0], [0.5906045436859131, 0.2486611008644104, 0.16073434054851532, 0.0, 0.0, 0.0], [0.5529289841651917, 0.18856702744960785, 0.14457571506500244, 0.11392831057310104, 0.0, 0.0], [0.45094072818756104, 0.16486799716949463, 0.17318038642406464, 0.11748014390468597, 0.09353074431419373, 0.0], [0.4257245659828186, 0.1732865273952484, 0.15651953220367432, 0.07022649794816971, 0.0808701142668724, 0.09337282180786133]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6133623123168945, 0.38663768768310547, 0.0, 0.0, 0.0, 0.0], [0.06098509579896927, 0.03253461793065071, 0.9064802527427673, 0.0, 0.0, 0.0], [0.006717085838317871, 0.0004012881254311651, 0.7572958469390869, 0.23558568954467773, 0.0, 0.0], [0.03722766041755676, 0.002948855282738805, 0.10081092268228531, 0.04142269119620323, 0.8175898790359497, 0.0], [0.04989781975746155, 0.00030758307548239827, 0.0024198265746235847, 0.0034334994852542877, 0.0006823898293077946, 0.9432588815689087]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9489555954933167, 0.051044441759586334, 0.0, 0.0, 0.0, 0.0], [0.6821408867835999, 0.1395241767168045, 0.17833495140075684, 0.0, 0.0, 0.0], [0.20366324484348297, 0.05641487240791321, 0.06399301439523697, 0.6759288311004639, 0.0, 0.0], [0.3419547975063324, 0.06725440919399261, 0.07926183938980103, 0.1783619523048401, 0.3331669867038727, 0.0], [0.09464015811681747, 0.0074282134883105755, 0.006983973551541567, 0.0071843694895505905, 0.018724264577031136, 0.865039050579071]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.33834606409072876, 0.6616539359092712, 0.0, 0.0, 0.0, 0.0], [0.07855993509292603, 0.006165449041873217, 0.9152746200561523, 0.0, 0.0, 0.0], [0.01677597686648369, 0.0004037705948576331, 0.003340460592880845, 0.9794798493385315, 0.0, 0.0], [0.027600426226854324, 0.00044415233423933387, 0.0006541680195368826, 0.0002266185765620321, 0.971074640750885, 0.0], [0.010248198173940182, 3.701553578139283e-05, 0.00016064041119534522, 2.7341819077264518e-05, 1.0187304724240676e-05, 0.98951655626297]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.982503354549408, 0.017496665939688683, 0.0, 0.0, 0.0, 0.0], [0.8874197006225586, 0.05467939004302025, 0.05790085718035698, 0.0, 0.0, 0.0], [0.6849910616874695, 0.1228068619966507, 0.04972026124596596, 0.14248186349868774, 0.0, 0.0], [0.6015856862068176, 0.09881888329982758, 0.07070108503103256, 0.16652540862560272, 0.06236903741955757, 0.0], [0.3232504427433014, 0.12567411363124847, 0.04432179778814316, 0.07076980918645859, 0.06606649607419968, 0.36991727352142334]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9191647171974182, 0.0808352455496788, 0.0, 0.0, 0.0, 0.0], [0.45986413955688477, 0.39703112840652466, 0.14310479164123535, 0.0, 0.0, 0.0], [0.3003872334957123, 0.22181738913059235, 0.38161516189575195, 0.09618020057678223, 0.0, 0.0], [0.18963925540447235, 0.1376371532678604, 0.20173484086990356, 0.23632164299488068, 0.23466713726520538, 0.0], [0.15410441160202026, 0.09489496797323227, 0.11902562528848648, 0.10277965664863586, 0.4317220449447632, 0.09747327119112015]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.364999920129776, 0.6350001096725464, 0.0, 0.0, 0.0, 0.0], [0.24595215916633606, 0.5519201755523682, 0.20212766528129578, 0.0, 0.0, 0.0], [0.2721358835697174, 0.40738627314567566, 0.25186213850975037, 0.06861574947834015, 0.0, 0.0], [0.10242555290460587, 0.16683615744113922, 0.524804949760437, 0.05445462837815285, 0.15147870779037476, 0.0], [0.25029507279396057, 0.22198128700256348, 0.18899968266487122, 0.10677118599414825, 0.1303267478942871, 0.10162602365016937]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6990506649017334, 0.3009493350982666, 0.0, 0.0, 0.0, 0.0], [0.5107942819595337, 0.2948642075061798, 0.1943415403366089, 0.0, 0.0, 0.0], [0.4604707360267639, 0.2805190980434418, 0.19174803793430328, 0.0672621801495552, 0.0, 0.0], [0.37648412585258484, 0.21120662987232208, 0.20214538276195526, 0.10207021236419678, 0.10809355974197388, 0.0], [0.30138441920280457, 0.20456179976463318, 0.18250338733196259, 0.11019382625818253, 0.1629127413034439, 0.03844383731484413]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7131582498550415, 0.2868417799472809, 0.0, 0.0, 0.0, 0.0], [0.4058799147605896, 0.18063297867774963, 0.41348710656166077, 0.0, 0.0, 0.0], [0.265546053647995, 0.1698586493730545, 0.3358593285083771, 0.228736013174057, 0.0, 0.0], [0.31385406851768494, 0.1831669807434082, 0.14928358793258667, 0.05377671495079994, 0.29991865158081055, 0.0], [0.20466560125350952, 0.18731118738651276, 0.15959151089191437, 0.06381776183843613, 0.03642302006483078, 0.34819093346595764]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6586242914199829, 0.3413757383823395, 0.0, 0.0, 0.0, 0.0], [0.5917776226997375, 0.3160035014152527, 0.0922188088297844, 0.0, 0.0, 0.0], [0.5477152466773987, 0.23586955666542053, 0.061456020921468735, 0.1549593061208725, 0.0, 0.0], [0.4587061107158661, 0.22439992427825928, 0.07887422293424606, 0.0992034301161766, 0.13881628215312958, 0.0], [0.32743722200393677, 0.19600819051265717, 0.068057119846344, 0.0892510637640953, 0.11618079245090485, 0.20306548476219177]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9961552023887634, 0.0038448425475507975, 0.0, 0.0, 0.0, 0.0], [0.8594854474067688, 0.06906110048294067, 0.07145342975854874, 0.0, 0.0, 0.0], [0.3800053000450134, 0.04127567633986473, 0.5496612787246704, 0.029057776555418968, 0.0, 0.0], [0.21445226669311523, 0.05088742449879646, 0.4317440092563629, 0.25869303941726685, 0.044223275035619736, 0.0], [0.11175256222486496, 0.017593080177903175, 0.027507441118359566, 0.04086771607398987, 0.7754669785499573, 0.026812179014086723]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9285967946052551, 0.07140326499938965, 0.0, 0.0, 0.0, 0.0], [0.6077286005020142, 0.3121427297592163, 0.08012867718935013, 0.0, 0.0, 0.0], [0.4942909777164459, 0.28503698110580444, 0.11849315464496613, 0.10217894613742828, 0.0, 0.0], [0.4183879494667053, 0.23117904365062714, 0.0834062322974205, 0.11365949362516403, 0.1533672958612442, 0.0], [0.42215850949287415, 0.12917140126228333, 0.08740927278995514, 0.1016375944018364, 0.21230268478393555, 0.04732053726911545]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9786475896835327, 0.02135237120091915, 0.0, 0.0, 0.0, 0.0], [0.7749121785163879, 0.06510371714830399, 0.15998409688472748, 0.0, 0.0, 0.0], [0.6484923362731934, 0.07483134418725967, 0.14751605689525604, 0.12916021049022675, 0.0, 0.0], [0.5224639773368835, 0.06921815127134323, 0.13823404908180237, 0.1110658198595047, 0.15901805460453033, 0.0], [0.3964517116546631, 0.07325823605060577, 0.12938153743743896, 0.1064242571592331, 0.14864002168178558, 0.1458442211151123]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5525906085968018, 0.44740936160087585, 0.0, 0.0, 0.0, 0.0], [0.5585009455680847, 0.2176259458065033, 0.22387312352657318, 0.0, 0.0, 0.0], [0.5143128633499146, 0.15964674949645996, 0.15491968393325806, 0.1711207628250122, 0.0, 0.0], [0.5039961338043213, 0.11401888728141785, 0.11974027007818222, 0.12552587687969208, 0.13671889901161194, 0.0], [0.5061842799186707, 0.08567393571138382, 0.08903021365404129, 0.09759818762540817, 0.1027572825551033, 0.11875619739294052]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9242545366287231, 0.07574543356895447, 0.0, 0.0, 0.0, 0.0], [0.8257425427436829, 0.07932533323764801, 0.09493216127157211, 0.0, 0.0, 0.0], [0.7306380271911621, 0.0857183039188385, 0.08043931424617767, 0.10320431739091873, 0.0, 0.0], [0.6383238434791565, 0.07886394113302231, 0.07815027981996536, 0.08758097141981125, 0.1170809343457222, 0.0], [0.5552157163619995, 0.07409121096134186, 0.06834889203310013, 0.07778600603342056, 0.09999319165945053, 0.12456497550010681]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8578913807868958, 0.14210854470729828, 0.0, 0.0, 0.0, 0.0], [0.6423038244247437, 0.166290283203125, 0.19140593707561493, 0.0, 0.0, 0.0], [0.5530979633331299, 0.10609274357557297, 0.07821257412433624, 0.26259663701057434, 0.0, 0.0], [0.40121692419052124, 0.12223611027002335, 0.1934729963541031, 0.14164622128009796, 0.14142780005931854, 0.0], [0.40212565660476685, 0.18450751900672913, 0.07516805827617645, 0.05849048122763634, 0.1444634348154068, 0.13524490594863892]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9791558980941772, 0.020844051614403725, 0.0, 0.0, 0.0, 0.0], [0.8829841613769531, 0.06233249977231026, 0.05468335747718811, 0.0, 0.0, 0.0], [0.8105455040931702, 0.08617085963487625, 0.07321777194738388, 0.03006584383547306, 0.0, 0.0], [0.6819812059402466, 0.04990820586681366, 0.08296552300453186, 0.08369525521993637, 0.10144983977079391, 0.0], [0.4056689441204071, 0.07337666302919388, 0.08601408451795578, 0.061709366738796234, 0.13226434588432312, 0.2409665435552597]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9670190811157227, 0.03298088163137436, 0.0, 0.0, 0.0, 0.0], [0.8449064493179321, 0.0851450264453888, 0.06994850933551788, 0.0, 0.0, 0.0], [0.7123572826385498, 0.07896047830581665, 0.055410757660865784, 0.15327158570289612, 0.0, 0.0], [0.6402613520622253, 0.0739755630493164, 0.044393062591552734, 0.14322125911712646, 0.09814881533384323, 0.0], [0.5073903799057007, 0.07523059099912643, 0.07754647731781006, 0.11362491548061371, 0.13947951793670654, 0.08672808855772018]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8487569093704224, 0.1512431502342224, 0.0, 0.0, 0.0, 0.0], [0.8415648937225342, 0.12107233703136444, 0.03736274689435959, 0.0, 0.0, 0.0], [0.7505517601966858, 0.11348944902420044, 0.06179959326982498, 0.07415912300348282, 0.0, 0.0], [0.6614719033241272, 0.10242646187543869, 0.052934251725673676, 0.07529708743095398, 0.10787025839090347, 0.0], [0.6014202237129211, 0.11340376734733582, 0.05631929263472557, 0.07096721231937408, 0.10906282067298889, 0.04882663115859032]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9445484280586243, 0.05545158311724663, 0.0, 0.0, 0.0, 0.0], [0.8874568939208984, 0.05474215745925903, 0.0578010231256485, 0.0, 0.0, 0.0], [0.8281888961791992, 0.06895001977682114, 0.059034693986177444, 0.0438263975083828, 0.0, 0.0], [0.6429892778396606, 0.0674755647778511, 0.11629703640937805, 0.05417950078845024, 0.11905858665704727, 0.0], [0.7367823719978333, 0.056119054555892944, 0.06857288628816605, 0.034219540655612946, 0.0787537544965744, 0.02555238828063011]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0002913394710049033, 0.9997085928916931, 0.0, 0.0, 0.0, 0.0], [0.0007981209782883525, 0.5288336873054504, 0.4703682065010071, 0.0, 0.0, 0.0], [0.0007648481405340135, 0.34519824385643005, 0.3085267245769501, 0.34551018476486206, 0.0, 0.0], [0.0010283143492415547, 0.241359144449234, 0.23320138454437256, 0.2555713355541229, 0.2688397467136383, 0.0], [0.0009746829164214432, 0.17789699137210846, 0.16743157804012299, 0.1858760118484497, 0.18734444677829742, 0.28047630190849304]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.824492871761322, 0.17550717294216156, 0.0, 0.0, 0.0, 0.0], [0.12386877834796906, 0.044499922543764114, 0.8316312432289124, 0.0, 0.0, 0.0], [0.07924355566501617, 0.01296587660908699, 0.0015277155907824636, 0.9062628149986267, 0.0, 0.0], [0.08806384354829788, 0.0213409923017025, 0.0028886159416288137, 0.002845379989594221, 0.884861171245575, 0.0], [0.09983218461275101, 0.03363388776779175, 0.0054999832063913345, 0.002433052286505699, 0.0015082412865012884, 0.8570926189422607]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9646892547607422, 0.03531072288751602, 0.0, 0.0, 0.0, 0.0], [0.7529157400131226, 0.08733473718166351, 0.15974950790405273, 0.0, 0.0, 0.0], [0.4202282726764679, 0.09195102006196976, 0.23549850285053253, 0.25232216715812683, 0.0, 0.0], [0.30848920345306396, 0.05908140912652016, 0.38391315937042236, 0.15659146010875702, 0.09192468225955963, 0.0], [0.44790443778038025, 0.04329312965273857, 0.0796918049454689, 0.11081931740045547, 0.22124572098255157, 0.09704558551311493]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.991096019744873, 0.008904009126126766, 0.0, 0.0, 0.0, 0.0], [0.9697675704956055, 0.026084503158926964, 0.004147922620177269, 0.0, 0.0, 0.0], [0.9082901477813721, 0.033206019550561905, 0.00942116230726242, 0.049082688987255096, 0.0, 0.0], [0.8949133157730103, 0.05544555187225342, 0.005577624775469303, 0.03150692582130432, 0.012556522153317928, 0.0], [0.8497740030288696, 0.028890123590826988, 0.0036647915840148926, 0.03751987963914871, 0.038427725434303284, 0.04172350466251373]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9984525442123413, 0.0015474462416023016, 0.0, 0.0, 0.0, 0.0], [0.48947831988334656, 0.4812193810939789, 0.029302269220352173, 0.0, 0.0, 0.0], [0.11772153526544571, 0.13121186196804047, 0.6702314615249634, 0.08083520829677582, 0.0, 0.0], [0.13043689727783203, 0.04068669304251671, 0.2652038037776947, 0.4114362895488739, 0.15223638713359833, 0.0], [0.12661904096603394, 0.03275119513273239, 0.03567872568964958, 0.06039190664887428, 0.6021825075149536, 0.1423766165971756]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9805176854133606, 0.019482342526316643, 0.0, 0.0, 0.0, 0.0], [0.7948849201202393, 0.12061909586191177, 0.08449601382017136, 0.0, 0.0, 0.0], [0.5612356066703796, 0.15743127465248108, 0.20339730381965637, 0.0779358446598053, 0.0, 0.0], [0.42583736777305603, 0.10742014646530151, 0.15123659372329712, 0.08755031228065491, 0.22795552015304565, 0.0], [0.24752654135227203, 0.024188270792365074, 0.03039524517953396, 0.08586956560611725, 0.5714336633682251, 0.040586672723293304]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9887767434120178, 0.011223225854337215, 0.0, 0.0, 0.0, 0.0], [0.7572693228721619, 0.22317346930503845, 0.019557112827897072, 0.0, 0.0, 0.0], [0.5341880321502686, 0.22107566893100739, 0.1762184202671051, 0.06851787120103836, 0.0, 0.0], [0.17095312476158142, 0.0822940468788147, 0.576022207736969, 0.11097585409879684, 0.059754710644483566, 0.0], [0.2487109899520874, 0.08880793303251266, 0.08980197459459305, 0.09729334712028503, 0.4413093626499176, 0.03407646715641022]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8422133326530457, 0.15778663754463196, 0.0, 0.0, 0.0, 0.0], [0.468412846326828, 0.46105360984802246, 0.07053359597921371, 0.0, 0.0, 0.0], [0.2588140666484833, 0.4635888636112213, 0.18503506481647491, 0.09256205707788467, 0.0, 0.0], [0.18399578332901, 0.29154160618782043, 0.17031098902225494, 0.27173006534576416, 0.08242159336805344, 0.0], [0.1646990180015564, 0.2472696155309677, 0.08770562708377838, 0.22575001418590546, 0.1774536371231079, 0.09712201356887817]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9919946193695068, 0.008005390875041485, 0.0, 0.0, 0.0, 0.0], [0.9068724513053894, 0.044065121561288834, 0.04906242713332176, 0.0, 0.0, 0.0], [0.8582221865653992, 0.055348269641399384, 0.040419407188892365, 0.046010036021471024, 0.0, 0.0], [0.7855252623558044, 0.041242364794015884, 0.08369296044111252, 0.04887620359659195, 0.040663279592990875, 0.0], [0.7856317162513733, 0.05014643445611, 0.04751267284154892, 0.027365952730178833, 0.05614755302667618, 0.03319567069411278]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9041035175323486, 0.09589648246765137, 0.0, 0.0, 0.0, 0.0], [0.5862312912940979, 0.07199832051992416, 0.34177035093307495, 0.0, 0.0, 0.0], [0.3878960907459259, 0.04660807177424431, 0.20278996229171753, 0.36270591616630554, 0.0, 0.0], [0.2665242552757263, 0.024533024057745934, 0.12211935967206955, 0.20041218400001526, 0.386411190032959, 0.0], [0.23357485234737396, 0.02053728699684143, 0.09610321372747421, 0.13062246143817902, 0.22990450263023376, 0.289257675409317]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9639912247657776, 0.036008793860673904, 0.0, 0.0, 0.0, 0.0], [0.7075552344322205, 0.2542775869369507, 0.038167137652635574, 0.0, 0.0, 0.0], [0.2566526234149933, 0.20589298009872437, 0.01665665954351425, 0.5207977294921875, 0.0, 0.0], [0.1037939190864563, 0.04639088362455368, 0.008698614314198494, 0.7866851687431335, 0.05443140119314194, 0.0], [0.2214341163635254, 0.03379744663834572, 0.029023902490735054, 0.541292130947113, 0.15286092460155487, 0.021591555327177048]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9891703724861145, 0.010829661041498184, 0.0, 0.0, 0.0, 0.0], [0.7913155555725098, 0.12309625744819641, 0.08558809012174606, 0.0, 0.0, 0.0], [0.2954600155353546, 0.15808308124542236, 0.4217240810394287, 0.1247328370809555, 0.0, 0.0], [0.23440983891487122, 0.09886523336172104, 0.33160170912742615, 0.1971396654844284, 0.1379835456609726, 0.0], [0.19728390872478485, 0.05741839483380318, 0.06909029185771942, 0.16469819843769073, 0.2797277867794037, 0.23178131878376007]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9359127879142761, 0.0640871673822403, 0.0, 0.0, 0.0, 0.0], [0.7888627648353577, 0.08673475682735443, 0.12440246343612671, 0.0, 0.0, 0.0], [0.6535118818283081, 0.07573551684617996, 0.09732568264007568, 0.17342689633369446, 0.0, 0.0], [0.522276759147644, 0.058278825134038925, 0.09920477122068405, 0.17020836472511292, 0.15003129839897156, 0.0], [0.4108840823173523, 0.047306034713983536, 0.07265672832727432, 0.10560744255781174, 0.10550004243850708, 0.25804558396339417]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9683833122253418, 0.03161672502756119, 0.0, 0.0, 0.0, 0.0], [0.8965396881103516, 0.038870569318532944, 0.06458976864814758, 0.0, 0.0, 0.0], [0.8264952898025513, 0.03213464096188545, 0.05196719989180565, 0.0894029513001442, 0.0, 0.0], [0.7718173265457153, 0.030402837321162224, 0.045827414840459824, 0.07118473201990128, 0.08076759427785873, 0.0], [0.7292331457138062, 0.021699821576476097, 0.033074747771024704, 0.04720093309879303, 0.06474557518959045, 0.10404567420482635]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9979567527770996, 0.0020432830788195133, 0.0, 0.0, 0.0, 0.0], [0.955294132232666, 0.00802531372755766, 0.03668047487735748, 0.0, 0.0, 0.0], [0.9254710078239441, 0.002755576279014349, 0.0020629852078855038, 0.06971040368080139, 0.0, 0.0], [0.8660576939582825, 0.0038883681409060955, 0.0006785982404835522, 0.0006981453043408692, 0.1286771297454834, 0.0], [0.8455929160118103, 0.0037804055027663708, 0.000253423087997362, 6.0270751419011503e-05, 0.00011820747749879956, 0.15019479393959045]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9262455105781555, 0.07375453412532806, 0.0, 0.0, 0.0, 0.0], [0.7717157006263733, 0.16241952776908875, 0.06586471945047379, 0.0, 0.0, 0.0], [0.8167637586593628, 0.07807160913944244, 0.06324034929275513, 0.041924238204956055, 0.0, 0.0], [0.6867184638977051, 0.07755157351493835, 0.10056912153959274, 0.05955080687999725, 0.07561002671718597, 0.0], [0.6421161890029907, 0.11014898866415024, 0.07688194513320923, 0.054033469408750534, 0.10333634912967682, 0.013483096845448017]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9395954608917236, 0.060404520481824875, 0.0, 0.0, 0.0, 0.0], [0.23004619777202606, 0.6617380380630493, 0.1082158014178276, 0.0, 0.0, 0.0], [0.2670227289199829, 0.3607950508594513, 0.3249626159667969, 0.047219593077898026, 0.0, 0.0], [0.595201313495636, 0.12269274890422821, 0.06302059441804886, 0.08916817605495453, 0.12991715967655182, 0.0], [0.10284596681594849, 0.02938011661171913, 0.013739082030951977, 0.045860596001148224, 0.7698501348495483, 0.03832406550645828]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9040980935096741, 0.09590194374322891, 0.0, 0.0, 0.0, 0.0], [0.357237845659256, 0.6274612545967102, 0.015300876460969448, 0.0, 0.0, 0.0], [0.5917996764183044, 0.2764042019844055, 0.10476048290729523, 0.027035649865865707, 0.0, 0.0], [0.7254403829574585, 0.04983152449131012, 0.014982940629124641, 0.1778142899274826, 0.031930916011333466, 0.0], [0.7612743973731995, 0.06158972904086113, 0.005942251533269882, 0.01642685756087303, 0.1267806589603424, 0.0279861893504858]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9947587847709656, 0.005241230130195618, 0.0, 0.0, 0.0, 0.0], [0.9632415771484375, 0.017816413193941116, 0.018942030146718025, 0.0, 0.0, 0.0], [0.9671078324317932, 0.008509586565196514, 0.00856222677975893, 0.015820473432540894, 0.0, 0.0], [0.9340996146202087, 0.011952387169003487, 0.02018021047115326, 0.02675083465874195, 0.0070168930105865, 0.0], [0.9587237238883972, 0.004657115787267685, 0.003326789475977421, 0.006545313633978367, 0.010182461701333523, 0.016564540565013885]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9769991040229797, 0.023000910878181458, 0.0, 0.0, 0.0, 0.0], [0.7917609214782715, 0.1753319948911667, 0.032907065004110336, 0.0, 0.0, 0.0], [0.7949192523956299, 0.10531841963529587, 0.040218502283096313, 0.05954383686184883, 0.0, 0.0], [0.7097718715667725, 0.10552527755498886, 0.06597573310136795, 0.05765606462955475, 0.061070989817380905, 0.0], [0.7506601214408875, 0.026514461264014244, 0.021576043218374252, 0.034296683967113495, 0.08494450151920319, 0.08200812339782715]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.983751654624939, 0.016248304396867752, 0.0, 0.0, 0.0, 0.0], [0.5615494847297668, 0.08956841379404068, 0.3488820493221283, 0.0, 0.0, 0.0], [0.32929039001464844, 0.024114903062582016, 0.5428059697151184, 0.10378880053758621, 0.0, 0.0], [0.34330207109451294, 0.01308644749224186, 0.5121983289718628, 0.11146228760480881, 0.019950881600379944, 0.0], [0.4792812764644623, 0.01733359508216381, 0.1180536150932312, 0.06130281835794449, 0.20071913301944733, 0.12330964207649231]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9908847212791443, 0.009115329943597317, 0.0, 0.0, 0.0, 0.0], [0.5282707214355469, 0.3292262554168701, 0.1425030380487442, 0.0, 0.0, 0.0], [0.48788541555404663, 0.23368670046329498, 0.17578084766864777, 0.10264702141284943, 0.0, 0.0], [0.31444698572158813, 0.18065163493156433, 0.168714240193367, 0.09506598114967346, 0.24112118780612946, 0.0], [0.5168765187263489, 0.035897161811590195, 0.026188155636191368, 0.04039734974503517, 0.18791745603084564, 0.1927233189344406]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8750308156013489, 0.12496919929981232, 0.0, 0.0, 0.0, 0.0], [0.4550614655017853, 0.4900427758693695, 0.05489582195878029, 0.0, 0.0, 0.0], [0.2933720052242279, 0.5449907183647156, 0.09444297850131989, 0.06719419360160828, 0.0, 0.0], [0.489708811044693, 0.2720997631549835, 0.06861965358257294, 0.14694802463054657, 0.022623788565397263, 0.0], [0.4729066491127014, 0.08103099465370178, 0.016052134335041046, 0.30672287940979004, 0.10120721161365509, 0.022080255672335625]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9630220532417297, 0.03697792813181877, 0.0, 0.0, 0.0, 0.0], [0.7557195425033569, 0.16436372697353363, 0.07991670072078705, 0.0, 0.0, 0.0], [0.6947705745697021, 0.08409853279590607, 0.0638260766863823, 0.15730486810207367, 0.0, 0.0], [0.5821147561073303, 0.03297805413603783, 0.07936596870422363, 0.19441406428813934, 0.11112712323665619, 0.0], [0.5974540710449219, 0.04261096194386482, 0.06919723749160767, 0.14563441276550293, 0.12481734901666641, 0.020285936072468758]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9957822561264038, 0.004217816516757011, 0.0, 0.0, 0.0, 0.0], [0.9312832951545715, 0.010560247115790844, 0.05815650522708893, 0.0, 0.0, 0.0], [0.8435326814651489, 0.015695005655288696, 0.045751139521598816, 0.09502115100622177, 0.0, 0.0], [0.772409975528717, 0.011981245130300522, 0.03504609689116478, 0.03876771405339241, 0.14179500937461853, 0.0], [0.7642908692359924, 0.009868789464235306, 0.00812275055795908, 0.013314393348991871, 0.04824395477771759, 0.15615922212600708]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9701177477836609, 0.02988232672214508, 0.0, 0.0, 0.0, 0.0], [0.6564007997512817, 0.22506150603294373, 0.11853761970996857, 0.0, 0.0, 0.0], [0.6958062648773193, 0.14701850712299347, 0.07145983725786209, 0.08571550250053406, 0.0, 0.0], [0.6353274583816528, 0.1346064656972885, 0.030994214117527008, 0.056916315108537674, 0.1421555131673813, 0.0], [0.6779401898384094, 0.053654152899980545, 0.01800631172955036, 0.06284520775079727, 0.1103820651769638, 0.07717210054397583]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9822334051132202, 0.017766647040843964, 0.0, 0.0, 0.0, 0.0], [0.9037663340568542, 0.06541544198989868, 0.03081829659640789, 0.0, 0.0, 0.0], [0.8119193911552429, 0.03679030388593674, 0.060560714453458786, 0.09072960168123245, 0.0, 0.0], [0.40546438097953796, 0.10383912175893784, 0.10211236774921417, 0.35434210300445557, 0.03424208238720894, 0.0], [0.22824221849441528, 0.017278727144002914, 0.05055465176701546, 0.6015752553939819, 0.09411764144897461, 0.008231506682932377]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9873148202896118, 0.012685136869549751, 0.0, 0.0, 0.0, 0.0], [0.35445743799209595, 0.5317603349685669, 0.11378221958875656, 0.0, 0.0, 0.0], [0.07823363691568375, 0.7221359014511108, 0.10936623811721802, 0.090264230966568, 0.0, 0.0], [0.21967869997024536, 0.4048435091972351, 0.12358088046312332, 0.20018866658210754, 0.051708199083805084, 0.0], [0.36089760065078735, 0.10459021478891373, 0.06983799487352371, 0.2976483404636383, 0.13869903981685638, 0.02832675166428089]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9732162356376648, 0.0267837755382061, 0.0, 0.0, 0.0, 0.0], [0.9167553782463074, 0.061452705413103104, 0.02179192565381527, 0.0, 0.0, 0.0], [0.8543081283569336, 0.08049600571393967, 0.030334919691085815, 0.03486092761158943, 0.0, 0.0], [0.8919214606285095, 0.04280779883265495, 0.022045055404305458, 0.023470671847462654, 0.01975487545132637, 0.0], [0.8116763234138489, 0.03413533419370651, 0.03567665070295334, 0.04748587682843208, 0.0253971628844738, 0.04562860727310181]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9502761960029602, 0.04972382262349129, 0.0, 0.0, 0.0, 0.0], [0.7637454271316528, 0.2007361352443695, 0.03551840782165527, 0.0, 0.0, 0.0], [0.6279097199440002, 0.03768139332532883, 0.1994536966085434, 0.13495522737503052, 0.0, 0.0], [0.6397060751914978, 0.027007432654500008, 0.09082036465406418, 0.20653828978538513, 0.03592785820364952, 0.0], [0.4559425115585327, 0.021641194820404053, 0.12939567863941193, 0.21800927817821503, 0.10379841923713684, 0.07121295481920242]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9498406648635864, 0.050159383565187454, 0.0, 0.0, 0.0, 0.0], [0.8688724637031555, 0.0872218981385231, 0.043905653059482574, 0.0, 0.0, 0.0], [0.6937950253486633, 0.06359200924634933, 0.091790571808815, 0.15082231163978577, 0.0, 0.0], [0.7266597151756287, 0.04389883577823639, 0.04683985933661461, 0.09851823002099991, 0.08408336341381073, 0.0], [0.7848998308181763, 0.037147827446460724, 0.012907838448882103, 0.01053939200937748, 0.12079165875911713, 0.03371351957321167]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9891054034233093, 0.01089458167552948, 0.0, 0.0, 0.0, 0.0], [0.8929519653320312, 0.08700055629014969, 0.02004752680659294, 0.0, 0.0, 0.0], [0.7891124486923218, 0.09797251224517822, 0.08633202314376831, 0.026582980528473854, 0.0, 0.0], [0.8850635886192322, 0.03645012155175209, 0.05395457148551941, 0.01237727515399456, 0.012154522351920605, 0.0], [0.6861329674720764, 0.05720378831028938, 0.011636304669082165, 0.021660611033439636, 0.1748800277709961, 0.048486363142728806]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9396191835403442, 0.06038080155849457, 0.0, 0.0, 0.0, 0.0], [0.7851794958114624, 0.19751444458961487, 0.017306052148342133, 0.0, 0.0, 0.0], [0.7660509943962097, 0.15444670617580414, 0.03188290074467659, 0.04761936888098717, 0.0, 0.0], [0.703522801399231, 0.05171430483460426, 0.07760990411043167, 0.1533905267715454, 0.013762423768639565, 0.0], [0.7121888399124146, 0.04994234815239906, 0.03772548958659172, 0.08649132400751114, 0.06541401147842407, 0.04823806509375572]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.974072277545929, 0.025927715003490448, 0.0, 0.0, 0.0, 0.0], [0.792539656162262, 0.01171559002250433, 0.19574476778507233, 0.0, 0.0, 0.0], [0.5106770992279053, 0.007296787109225988, 0.039619915187358856, 0.4424062669277191, 0.0, 0.0], [0.5862472057342529, 0.012099712155759335, 0.024585209786891937, 0.06737840175628662, 0.30968940258026123, 0.0], [0.30196306109428406, 0.007724012713879347, 0.011518122628331184, 0.046947259455919266, 0.22146707773208618, 0.41038045287132263]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9744554162025452, 0.02554464340209961, 0.0, 0.0, 0.0, 0.0], [0.9769195318222046, 0.015048524364829063, 0.008031901903450489, 0.0, 0.0, 0.0], [0.9060619473457336, 0.025875424966216087, 0.025954782962799072, 0.04210779070854187, 0.0, 0.0], [0.9400081038475037, 0.00555665697902441, 0.005828304681926966, 0.031757812947034836, 0.016849134117364883, 0.0], [0.9105738401412964, 0.0019752182997763157, 0.008646721951663494, 0.013360846787691116, 0.03543964773416519, 0.030003678053617477]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9791666865348816, 0.020833350718021393, 0.0, 0.0, 0.0, 0.0], [0.8444858193397522, 0.13507869839668274, 0.020435383543372154, 0.0, 0.0, 0.0], [0.7903086543083191, 0.14559169113636017, 0.037529975175857544, 0.026569725945591927, 0.0, 0.0], [0.7298924326896667, 0.056496407836675644, 0.032735615968704224, 0.10400459170341492, 0.07687094807624817, 0.0], [0.5684185028076172, 0.04388832300901413, 0.026293467730283737, 0.0811714455485344, 0.24314835667610168, 0.037079911679029465]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9499868154525757, 0.05001320689916611, 0.0, 0.0, 0.0, 0.0], [0.9336170554161072, 0.05848868936300278, 0.007894262671470642, 0.0, 0.0, 0.0], [0.7897834181785583, 0.11071821302175522, 0.05360178276896477, 0.04589657858014107, 0.0, 0.0], [0.885930061340332, 0.05752986669540405, 0.01374326553195715, 0.0033877466339617968, 0.03940902277827263, 0.0], [0.9337607622146606, 0.02647063508629799, 0.004523396957665682, 0.0061904797330498695, 0.014132906682789326, 0.014921708963811398]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.8521224554035598e-09, 0.0, 0.0, 0.0, 0.0], [6.6758907451003324e-06, 0.9999804496765137, 1.2841281204600818e-05, 0.0, 0.0, 0.0], [2.2194194926328237e-08, 2.6684581211355862e-09, 0.9999971389770508, 2.8136880700913025e-06, 0.0, 0.0], [1.0145409987671883e-06, 4.464065739284706e-08, 0.00035356366424821317, 0.9993677735328674, 0.0002776293840724975, 0.0], [9.436550429953172e-10, 1.382057315812979e-11, 5.017835036369434e-10, 2.965183876213473e-09, 0.9999971389770508, 2.8644042231462663e-06]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9948632121086121, 0.005136783700436354, 0.0, 0.0, 0.0, 0.0], [0.9274215698242188, 0.01832387037575245, 0.05425456911325455, 0.0, 0.0, 0.0], [0.9678993225097656, 0.004143435508012772, 0.004314453341066837, 0.023642776533961296, 0.0, 0.0], [0.8999068737030029, 0.001467161695472896, 0.00029133574571460485, 0.002585014794021845, 0.09574954956769943, 0.0], [0.9386115670204163, 0.00022248300956562161, 0.0006146665546111763, 0.0015495637198910117, 0.030689461156725883, 0.028312424197793007]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9999959468841553, 4.042720775032649e-06, 0.0, 0.0, 0.0, 0.0], [0.9982761144638062, 3.2613831990602193e-06, 0.001720669330097735, 0.0, 0.0, 0.0], [0.9998809099197388, 5.328835683826583e-08, 6.376215537784446e-07, 0.00011847059795400128, 0.0, 0.0], [0.9996154308319092, 3.473169556400535e-07, 3.8920820344401363e-08, 4.468433303372876e-07, 0.00038369710091501474, 0.0], [0.9994840621948242, 1.655020476221125e-08, 2.8715557931491276e-08, 1.0638284493325045e-06, 0.0002126671897713095, 0.00030212008277885616]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9514135718345642, 0.048586405813694, 0.0, 0.0, 0.0, 0.0], [0.5749948024749756, 0.39028096199035645, 0.03472418338060379, 0.0, 0.0, 0.0], [0.7442318201065063, 0.1752411425113678, 0.0756477490067482, 0.004879283253103495, 0.0, 0.0], [0.5232070684432983, 0.09429339319467545, 0.1138191670179367, 0.19979268312454224, 0.06888769567012787, 0.0], [0.47472575306892395, 0.05636607110500336, 0.04530389606952667, 0.06967321783304214, 0.3098014295101166, 0.0441296212375164]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8734648823738098, 0.12653514742851257, 0.0, 0.0, 0.0, 0.0], [0.6097912788391113, 0.3541727066040039, 0.036036062985658646, 0.0, 0.0, 0.0], [0.45984190702438354, 0.38697871565818787, 0.0996011346578598, 0.05357823893427849, 0.0, 0.0], [0.572220504283905, 0.23636263608932495, 0.08344558626413345, 0.06921917200088501, 0.03875211998820305, 0.0], [0.5143564343452454, 0.16723087430000305, 0.09019406139850616, 0.0765448659658432, 0.10578085482120514, 0.04589281603693962]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.981228768825531, 0.018771231174468994, 0.0, 0.0, 0.0, 0.0], [0.6142941117286682, 0.3503977954387665, 0.0353081189095974, 0.0, 0.0, 0.0], [0.5770686268806458, 0.32858458161354065, 0.05508256331086159, 0.03926428034901619, 0.0, 0.0], [0.17188192903995514, 0.011042501777410507, 0.054578714072704315, 0.7326585650444031, 0.029838265851140022, 0.0], [0.3783015012741089, 0.017070062458515167, 0.021754134446382523, 0.4409688115119934, 0.06093813106417656, 0.08096737414598465]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9923112392425537, 0.007688735146075487, 0.0, 0.0, 0.0, 0.0], [0.9498787522315979, 0.016709784045815468, 0.03341152146458626, 0.0, 0.0, 0.0], [0.9961295127868652, 0.0008787295082584023, 0.0006868162308819592, 0.0023048371076583862, 0.0, 0.0], [0.9935757517814636, 0.0032634998206049204, 0.0009993825806304812, 0.00027932299417443573, 0.0018820574041455984, 0.0], [0.9907532930374146, 0.00021344318520277739, 0.0004595233185682446, 0.0007905619568191469, 0.004424723796546459, 0.003358350833877921]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9647740125656128, 0.03522596135735512, 0.0, 0.0, 0.0, 0.0], [0.8194130063056946, 0.1365436613559723, 0.04404333233833313, 0.0, 0.0, 0.0], [0.7584245800971985, 0.006878929678350687, 0.20653395354747772, 0.028162529692053795, 0.0, 0.0], [0.5298128128051758, 0.002678812015801668, 0.07857988774776459, 0.3598373234272003, 0.02909109927713871, 0.0], [0.7544413208961487, 0.00036782227107323706, 0.0019713479559868574, 0.00324004958383739, 0.1942344754934311, 0.04574500769376755]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9749131202697754, 0.02508680149912834, 0.0, 0.0, 0.0, 0.0], [0.9306471943855286, 0.05705660209059715, 0.012296222150325775, 0.0, 0.0, 0.0], [0.9305251836776733, 0.052770983427762985, 0.01111945416778326, 0.005584415514022112, 0.0, 0.0], [0.8863320350646973, 0.01292418036609888, 0.017724711447954178, 0.06150198355317116, 0.021517015993595123, 0.0], [0.791684627532959, 0.015036096796393394, 0.0317479707300663, 0.03392200171947479, 0.03707978501915932, 0.09052948653697968]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9608501195907593, 0.039149850606918335, 0.0, 0.0, 0.0, 0.0], [0.9121272563934326, 0.02257651649415493, 0.06529619544744492, 0.0, 0.0, 0.0], [0.9364108443260193, 0.015584447421133518, 0.024544963613152504, 0.02345985174179077, 0.0, 0.0], [0.9454620480537415, 0.006762288510799408, 0.022026237100362778, 0.009137796238064766, 0.016611700877547264, 0.0], [0.8346164226531982, 0.001881699077785015, 0.00560904573649168, 0.01887359470129013, 0.12449200451374054, 0.014527074061334133]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9964227080345154, 0.0035772807896137238, 0.0, 0.0, 0.0, 0.0], [0.9713928699493408, 0.024453025311231613, 0.004154058638960123, 0.0, 0.0, 0.0], [0.9735792279243469, 0.019003381952643394, 0.003664410673081875, 0.0037529165856540203, 0.0, 0.0], [0.9586312174797058, 0.007116180844604969, 0.009218388237059116, 0.022725583985447884, 0.0023084774147719145, 0.0], [0.973607063293457, 0.008490582928061485, 0.0032512471079826355, 0.003606445388868451, 0.004877461586147547, 0.006167212035506964]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.97598797082901, 0.024011990055441856, 0.0, 0.0, 0.0, 0.0], [0.9460638165473938, 0.04211375489830971, 0.011822436936199665, 0.0, 0.0, 0.0], [0.8446813225746155, 0.04293116182088852, 0.05218198522925377, 0.06020559370517731, 0.0, 0.0], [0.9378372430801392, 0.03354858607053757, 0.008826455101370811, 0.0028792242519557476, 0.016908427700400352, 0.0], [0.8124931454658508, 0.02696753479540348, 0.05999218672513962, 0.03445731848478317, 0.011011860333383083, 0.05507794767618179]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9001203775405884, 0.09987961500883102, 0.0, 0.0, 0.0, 0.0], [0.627193033695221, 0.07988718152046204, 0.29291975498199463, 0.0, 0.0, 0.0], [0.7624077796936035, 0.02734432928264141, 0.038679543882608414, 0.17156831920146942, 0.0, 0.0], [0.7995968461036682, 0.014336260966956615, 0.01437566988170147, 0.025438452139496803, 0.14625284075737, 0.0], [0.7851970791816711, 0.04204057529568672, 0.025253651663661003, 0.02908395044505596, 0.029306314885616302, 0.08911846578121185]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9954467415809631, 0.0045532057993113995, 0.0, 0.0, 0.0, 0.0], [0.9356001615524292, 0.04476744681596756, 0.019632352516055107, 0.0, 0.0, 0.0], [0.5605552792549133, 0.09861977398395538, 0.29983264207839966, 0.040992289781570435, 0.0, 0.0], [0.5893709659576416, 0.11000988632440567, 0.08033622056245804, 0.16754034161567688, 0.05274256691336632, 0.0], [0.22305884957313538, 0.05680817365646362, 0.05467984080314636, 0.24733951687812805, 0.3111244738101959, 0.1069890558719635]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9301451444625854, 0.06985488533973694, 0.0, 0.0, 0.0, 0.0], [0.8936478495597839, 0.08535721153020859, 0.020994966849684715, 0.0, 0.0, 0.0], [0.8404538035392761, 0.10619214922189713, 0.02363673783838749, 0.029717326164245605, 0.0, 0.0], [0.8927386403083801, 0.024784674867987633, 0.008319000713527203, 0.05165454372763634, 0.022503145039081573, 0.0], [0.8646610975265503, 0.009503193199634552, 0.0024329854641109705, 0.04796753078699112, 0.04273205250501633, 0.03270319849252701]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9859625697135925, 0.014037408865988255, 0.0, 0.0, 0.0, 0.0], [0.9702037572860718, 0.0168070700019598, 0.012989125214517117, 0.0, 0.0, 0.0], [0.9524770379066467, 0.016064459457993507, 0.013456220738589764, 0.018002323806285858, 0.0, 0.0], [0.9332928657531738, 0.01897200010716915, 0.02014683373272419, 0.017023753374814987, 0.010564540512859821, 0.0], [0.9113592505455017, 0.012528638355433941, 0.02209620550274849, 0.01751861348748207, 0.018517911434173584, 0.01797938533127308]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9681769013404846, 0.03182310611009598, 0.0, 0.0, 0.0, 0.0], [0.9096417427062988, 0.07916690409183502, 0.011191264726221561, 0.0, 0.0, 0.0], [0.8379932045936584, 0.13078266382217407, 0.012140989303588867, 0.019083037972450256, 0.0, 0.0], [0.9116525053977966, 0.05451957508921623, 0.009499342180788517, 0.00746585289016366, 0.01686275750398636, 0.0], [0.8510289192199707, 0.07338211685419083, 0.008022507652640343, 0.009083161130547523, 0.04261006414890289, 0.015873271971940994]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9799023866653442, 0.020097682252526283, 0.0, 0.0, 0.0, 0.0], [0.9558742642402649, 0.029063312336802483, 0.015062497928738594, 0.0, 0.0, 0.0], [0.7943133115768433, 0.06074100360274315, 0.06907659024000168, 0.07586916536092758, 0.0, 0.0], [0.5494324564933777, 0.03154711425304413, 0.05482015758752823, 0.05788077041506767, 0.3063195049762726, 0.0], [0.6453980803489685, 0.010770943015813828, 0.017528092488646507, 0.02157985046505928, 0.24958276748657227, 0.05514020845293999]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9506809115409851, 0.0493190623819828, 0.0, 0.0, 0.0, 0.0], [0.8553215265274048, 0.09256264567375183, 0.05211575701832771, 0.0, 0.0, 0.0], [0.850852370262146, 0.04734604433178902, 0.044177331030368805, 0.057624250650405884, 0.0, 0.0], [0.7697131633758545, 0.02788589708507061, 0.031017286702990532, 0.06842502951622009, 0.1029587835073471, 0.0], [0.7931903004646301, 0.04052198305726051, 0.029242033138871193, 0.04478124529123306, 0.04894689470529556, 0.04331749677658081]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9770310521125793, 0.02296893112361431, 0.0, 0.0, 0.0, 0.0], [0.9429817199707031, 0.017321482300758362, 0.03969680890440941, 0.0, 0.0, 0.0], [0.9144344925880432, 0.008583576418459415, 0.013035810552537441, 0.06394599378108978, 0.0, 0.0], [0.9222429990768433, 0.0036440351977944374, 0.003740275977179408, 0.010410364717245102, 0.05996239185333252, 0.0], [0.9198879599571228, 0.0030822583939880133, 0.0034827394410967827, 0.004206796642392874, 0.02125428058207035, 0.048085976392030716]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.977458119392395, 0.022541873157024384, 0.0, 0.0, 0.0, 0.0], [0.8929325342178345, 0.07475466281175613, 0.032312843948602676, 0.0, 0.0, 0.0], [0.8423511385917664, 0.05980278551578522, 0.03740081936120987, 0.06044524535536766, 0.0, 0.0], [0.7674624919891357, 0.03536349534988403, 0.042155250906944275, 0.06658654659986496, 0.08843226730823517, 0.0], [0.6182611584663391, 0.01611059531569481, 0.020167622715234756, 0.03868892416357994, 0.23147016763687134, 0.07530155777931213]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9634856581687927, 0.036514393985271454, 0.0, 0.0, 0.0, 0.0], [0.4363938570022583, 0.522637128829956, 0.04096902906894684, 0.0, 0.0, 0.0], [0.3608614206314087, 0.35129693150520325, 0.2655103802680969, 0.022331148386001587, 0.0, 0.0], [0.3942921757698059, 0.021704670041799545, 0.07794328778982162, 0.37168896198272705, 0.1343708038330078, 0.0], [0.6310713887214661, 0.01698400266468525, 0.025942081585526466, 0.08615949749946594, 0.2183200567960739, 0.021522950381040573]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9988250136375427, 0.0011750265257433057, 0.0, 0.0, 0.0, 0.0], [0.9944871068000793, 0.0004826401418540627, 0.0050302306190133095, 0.0, 0.0, 0.0], [0.9981209635734558, 2.705173392314464e-05, 0.0001130745149566792, 0.0017389442073181272, 0.0, 0.0], [0.9982239603996277, 6.83655816828832e-05, 0.00010199935059063137, 6.028370262356475e-05, 0.0015453165397047997, 0.0], [0.9982888102531433, 1.055222810464329e-06, 3.2781026675365865e-05, 0.00013038977340329438, 0.0006605894886888564, 0.0008863684488460422]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9936710596084595, 0.006328921765089035, 0.0, 0.0, 0.0, 0.0], [0.9727688431739807, 0.0018561368342489004, 0.025375060737133026, 0.0, 0.0, 0.0], [0.9724299907684326, 0.0019586149137467146, 0.011192461475729942, 0.014418890699744225, 0.0, 0.0], [0.9782041311264038, 0.0009589138207957149, 0.0018706483533605933, 0.006326568778604269, 0.012639678083360195, 0.0], [0.9592596888542175, 0.0024555064737796783, 0.00161241355817765, 0.005019655916839838, 0.006687097251415253, 0.024965662509202957]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9629000425338745, 0.03709998354315758, 0.0, 0.0, 0.0, 0.0], [0.36801934242248535, 0.6152258515357971, 0.016754813492298126, 0.0, 0.0, 0.0], [0.3173511326313019, 0.6140013337135315, 0.05375149846076965, 0.014896026812493801, 0.0, 0.0], [0.48987284302711487, 0.21071474254131317, 0.04693019017577171, 0.20700432360172272, 0.04547784850001335, 0.0], [0.48774227499961853, 0.1769528090953827, 0.06915216147899628, 0.09849268198013306, 0.12091436982154846, 0.046745721250772476]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9794419407844543, 0.020558049902319908, 0.0, 0.0, 0.0, 0.0], [0.6677903532981873, 0.31032365560531616, 0.021886007860302925, 0.0, 0.0, 0.0], [0.7118757367134094, 0.11108540743589401, 0.14187385141849518, 0.03516504913568497, 0.0, 0.0], [0.4501457214355469, 0.04036055505275726, 0.040458209812641144, 0.388570100069046, 0.08046531677246094, 0.0], [0.49346262216567993, 0.013696977868676186, 0.008126799948513508, 0.13074499368667603, 0.3086138069629669, 0.04535480588674545]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9846054315567017, 0.015394587069749832, 0.0, 0.0, 0.0, 0.0], [0.9806739091873169, 0.007713791914284229, 0.011612347327172756, 0.0, 0.0, 0.0], [0.932663083076477, 0.01957838423550129, 0.02410353161394596, 0.023654978722333908, 0.0, 0.0], [0.9422016739845276, 0.0009538981830701232, 0.0010898025939241052, 0.00319337984547019, 0.05256118252873421, 0.0], [0.9352930784225464, 0.0010279357666149735, 0.004444425459951162, 0.001637140172533691, 0.010590963996946812, 0.04700646549463272]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9985783100128174, 0.0014216724084690213, 0.0, 0.0, 0.0, 0.0], [0.9893348813056946, 0.0011178902350366116, 0.00954714696854353, 0.0, 0.0, 0.0], [0.9979978203773499, 7.997050124686211e-05, 0.00013218850654084235, 0.0017900333041325212, 0.0, 0.0], [0.9986976385116577, 4.1044117097044364e-05, 3.8683547245454974e-06, 2.3676282580709085e-05, 0.0012337174266576767, 0.0], [0.9971563816070557, 1.852225250331685e-05, 1.8826559653462027e-06, 2.7900125132873654e-05, 0.0006533482228405774, 0.0021419788245111704]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9768233299255371, 0.023176640272140503, 0.0, 0.0, 0.0, 0.0], [0.9194678068161011, 0.05088186264038086, 0.029650341719388962, 0.0, 0.0, 0.0], [0.8474554419517517, 0.06100169196724892, 0.04372376948595047, 0.04781914874911308, 0.0, 0.0], [0.8011623620986938, 0.041866958141326904, 0.04375807195901871, 0.041894737631082535, 0.07131782174110413, 0.0], [0.8031871914863586, 0.02450493723154068, 0.017323585227131844, 0.04744395986199379, 0.06109930947422981, 0.046441152691841125]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9829428195953369, 0.01705716922879219, 0.0, 0.0, 0.0, 0.0], [0.8863736987113953, 0.09492647647857666, 0.018699750304222107, 0.0, 0.0, 0.0], [0.9231085777282715, 0.03696346655488014, 0.032198335975408554, 0.007729663979262114, 0.0, 0.0], [0.9068527221679688, 0.016046639531850815, 0.014310522936284542, 0.04543786868453026, 0.017352323979139328, 0.0], [0.6555973887443542, 0.05091019719839096, 0.028384855017066002, 0.1256549060344696, 0.10546853393316269, 0.03398407623171806]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9502318501472473, 0.049768079072237015, 0.0, 0.0, 0.0, 0.0], [0.8829865455627441, 0.1000962108373642, 0.01691717840731144, 0.0, 0.0, 0.0], [0.8057457804679871, 0.14463546872138977, 0.03018922731280327, 0.019429458305239677, 0.0, 0.0], [0.8706230521202087, 0.032440632581710815, 0.026951627805829048, 0.04410304129123688, 0.025881657376885414, 0.0], [0.688364565372467, 0.009681451134383678, 0.016449343413114548, 0.0987110361456871, 0.08971209079027176, 0.09708156436681747]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9792683124542236, 0.02073168195784092, 0.0, 0.0, 0.0, 0.0], [0.9523284435272217, 0.025933818891644478, 0.021737735718488693, 0.0, 0.0, 0.0], [0.9144353270530701, 0.017671240493655205, 0.022358495742082596, 0.04553484544157982, 0.0, 0.0], [0.9448292851448059, 0.006467597559094429, 0.006386063527315855, 0.03263096138834953, 0.00968620739877224, 0.0], [0.9347906112670898, 0.007862505502998829, 0.007788175716996193, 0.021432818844914436, 0.008491144515573978, 0.01963483914732933]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.983370304107666, 0.016629677265882492, 0.0, 0.0, 0.0, 0.0], [0.963111400604248, 0.009229931980371475, 0.027658598497509956, 0.0, 0.0, 0.0], [0.9706628322601318, 0.0041494048200547695, 0.0068131014704704285, 0.018374638631939888, 0.0, 0.0], [0.987951934337616, 0.002165885642170906, 0.00034901127219200134, 0.001583816367201507, 0.00794942770153284, 0.0], [0.9457950592041016, 0.014583553187549114, 0.0003652951563708484, 0.0009569536778144538, 0.013621564954519272, 0.02467755414545536]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9878059029579163, 0.01219407469034195, 0.0, 0.0, 0.0, 0.0], [0.87103670835495, 0.09448163211345673, 0.03448161482810974, 0.0, 0.0, 0.0], [0.6309783458709717, 0.11090382188558578, 0.1923021823167801, 0.06581564992666245, 0.0, 0.0], [0.5360490083694458, 0.04618944972753525, 0.13605308532714844, 0.26455509662628174, 0.017153292894363403, 0.0], [0.8287520408630371, 0.023732755333185196, 0.02008037269115448, 0.07245264202356339, 0.030431220307946205, 0.024550989270210266]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8995685577392578, 0.10043150931596756, 0.0, 0.0, 0.0, 0.0], [0.270343542098999, 0.6504329442977905, 0.07922357320785522, 0.0, 0.0, 0.0], [0.20541730523109436, 0.5892508625984192, 0.18085837364196777, 0.024473490193486214, 0.0, 0.0], [0.5573861002922058, 0.1774134784936905, 0.08806808292865753, 0.09881848096847534, 0.07831384986639023, 0.0], [0.5922912359237671, 0.08700639009475708, 0.05643285810947418, 0.05685883015394211, 0.12181518226861954, 0.08559554070234299]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9316380620002747, 0.06836195290088654, 0.0, 0.0, 0.0, 0.0], [0.9572945833206177, 0.026243582367897034, 0.0164618119597435, 0.0, 0.0, 0.0], [0.9880544543266296, 0.00427332753315568, 0.002954584313556552, 0.004717645235359669, 0.0, 0.0], [0.99403977394104, 0.0009413420339114964, 0.0004739820142276585, 0.00011646930943243206, 0.004428447224199772, 0.0], [0.9806035161018372, 2.5468933017691597e-05, 0.00016239412070717663, 0.0001476418401580304, 0.0013442443450912833, 0.017716845497488976]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.993178129196167, 0.006821857299655676, 0.0, 0.0, 0.0, 0.0], [0.9756524562835693, 0.01318411435931921, 0.011163423769176006, 0.0, 0.0, 0.0], [0.9418966770172119, 0.004721744451671839, 0.0023818055633455515, 0.050999753177165985, 0.0, 0.0], [0.9905040860176086, 0.0022848136723041534, 6.198462506290525e-05, 0.0005984465242363513, 0.006550676189363003, 0.0], [0.9697660207748413, 0.0008878845837898552, 0.00023466735729016364, 0.0017040816601365805, 0.004128355998545885, 0.02327893301844597]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9716231822967529, 0.02837684564292431, 0.0, 0.0, 0.0, 0.0], [0.9223619699478149, 0.028907248750329018, 0.048730745911598206, 0.0, 0.0, 0.0], [0.8426317572593689, 0.023872116580605507, 0.04748132824897766, 0.08601479232311249, 0.0, 0.0], [0.8521121740341187, 0.020744236186146736, 0.04494619369506836, 0.05765002593398094, 0.02454746514558792, 0.0], [0.8800725936889648, 0.022448532283306122, 0.018235722556710243, 0.01925482600927353, 0.015854258090257645, 0.044134121388196945]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9412723779678345, 0.058727629482746124, 0.0, 0.0, 0.0, 0.0], [0.916313886642456, 0.05759201943874359, 0.02609400637447834, 0.0, 0.0, 0.0], [0.8392423391342163, 0.057690516114234924, 0.01382902916520834, 0.08923812955617905, 0.0, 0.0], [0.8987162113189697, 0.0134778693318367, 0.0003456450067460537, 0.003298751311376691, 0.08416149020195007, 0.0], [0.8701692223548889, 0.002700856188312173, 0.00143499206751585, 0.0056661744602024555, 0.08874300867319107, 0.031285665929317474]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9656725525856018, 0.03432750701904297, 0.0, 0.0, 0.0, 0.0], [0.9178615808486938, 0.062257930636405945, 0.019880469888448715, 0.0, 0.0, 0.0], [0.823314905166626, 0.06282395124435425, 0.03670429438352585, 0.07715693861246109, 0.0, 0.0], [0.8501748442649841, 0.03816927224397659, 0.03196492791175842, 0.0516013503074646, 0.02808968350291252, 0.0], [0.6572404503822327, 0.05877397954463959, 0.04336007311940193, 0.09013211727142334, 0.08146599680185318, 0.06902744621038437]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9162061810493469, 0.0837937667965889, 0.0, 0.0, 0.0, 0.0], [0.9451773762702942, 0.04099284112453461, 0.013829832896590233, 0.0, 0.0, 0.0], [0.8928355574607849, 0.05368670076131821, 0.017596954479813576, 0.03588071092963219, 0.0, 0.0], [0.8337052464485168, 0.04799601063132286, 0.033513229340314865, 0.04680858924984932, 0.03797686845064163, 0.0], [0.8167192339897156, 0.06337132304906845, 0.013286277651786804, 0.020469767972826958, 0.025292355567216873, 0.06086111441254616]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9525133371353149, 0.04748663306236267, 0.0, 0.0, 0.0, 0.0], [0.3019869327545166, 0.6520938873291016, 0.04591925069689751, 0.0, 0.0, 0.0], [0.285582959651947, 0.556952178478241, 0.1444743126630783, 0.012990524061024189, 0.0, 0.0], [0.843804121017456, 0.032251205295324326, 0.03954290598630905, 0.06848159432411194, 0.015920041128993034, 0.0], [0.6664940714836121, 0.06095913052558899, 0.04064354673027992, 0.06804485619068146, 0.09186329692602158, 0.07199501991271973]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9682655334472656, 0.031734466552734375, 0.0, 0.0, 0.0, 0.0], [0.738521933555603, 0.22856839001178741, 0.032909639179706573, 0.0, 0.0, 0.0], [0.5946676135063171, 0.2303314357995987, 0.14867636561393738, 0.02632458508014679, 0.0, 0.0], [0.6339254975318909, 0.05813034623861313, 0.09654320776462555, 0.14291946589946747, 0.06848153471946716, 0.0], [0.40375572443008423, 0.08945391327142715, 0.07635112851858139, 0.25587135553359985, 0.1433039754629135, 0.03126389905810356]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9869793653488159, 0.013020593672990799, 0.0, 0.0, 0.0, 0.0], [0.8631385564804077, 0.1105666309595108, 0.02629482001066208, 0.0, 0.0, 0.0], [0.9488080143928528, 0.028614996001124382, 0.006535546388477087, 0.016041526570916176, 0.0, 0.0], [0.9672170877456665, 0.006604980677366257, 0.00045171406236477196, 0.004844417329877615, 0.020881708711385727, 0.0], [0.9354621171951294, 0.02047806605696678, 0.0011700231116265059, 0.007056943140923977, 0.0163181871175766, 0.019514625892043114]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9846673011779785, 0.015332723967730999, 0.0, 0.0, 0.0, 0.0], [0.9052747488021851, 0.08373606950044632, 0.010989243164658546, 0.0, 0.0, 0.0], [0.8145939111709595, 0.04283742979168892, 0.10568301379680634, 0.03688570484519005, 0.0, 0.0], [0.23519809544086456, 0.012018457986414433, 0.05280117318034172, 0.6516180038452148, 0.04836418479681015, 0.0], [0.31818512082099915, 0.018632443621754646, 0.03948190063238144, 0.3755541741847992, 0.20787373185157776, 0.04027257487177849]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9811733365058899, 0.018826685845851898, 0.0, 0.0, 0.0, 0.0], [0.8618939518928528, 0.06479164958000183, 0.07331438362598419, 0.0, 0.0, 0.0], [0.7664540410041809, 0.07330425828695297, 0.10353513062000275, 0.056706514209508896, 0.0, 0.0], [0.8128499984741211, 0.03215480223298073, 0.059005625545978546, 0.05416511744260788, 0.04182446748018265, 0.0], [0.8687856197357178, 0.026987861841917038, 0.02047000452876091, 0.01629738137125969, 0.03218390792608261, 0.03527523949742317]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9264583587646484, 0.07354167848825455, 0.0, 0.0, 0.0, 0.0], [0.8403540849685669, 0.06373751163482666, 0.09590838104486465, 0.0, 0.0, 0.0], [0.7330995798110962, 0.06451118737459183, 0.10380073636770248, 0.09858842939138412, 0.0, 0.0], [0.9143612384796143, 0.008257776498794556, 0.007320381235331297, 0.017966248095035553, 0.05209439620375633, 0.0], [0.8971915245056152, 0.008555498905479908, 0.007019453682005405, 0.014860544353723526, 0.03399762138724327, 0.03837529569864273]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9180347919464111, 0.08196526020765305, 0.0, 0.0, 0.0, 0.0], [0.8328666687011719, 0.1219901517033577, 0.04514322429895401, 0.0, 0.0, 0.0], [0.7994157075881958, 0.0874413549900055, 0.03605784848332405, 0.07708510011434555, 0.0, 0.0], [0.880984902381897, 0.020749641582369804, 0.020554615184664726, 0.017120830714702606, 0.06058995798230171, 0.0], [0.745303213596344, 0.044334057718515396, 0.022549288347363472, 0.0331527441740036, 0.03357058763504028, 0.12109009176492691]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9867060780525208, 0.013293893076479435, 0.0, 0.0, 0.0, 0.0], [0.982177734375, 0.012414131313562393, 0.005408108700066805, 0.0, 0.0, 0.0], [0.9630486369132996, 0.015290752984583378, 0.010345698334276676, 0.0113149369135499, 0.0, 0.0], [0.9213568568229675, 0.014132463373243809, 0.017639216035604477, 0.016567690297961235, 0.030303770676255226, 0.0], [0.9373326301574707, 0.009064299054443836, 0.007548365276306868, 0.006576443091034889, 0.011827622540295124, 0.027650514617562294]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9951004385948181, 0.00489962799474597, 0.0, 0.0, 0.0, 0.0], [0.9476007223129272, 0.041407931596040726, 0.010991275310516357, 0.0, 0.0, 0.0], [0.9142175316810608, 0.023523783311247826, 0.039145033806562424, 0.023113621398806572, 0.0, 0.0], [0.9534738659858704, 0.008932933211326599, 0.015272765420377254, 0.007908251136541367, 0.014412266202270985, 0.0], [0.9427101016044617, 0.00823307130485773, 0.004650997929275036, 0.004178107250481844, 0.005463531706482172, 0.03476419299840927]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9543376564979553, 0.045662373304367065, 0.0, 0.0, 0.0, 0.0], [0.9696040749549866, 0.01954760029911995, 0.01084828469902277, 0.0, 0.0, 0.0], [0.9710449576377869, 0.012425386346876621, 0.008068876340985298, 0.008460716344416142, 0.0, 0.0], [0.9726192951202393, 0.002697656163945794, 0.00044831327977590263, 0.0013814778067171574, 0.022853154689073563, 0.0], [0.9675466418266296, 0.009613442234694958, 0.003203035332262516, 0.00424883933737874, 0.007442260626703501, 0.00794589426368475]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9887008666992188, 0.011299116536974907, 0.0, 0.0, 0.0, 0.0], [0.9382632374763489, 0.04204244911670685, 0.019694412127137184, 0.0, 0.0, 0.0], [0.8351995944976807, 0.03487853705883026, 0.05134471505880356, 0.07857715338468552, 0.0, 0.0], [0.9042676687240601, 0.010541575029492378, 0.016426723450422287, 0.025921987369656563, 0.04284200444817543, 0.0], [0.8913140892982483, 0.00891267228871584, 0.005010711494833231, 0.008175632916390896, 0.013514749705791473, 0.07307209819555283]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8693912029266357, 0.13060881197452545, 0.0, 0.0, 0.0, 0.0], [0.3507988452911377, 0.606351912021637, 0.04284917935729027, 0.0, 0.0, 0.0], [0.35475659370422363, 0.3502019941806793, 0.24722407758235931, 0.04781729355454445, 0.0, 0.0], [0.35370609164237976, 0.03527737781405449, 0.09567111730575562, 0.449796199798584, 0.06554921716451645, 0.0], [0.4132595360279083, 0.09055527299642563, 0.05286579951643944, 0.174679696559906, 0.173848956823349, 0.09479076415300369]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9629756212234497, 0.037024300545454025, 0.0, 0.0, 0.0, 0.0], [0.9756426811218262, 0.01965854875743389, 0.004698706325143576, 0.0, 0.0, 0.0], [0.9775736927986145, 0.013286248780786991, 0.0025590297300368547, 0.006581062916666269, 0.0, 0.0], [0.9870142936706543, 0.007388236932456493, 0.0009579154429957271, 0.0018318220973014832, 0.0028077505994588137, 0.0], [0.9409245848655701, 0.016633737832307816, 0.0022979143541306257, 0.0058906711637973785, 0.0055129327811300755, 0.02874022163450718]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.962827205657959, 0.037172831594944, 0.0, 0.0, 0.0, 0.0], [0.9582237601280212, 0.024641817435622215, 0.017134377732872963, 0.0, 0.0, 0.0], [0.9351300001144409, 0.015331573784351349, 0.014810982160270214, 0.034727465361356735, 0.0, 0.0], [0.9225171208381653, 0.010528750717639923, 0.011010154150426388, 0.01944003626704216, 0.036503832787275314, 0.0], [0.8420165777206421, 0.04357199743390083, 0.007488282397389412, 0.01496153138577938, 0.02385285682976246, 0.06810864061117172]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9926387071609497, 0.00736132962629199, 0.0, 0.0, 0.0, 0.0], [0.9957393407821655, 0.0033469819463789463, 0.000913690309971571, 0.0, 0.0, 0.0], [0.9869900345802307, 0.001974786864593625, 0.001524551771581173, 0.009510699659585953, 0.0, 0.0], [0.9933527708053589, 0.001020324882119894, 0.00034337223041802645, 0.0010291127255186439, 0.004254369530826807, 0.0], [0.9749016761779785, 0.00043480272870510817, 0.0004306558985263109, 0.0012364407302811742, 0.0015347707085311413, 0.021461669355630875]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9897475242614746, 0.010252462700009346, 0.0, 0.0, 0.0, 0.0], [0.9790639281272888, 0.01650906540453434, 0.0044270907528698444, 0.0, 0.0, 0.0], [0.9521436095237732, 0.029432358220219612, 0.008943161927163601, 0.009480923414230347, 0.0, 0.0], [0.939594030380249, 0.021510960534214973, 0.010278552770614624, 0.004555229097604752, 0.024061163887381554, 0.0], [0.9205074906349182, 0.016153652220964432, 0.010818594135344028, 0.01664440892636776, 0.014566398225724697, 0.021309375762939453]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9898501634597778, 0.010149780660867691, 0.0, 0.0, 0.0, 0.0], [0.9820910096168518, 0.006907520350068808, 0.011001535691320896, 0.0, 0.0, 0.0], [0.9684997200965881, 0.008987602777779102, 0.015342563390731812, 0.007170087192207575, 0.0, 0.0], [0.9274120330810547, 0.009485266171395779, 0.022066107019782066, 0.03222890570759773, 0.008807653561234474, 0.0], [0.900665819644928, 0.021623756736516953, 0.013808279298245907, 0.009843860752880573, 0.008521373383700848, 0.04553695768117905]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9954444169998169, 0.004555588588118553, 0.0, 0.0, 0.0, 0.0], [0.995254397392273, 0.002460238989442587, 0.002285485854372382, 0.0, 0.0, 0.0], [0.9862446188926697, 0.0015168144600465894, 0.004072288051247597, 0.008166354149580002, 0.0, 0.0], [0.9889963865280151, 0.001226040069013834, 0.0007996349013410509, 0.0006774227367714047, 0.008300574496388435, 0.0], [0.9865202903747559, 0.00039427157025784254, 0.0009571771952323616, 0.0004954367759637535, 0.0009604979422874749, 0.010672281496226788]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9821295142173767, 0.017870500683784485, 0.0, 0.0, 0.0, 0.0], [0.7489436268806458, 0.22002726793289185, 0.031029189005494118, 0.0, 0.0, 0.0], [0.28547799587249756, 0.21125678718090057, 0.47871601581573486, 0.024549242109060287, 0.0, 0.0], [0.8056644201278687, 0.026974644511938095, 0.04302806034684181, 0.06993705034255981, 0.05439583212137222, 0.0], [0.3307209014892578, 0.022326624020934105, 0.016627125442028046, 0.08019453287124634, 0.41574832797050476, 0.13438253104686737]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9697746634483337, 0.030225319787859917, 0.0, 0.0, 0.0, 0.0], [0.9800565838813782, 0.015018894337117672, 0.004924521781504154, 0.0, 0.0, 0.0], [0.9237861037254333, 0.052764780819416046, 0.00630240747705102, 0.017146753147244453, 0.0, 0.0], [0.9451844096183777, 0.03618047758936882, 0.001989208161830902, 0.003958724904805422, 0.012687299400568008, 0.0], [0.9633325934410095, 0.018662991002202034, 0.0030418417882174253, 0.007070912979543209, 0.0050094155594706535, 0.002882065251469612]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9873244762420654, 0.012675459496676922, 0.0, 0.0, 0.0, 0.0], [0.9904569983482361, 0.0055419523268938065, 0.004001122899353504, 0.0, 0.0, 0.0], [0.9814971685409546, 0.004653455223888159, 0.003725277027115226, 0.010124054737389088, 0.0, 0.0], [0.9744365811347961, 0.004632251337170601, 0.002379992976784706, 0.006518087349832058, 0.012033028528094292, 0.0], [0.9624497294425964, 0.0033743639942258596, 0.0013198587112128735, 0.0017275003483518958, 0.002944675739854574, 0.028183799237012863]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9807674288749695, 0.01923258602619171, 0.0, 0.0, 0.0, 0.0], [0.9664245843887329, 0.015413926914334297, 0.018161438405513763, 0.0, 0.0, 0.0], [0.9632682204246521, 0.004538117907941341, 0.002925391308963299, 0.029268190264701843, 0.0, 0.0], [0.9562349319458008, 0.0012223608791828156, 0.0005304080550558865, 0.00867149606347084, 0.03334089741110802, 0.0], [0.9657101035118103, 0.0009808284230530262, 0.0016686266753822565, 0.002634831238538027, 0.005866361316293478, 0.023139292374253273]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9639716148376465, 0.036028459668159485, 0.0, 0.0, 0.0, 0.0], [0.9562800526618958, 0.03373315557837486, 0.009986846707761288, 0.0, 0.0, 0.0], [0.8539998531341553, 0.08073022216558456, 0.03334445133805275, 0.031925540417432785, 0.0, 0.0], [0.9547491073608398, 0.009605025872588158, 0.004146162886172533, 0.0020133228972554207, 0.029486361891031265, 0.0], [0.9331137537956238, 0.028699662536382675, 0.005477475933730602, 0.006368075497448444, 0.012613046914339066, 0.013728085905313492]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9392993450164795, 0.06070063263177872, 0.0, 0.0, 0.0, 0.0], [0.9298391342163086, 0.061895377933979034, 0.008265496231615543, 0.0, 0.0, 0.0], [0.8471823334693909, 0.09035038203001022, 0.01763608679175377, 0.044831156730651855, 0.0, 0.0], [0.8857703804969788, 0.03918175399303436, 0.007867704145610332, 0.02276589721441269, 0.04441439360380173, 0.0], [0.8563280701637268, 0.10088995099067688, 0.006531452294439077, 0.008485927246510983, 0.007368441205471754, 0.020396249368786812]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8353264331817627, 0.1646735519170761, 0.0, 0.0, 0.0, 0.0], [0.6160858869552612, 0.3137648403644562, 0.07014927268028259, 0.0, 0.0, 0.0], [0.34316325187683105, 0.2758493721485138, 0.1196604073047638, 0.26132699847221375, 0.0, 0.0], [0.5908172130584717, 0.050290752202272415, 0.041665926575660706, 0.2199493646621704, 0.0972767099738121, 0.0], [0.8481413125991821, 0.06318090111017227, 0.014733693562448025, 0.055267371237277985, 0.00901501253247261, 0.009661628864705563]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9627319574356079, 0.03726799786090851, 0.0, 0.0, 0.0, 0.0], [0.7757522463798523, 0.1799626499414444, 0.044285036623477936, 0.0, 0.0, 0.0], [0.6317060589790344, 0.24380716681480408, 0.10925652086734772, 0.015230235643684864, 0.0, 0.0], [0.9539909958839417, 0.018182311207056046, 0.011601822450757027, 0.012299076654016972, 0.003925766795873642, 0.0], [0.40356943011283875, 0.14237558841705322, 0.05661217123270035, 0.1975736767053604, 0.0929921343922615, 0.10687707364559174]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9802619218826294, 0.019738124683499336, 0.0, 0.0, 0.0, 0.0], [0.9873908162117004, 0.007800452411174774, 0.004808681085705757, 0.0, 0.0, 0.0], [0.9283918738365173, 0.008301235735416412, 0.01330565195530653, 0.05000120773911476, 0.0, 0.0], [0.8981055021286011, 0.015591299161314964, 0.010177576914429665, 0.039987027645111084, 0.0361386202275753, 0.0], [0.9753499031066895, 0.00035433052107691765, 0.0005866039427928627, 0.0011877501383423805, 0.0010750899091362953, 0.021446440368890762]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9295330047607422, 0.07046692818403244, 0.0, 0.0, 0.0, 0.0], [0.9361506104469299, 0.04116682708263397, 0.022682538256049156, 0.0, 0.0, 0.0], [0.8486821055412292, 0.05802798643708229, 0.024856165051460266, 0.0684337466955185, 0.0, 0.0], [0.8661180734634399, 0.02232467755675316, 0.010369130410254002, 0.02600197121500969, 0.07518619298934937, 0.0], [0.8074421882629395, 0.044382549822330475, 0.01849711686372757, 0.03357789292931557, 0.018561245873570442, 0.07753907144069672]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9680535197257996, 0.03194643557071686, 0.0, 0.0, 0.0, 0.0], [0.9693689942359924, 0.02568492479622364, 0.004946070723235607, 0.0, 0.0, 0.0], [0.9620568156242371, 0.022552406415343285, 0.005471326876431704, 0.009919456206262112, 0.0, 0.0], [0.9727528095245361, 0.010137127712368965, 0.000757327419705689, 0.0028828983195126057, 0.013469807803630829, 0.0], [0.9624635577201843, 0.0031109037809073925, 0.0010007602395489812, 0.0019475930603221059, 0.008266227319836617, 0.02321087196469307]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8542501330375671, 0.14574992656707764, 0.0, 0.0, 0.0, 0.0], [0.9725967645645142, 0.014116315171122551, 0.01328685600310564, 0.0, 0.0, 0.0], [0.9257621765136719, 0.03257262706756592, 0.01461210660636425, 0.027053095400333405, 0.0, 0.0], [0.7923423051834106, 0.027305101975798607, 0.01880674995481968, 0.13854165375232697, 0.023004096001386642, 0.0], [0.6152060627937317, 0.02665526419878006, 0.029352931305766106, 0.05590886250138283, 0.11611279845237732, 0.15676409006118774]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9804654121398926, 0.019534552469849586, 0.0, 0.0, 0.0, 0.0], [0.9882452487945557, 0.007509466726332903, 0.004245325922966003, 0.0, 0.0, 0.0], [0.9584206938743591, 0.0109635591506958, 0.010456060990691185, 0.020159708335995674, 0.0, 0.0], [0.9604811668395996, 0.007182627450674772, 0.003072339342907071, 0.006898913532495499, 0.02236509881913662, 0.0], [0.966888964176178, 0.0032812939025461674, 0.00550054432824254, 0.004234083462506533, 0.005038043484091759, 0.015057181939482689]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9498194456100464, 0.05018055811524391, 0.0, 0.0, 0.0, 0.0], [0.9781363606452942, 0.016430046409368515, 0.0054335566237568855, 0.0, 0.0, 0.0], [0.8618696331977844, 0.036093585193157196, 0.07555554062128067, 0.026481209322810173, 0.0, 0.0], [0.5449837446212769, 0.015411133877933025, 0.023516526445746422, 0.25743600726127625, 0.15865260362625122, 0.0], [0.9571874737739563, 0.0030803855042904615, 0.0014446862041950226, 0.006861559115350246, 0.014818714000284672, 0.01660723052918911]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6156560778617859, 0.3843439519405365, 0.0, 0.0, 0.0, 0.0], [0.36760634183883667, 0.42816370725631714, 0.20423001050949097, 0.0, 0.0, 0.0], [0.16471554338932037, 0.4136792719364166, 0.2509237229824066, 0.17068152129650116, 0.0, 0.0], [0.4184456169605255, 0.1524762362241745, 0.10305401682853699, 0.11071498692035675, 0.21530911326408386, 0.0], [0.19686934351921082, 0.2014620453119278, 0.12827259302139282, 0.09203246980905533, 0.09167550504207611, 0.2896881103515625]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9027364253997803, 0.09726352989673615, 0.0, 0.0, 0.0, 0.0], [0.9736634492874146, 0.014004302211105824, 0.01233230996876955, 0.0, 0.0, 0.0], [0.8504456281661987, 0.05690572410821915, 0.032060906291007996, 0.06058764085173607, 0.0, 0.0], [0.7661210298538208, 0.03530392050743103, 0.03433045372366905, 0.09675204753875732, 0.06749245524406433, 0.0], [0.8650374412536621, 0.020085260272026062, 0.01149806659668684, 0.01855834573507309, 0.018430285155773163, 0.06639053672552109]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9653082489967346, 0.03469168767333031, 0.0, 0.0, 0.0, 0.0], [0.9816323518753052, 0.014176066033542156, 0.004191514104604721, 0.0, 0.0, 0.0], [0.9275256395339966, 0.04737218841910362, 0.01152826938778162, 0.013573966920375824, 0.0, 0.0], [0.9293117523193359, 0.025833239778876305, 0.007227106485515833, 0.014300585724413395, 0.02332727052271366, 0.0], [0.8895062804222107, 0.04689619690179825, 0.0047171092592179775, 0.006286581978201866, 0.00609014043584466, 0.04650374501943588]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8938026428222656, 0.10619727522134781, 0.0, 0.0, 0.0, 0.0], [0.8221707940101624, 0.06304481625556946, 0.11478441953659058, 0.0, 0.0, 0.0], [0.5047380924224854, 0.15375731885433197, 0.2277037501335144, 0.11380083113908768, 0.0, 0.0], [0.4082071781158447, 0.09066355973482132, 0.11696872115135193, 0.24553199112415314, 0.13862857222557068, 0.0], [0.7291035652160645, 0.06638889014720917, 0.023112818598747253, 0.031103096902370453, 0.057143256068229675, 0.09314827620983124]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9247531890869141, 0.07524678111076355, 0.0, 0.0, 0.0, 0.0], [0.8957376480102539, 0.06989553570747375, 0.03436679765582085, 0.0, 0.0, 0.0], [0.7924937605857849, 0.0960114598274231, 0.05509118735790253, 0.056403566151857376, 0.0, 0.0], [0.7891505360603333, 0.07880303263664246, 0.03840155899524689, 0.05396979674696922, 0.03967496380209923, 0.0], [0.7807856798171997, 0.0799354612827301, 0.042531758546829224, 0.03234211727976799, 0.0178169384598732, 0.046588052064180374]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9480886459350586, 0.05191127583384514, 0.0, 0.0, 0.0, 0.0], [0.863694965839386, 0.04756204038858414, 0.08874296396970749, 0.0, 0.0, 0.0], [0.9341371059417725, 0.022224076092243195, 0.022624483332037926, 0.021014342084527016, 0.0, 0.0], [0.9588143229484558, 0.008020909503102303, 0.004490078426897526, 0.005862293299287558, 0.022812429815530777, 0.0], [0.9385918378829956, 0.021227721124887466, 0.0048724692314863205, 0.010940189473330975, 0.009524582885205746, 0.014843451790511608]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9763734340667725, 0.023626558482646942, 0.0, 0.0, 0.0, 0.0], [0.9884802103042603, 0.005189393647015095, 0.0063303736969828606, 0.0, 0.0, 0.0], [0.9477092027664185, 0.0179851483553648, 0.010156610049307346, 0.024149026721715927, 0.0, 0.0], [0.967192530632019, 0.006552813574671745, 0.0033227826934307814, 0.00556332478299737, 0.017368387430906296, 0.0], [0.9584562182426453, 0.007502961438149214, 0.0051363310776650906, 0.008071648888289928, 0.005997124593704939, 0.014835843816399574]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.884070873260498, 0.11592914164066315, 0.0, 0.0, 0.0, 0.0], [0.9931254386901855, 0.005070806015282869, 0.0018038019770756364, 0.0, 0.0, 0.0], [0.9534159302711487, 0.02382904477417469, 0.007748977281153202, 0.015006075613200665, 0.0, 0.0], [0.9151289463043213, 0.010873105376958847, 0.013190957717597485, 0.011050421744585037, 0.04975655674934387, 0.0], [0.8769673109054565, 0.03385210782289505, 0.00848648976534605, 0.009969149716198444, 0.03468578681349754, 0.036039214581251144]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0003709519514814019, 0.999629020690918, 0.0, 0.0, 0.0, 0.0], [6.525027856696397e-05, 0.3737829029560089, 0.6261518597602844, 0.0, 0.0, 0.0], [4.606018774211407e-05, 0.210508793592453, 0.4115968942642212, 0.3778482675552368, 0.0, 0.0], [4.753069515572861e-05, 0.11616954207420349, 0.23264272511005402, 0.3985331058502197, 0.2526070475578308, 0.0], [1.247641534973809e-06, 0.14819711446762085, 0.15813173353672028, 0.30074331164360046, 0.11939018964767456, 0.27353641390800476]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.971555769443512, 0.028444187715649605, 0.0, 0.0, 0.0, 0.0], [0.9529065489768982, 0.03233075141906738, 0.014762768521904945, 0.0, 0.0, 0.0], [0.9343128204345703, 0.02351292595267296, 0.02049802988767624, 0.021676240488886833, 0.0, 0.0], [0.9529678225517273, 0.00855141133069992, 0.004359325394034386, 0.008064556866884232, 0.026056913658976555, 0.0], [0.9653593897819519, 0.008487647399306297, 0.003499280195683241, 0.002721576252952218, 0.0032828773837536573, 0.016649367287755013]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8630780577659607, 0.13692188262939453, 0.0, 0.0, 0.0, 0.0], [0.7696157097816467, 0.0851333811879158, 0.14525099098682404, 0.0, 0.0, 0.0], [0.7133337259292603, 0.10170899331569672, 0.11931268870830536, 0.06564456224441528, 0.0, 0.0], [0.7186222076416016, 0.05444284901022911, 0.01386815495789051, 0.07808027416467667, 0.13498654961585999, 0.0], [0.7990148663520813, 0.05805593729019165, 0.009447019547224045, 0.017770467326045036, 0.02113853208720684, 0.09457314014434814]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9518988728523254, 0.048101115971803665, 0.0, 0.0, 0.0, 0.0], [0.8580653071403503, 0.02944577857851982, 0.11248888075351715, 0.0, 0.0, 0.0], [0.6577738523483276, 0.08513449877500534, 0.1261308640241623, 0.1309608370065689, 0.0, 0.0], [0.8087368607521057, 0.0323016420006752, 0.01841817982494831, 0.06856140494346619, 0.07198194414377213, 0.0], [0.6683295965194702, 0.13281384110450745, 0.021880635991692543, 0.02787741646170616, 0.04923408478498459, 0.0998644009232521]]]], \"left_text\": [\"No\", \",\", \" I\", \" am\", \" your\", \" father\"], \"right_text\": [\"No\", \",\", \" I\", \" am\", \" your\", \" father\"]}], \"default_filter\": \"0\", \"display_mode\": \"dark\", \"root_div_id\": \"bertviz-fbc5c2e7d0654600999365aa5a3d8d2c\", \"include_layers\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], \"include_heads\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], \"total_heads\": 12} is a template marker that is replaced by actual params.\n",
       "        const config = {};\n",
       "\n",
       "        const MIN_X = 0;\n",
       "        const MIN_Y = 0;\n",
       "        const DIV_WIDTH = 970;\n",
       "        const THUMBNAIL_PADDING = 5;\n",
       "        const DETAIL_WIDTH = 300;\n",
       "        const DETAIL_ATTENTION_WIDTH = 140;\n",
       "        const DETAIL_BOX_WIDTH = 80;\n",
       "        const DETAIL_BOX_HEIGHT = 18;\n",
       "        const DETAIL_PADDING = 15;\n",
       "        const ATTN_PADDING = 0;\n",
       "        const DETAIL_HEADING_HEIGHT = 25;\n",
       "        const HEADING_TEXT_SIZE = 15;\n",
       "        const HEADING_PADDING = 5;\n",
       "        const TEXT_SIZE = 13;\n",
       "        const TEXT_PADDING = 5;\n",
       "        const LAYER_COLORS = d3.schemeCategory10;\n",
       "        const PALETTE = {\n",
       "            'light': {\n",
       "                'text': 'black',\n",
       "                'background': 'white',\n",
       "                'highlight': '#F5F5F5'\n",
       "            },\n",
       "            'dark': {\n",
       "                'text': '#ccc',\n",
       "                'background': 'black',\n",
       "                'highlight': '#222'\n",
       "            }\n",
       "        }\n",
       "\n",
       "        function render() {\n",
       "\n",
       "            // Set global state variables\n",
       "\n",
       "            var attData = config.attention[config.filter];\n",
       "            config.leftText = attData.left_text;\n",
       "            config.rightText = attData.right_text;\n",
       "            config.attn = attData.attn;\n",
       "            config.numLayers = config.attn.length;\n",
       "            config.numHeads = config.attn[0].length;\n",
       "            config.thumbnailBoxHeight = 7 * (12 / config.totalHeads);\n",
       "            const axisSize = HEADING_TEXT_SIZE + HEADING_PADDING + TEXT_SIZE + TEXT_PADDING;\n",
       "            config.thumbnailHeight = Math.max(config.leftText.length, config.rightText.length) * config.thumbnailBoxHeight + 2 * THUMBNAIL_PADDING;\n",
       "            config.thumbnailWidth = (DIV_WIDTH - axisSize) / config.totalHeads;\n",
       "            config.detailHeight = Math.max(config.leftText.length, config.rightText.length) * DETAIL_BOX_HEIGHT + 2 * DETAIL_PADDING + DETAIL_HEADING_HEIGHT;\n",
       "            config.divHeight = Math.max(config.numLayers * config.thumbnailHeight + axisSize, config.detailHeight);\n",
       "\n",
       "            const vis = $(`#${config.rootDivId} #vis`)\n",
       "            vis.empty();\n",
       "            vis.attr(\"height\", config.divHeight);\n",
       "            config.svg = d3.select(`#${config.rootDivId} #vis`)\n",
       "                .append('svg')\n",
       "                .attr(\"width\", DIV_WIDTH)\n",
       "                .attr(\"height\", config.divHeight)\n",
       "                .attr(\"fill\", getBackgroundColor());\n",
       "\n",
       "            renderAxisLabels();\n",
       "\n",
       "            var i;\n",
       "            var j;\n",
       "            for (i = 0; i < config.numLayers; i++) {\n",
       "                for (j = 0; j < config.numHeads; j++) {\n",
       "                    renderThumbnail(i, j);\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "\n",
       "        function renderAxisLabels() {\n",
       "            const axisSize = HEADING_TEXT_SIZE + HEADING_PADDING + TEXT_SIZE + TEXT_PADDING;\n",
       "            const tableWidth = config.thumbnailWidth * config.heads.length;\n",
       "            config.svg.append(\"text\")\n",
       "                .text(\"Heads\")\n",
       "                .attr(\"fill\", \"black\")\n",
       "                .attr(\"font-weight\", \"bold\")\n",
       "                .attr(\"font-size\", HEADING_TEXT_SIZE + \"px\")\n",
       "                .attr(\"x\", axisSize + tableWidth / 2)\n",
       "                .attr(\"text-anchor\", \"middle\")\n",
       "                .attr(\"y\", 0)\n",
       "                .attr(\"dy\", HEADING_TEXT_SIZE);\n",
       "            for (let i = 0; i < config.numHeads; i++) {\n",
       "                config.svg.append(\"text\")\n",
       "                    .text(config.heads[i])\n",
       "                    .attr(\"fill\", \"black\")\n",
       "                    .attr(\"font-size\", TEXT_SIZE + \"px\")\n",
       "                    .attr(\"x\", axisSize + (i + .5) * config.thumbnailWidth)\n",
       "                    .attr(\"text-anchor\", \"middle\")\n",
       "                    .attr(\"y\", HEADING_TEXT_SIZE + HEADING_PADDING)\n",
       "                    .attr(\"dy\", TEXT_SIZE);\n",
       "            }\n",
       "            let x = 0;\n",
       "            let y = axisSize + config.thumbnailHeight * config.layers.length / 2;\n",
       "            console.log(\"x\", x, y)\n",
       "            config.svg.append(\"text\")\n",
       "                .text(\"Layers\")\n",
       "                .attr(\"fill\", \"black\")\n",
       "                .attr(\"font-weight\", \"bold\")\n",
       "                .attr(\"transform\", \"rotate(270, \" + x  + \", \" + y + \")\")\n",
       "                .attr(\"font-size\", HEADING_TEXT_SIZE + \"px\")\n",
       "                .attr(\"x\", x)\n",
       "                .attr(\"text-anchor\", \"middle\")\n",
       "                .attr(\"y\", y)\n",
       "                .attr(\"dy\", HEADING_TEXT_SIZE);\n",
       "            for (let i = 0; i < config.numLayers; i++) {\n",
       "                x = HEADING_TEXT_SIZE + HEADING_PADDING + TEXT_SIZE; // HACK\n",
       "                y = axisSize + (i + .5) * config.thumbnailHeight;\n",
       "                config.svg.append(\"text\")\n",
       "                    .text(config.layers[i])\n",
       "                    .attr(\"fill\", \"black\")\n",
       "                    .attr(\"font-size\", TEXT_SIZE + \"px\")\n",
       "                    .attr(\"x\", x)\n",
       "                    .attr(\"text-anchor\", \"end\")\n",
       "                    .attr(\"y\", y)\n",
       "                    .attr(\"dy\", TEXT_SIZE / 2);\n",
       "            }\n",
       "        }\n",
       "\n",
       "\n",
       "        function renderThumbnail(layerIndex, headIndex) {\n",
       "            const axisSize = HEADING_TEXT_SIZE + HEADING_PADDING + TEXT_SIZE + TEXT_PADDING\n",
       "            const x = headIndex * config.thumbnailWidth + axisSize;\n",
       "            const y = layerIndex * config.thumbnailHeight + axisSize;\n",
       "            renderThumbnailAttn(x, y, config.attn[layerIndex][headIndex], layerIndex, headIndex);\n",
       "        }\n",
       "\n",
       "        function renderDetail(att, layerIndex, headIndex) {\n",
       "            const axisSize = TEXT_SIZE + HEADING_PADDING + TEXT_SIZE + TEXT_PADDING;\n",
       "            var xOffset = .8 * config.thumbnailWidth;\n",
       "            var maxX = DIV_WIDTH;\n",
       "            var maxY = config.divHeight - 3;\n",
       "            var leftPos = axisSize + headIndex * config.thumbnailWidth;\n",
       "            var x = leftPos + THUMBNAIL_PADDING + xOffset;\n",
       "            if (x < MIN_X) {\n",
       "                x = MIN_X;\n",
       "            } else if (x + DETAIL_WIDTH > maxX) {\n",
       "                x = leftPos + THUMBNAIL_PADDING - DETAIL_WIDTH + 8;\n",
       "            }\n",
       "            var posLeftText = x;\n",
       "            var posAttention = posLeftText + DETAIL_BOX_WIDTH;\n",
       "            var posRightText = posAttention + DETAIL_ATTENTION_WIDTH;\n",
       "            var thumbnailHeight = Math.max(config.leftText.length, config.rightText.length) * config.thumbnailBoxHeight + 2 * THUMBNAIL_PADDING;\n",
       "            var yOffset = 20;\n",
       "            var y = layerIndex * thumbnailHeight + THUMBNAIL_PADDING + yOffset;\n",
       "            if (y < MIN_Y) {\n",
       "                y = MIN_Y;\n",
       "            } else if (y + config.detailHeight > maxY) {\n",
       "                y = maxY - config.detailHeight;\n",
       "            }\n",
       "            renderDetailFrame(x, y, layerIndex);\n",
       "            y = y + DETAIL_PADDING;\n",
       "            renderDetailHeading(x, y, layerIndex, headIndex);\n",
       "            y = y + DETAIL_HEADING_HEIGHT;\n",
       "            renderDetailText(config.leftText, \"leftText\", posLeftText, y , layerIndex);\n",
       "            renderDetailAttn(posAttention, y, att, layerIndex, headIndex);\n",
       "            renderDetailText(config.rightText, \"rightText\", posRightText, y, layerIndex);\n",
       "        }\n",
       "\n",
       "        function renderDetailHeading(x, y, layerIndex, headIndex) {\n",
       "            var fillColor = getTextColor();\n",
       "            config.svg.append(\"text\")\n",
       "                .classed(\"detail\", true)\n",
       "                .text('Layer ' + config.layers[layerIndex] + \", Head \" + config.heads[headIndex])\n",
       "                .attr(\"font-size\", TEXT_SIZE + \"px\")\n",
       "                .attr(\"font-weight\", \"bold\")\n",
       "                .style(\"cursor\", \"default\")\n",
       "                .style(\"-webkit-user-select\", \"none\")\n",
       "                .attr(\"fill\", fillColor)\n",
       "                .attr(\"x\", x + DETAIL_WIDTH / 2)\n",
       "                .attr(\"text-anchor\", \"middle\")\n",
       "                .attr(\"y\", y)\n",
       "                .attr(\"height\", DETAIL_HEADING_HEIGHT)\n",
       "                .attr(\"width\", DETAIL_WIDTH)\n",
       "                .attr(\"dy\", HEADING_TEXT_SIZE);\n",
       "        }\n",
       "\n",
       "        function renderDetailText(text, id, x, y, layerIndex) {\n",
       "            var tokenContainer = config.svg.append(\"svg:g\")\n",
       "                .classed(\"detail\", true)\n",
       "                .selectAll(\"g\")\n",
       "                .data(text)\n",
       "                .enter()\n",
       "                .append(\"g\");\n",
       "\n",
       "            var fillColor = getTextColor();\n",
       "\n",
       "            tokenContainer.append(\"rect\")\n",
       "                .classed(\"highlight\", true)\n",
       "                .attr(\"fill\", fillColor)\n",
       "                .style(\"opacity\", 0.0)\n",
       "                .attr(\"height\", DETAIL_BOX_HEIGHT)\n",
       "                .attr(\"width\", DETAIL_BOX_WIDTH)\n",
       "                .attr(\"x\", x)\n",
       "                .attr(\"y\", function (d, i) {\n",
       "                    return y + i * DETAIL_BOX_HEIGHT;\n",
       "                });\n",
       "\n",
       "            var textContainer = tokenContainer.append(\"text\")\n",
       "                .classed(\"token\", true)\n",
       "                .text(function (d) {\n",
       "                    return d;\n",
       "                })\n",
       "                .attr(\"font-size\", TEXT_SIZE + \"px\")\n",
       "                .style(\"cursor\", \"default\")\n",
       "                .style(\"-webkit-user-select\", \"none\")\n",
       "                .attr(\"fill\", fillColor)\n",
       "                .attr(\"x\", x)\n",
       "                .attr(\"y\", function (d, i) {\n",
       "                    return i * DETAIL_BOX_HEIGHT + y;\n",
       "                })\n",
       "                .attr(\"height\", DETAIL_BOX_HEIGHT)\n",
       "                .attr(\"width\", DETAIL_BOX_WIDTH)\n",
       "                .attr(\"dy\", TEXT_SIZE);\n",
       "\n",
       "            if (id == \"leftText\") {\n",
       "                textContainer.style(\"text-anchor\", \"end\")\n",
       "                    .attr(\"dx\", DETAIL_BOX_WIDTH - 2);\n",
       "                tokenContainer.on(\"mouseover\", function (d, index) {\n",
       "                    highlightSelection(index);\n",
       "                });\n",
       "                tokenContainer.on(\"mouseleave\", function () {\n",
       "                    unhighlightSelection();\n",
       "                });\n",
       "            }\n",
       "        }\n",
       "\n",
       "        function highlightSelection(index) {\n",
       "            config.svg.select(\"#leftText\")\n",
       "                .selectAll(\".highlight\")\n",
       "                .style(\"opacity\", function (d, i) {\n",
       "                    return i == index ? 1.0 : 0.0;\n",
       "                });\n",
       "            config.svg.selectAll(\".attn-line-group\")\n",
       "                .style(\"opacity\", function (d, i) {\n",
       "                    return i == index ? 1.0 : 0.0;\n",
       "                });\n",
       "        }\n",
       "\n",
       "        function unhighlightSelection() {\n",
       "            config.svg.select(\"#leftText\")\n",
       "                .selectAll(\".highlight\")\n",
       "                .style(\"opacity\", 0.0);\n",
       "            config.svg.selectAll(\".attn-line-group\")\n",
       "                .style(\"opacity\", 1);\n",
       "        }\n",
       "\n",
       "        function renderThumbnailAttn(x, y, att, layerIndex, headIndex) {\n",
       "\n",
       "            var attnContainer = config.svg.append(\"svg:g\");\n",
       "\n",
       "            var attnBackground = attnContainer.append(\"rect\")\n",
       "                .attr(\"id\", 'attn_background_' + layerIndex + \"_\" + headIndex)\n",
       "                .classed(\"attn_background\", true)\n",
       "                .attr(\"x\", x)\n",
       "                .attr(\"y\", y)\n",
       "                .attr(\"height\", config.thumbnailHeight)\n",
       "                .attr(\"width\", config.thumbnailWidth)\n",
       "                .attr(\"stroke-width\", 2)\n",
       "                .attr(\"stroke\", getLayerColor(layerIndex))\n",
       "                .attr(\"stroke-opacity\", 0)\n",
       "                .attr(\"fill\", getBackgroundColor());\n",
       "            var x1 = x + THUMBNAIL_PADDING;\n",
       "            var x2 = x1 + config.thumbnailWidth - 14;\n",
       "            var y1 = y + THUMBNAIL_PADDING;\n",
       "\n",
       "            attnContainer.selectAll(\"g\")\n",
       "                .data(att)\n",
       "                .enter()\n",
       "                .append(\"g\") // Add group for each source token\n",
       "                .attr(\"source-index\", function (d, i) { // Save index of source token\n",
       "                    return i;\n",
       "                })\n",
       "                .selectAll(\"line\")\n",
       "                .data(function (d) { // Loop over all target tokens\n",
       "                    return d;\n",
       "                })\n",
       "                .enter() // When entering\n",
       "                .append(\"line\")\n",
       "                .attr(\"x1\", x1)\n",
       "                .attr(\"y1\", function (d) {\n",
       "                    var sourceIndex = +this.parentNode.getAttribute(\"source-index\");\n",
       "                    return y1 + (sourceIndex + .5) * config.thumbnailBoxHeight;\n",
       "                })\n",
       "                .attr(\"x2\", x2)\n",
       "                .attr(\"y2\", function (d, targetIndex) {\n",
       "                    return y1 + (targetIndex + .5) * config.thumbnailBoxHeight;\n",
       "                })\n",
       "                .attr(\"stroke-width\", 2.2)\n",
       "                .attr(\"stroke\", getLayerColor(layerIndex))\n",
       "                .attr(\"stroke-opacity\", function (d) {\n",
       "                    return d;\n",
       "                });\n",
       "\n",
       "            var clickRegion = attnContainer.append(\"rect\")\n",
       "                .attr(\"x\", x)\n",
       "                .attr(\"y\", y)\n",
       "                .attr(\"height\", config.thumbnailHeight)\n",
       "                .attr(\"width\", config.thumbnailWidth)\n",
       "                .style(\"opacity\", 0);\n",
       "\n",
       "            clickRegion.on(\"click\", function (d, index) {\n",
       "                var attnBackgroundOther = config.svg.selectAll(\".attn_background\");\n",
       "                attnBackgroundOther.attr(\"fill\", getBackgroundColor());\n",
       "                attnBackgroundOther.attr(\"stroke-opacity\", 0);\n",
       "\n",
       "                config.svg.selectAll(\".detail\").remove();\n",
       "                if (config.detail_layer != layerIndex || config.detail_head != headIndex) {\n",
       "                    renderDetail(att, layerIndex, headIndex);\n",
       "                    config.detail_layer = layerIndex;\n",
       "                    config.detail_head = headIndex;\n",
       "                    attnBackground.attr(\"fill\", getHighlightColor());\n",
       "                    attnBackground.attr(\"stroke-opacity\", .8);\n",
       "                } else {\n",
       "                    config.detail_layer = null;\n",
       "                    config.detail_head = null;\n",
       "                    attnBackground.attr(\"fill\", getBackgroundColor());\n",
       "                    attnBackground.attr(\"stroke-opacity\", 0);\n",
       "                }\n",
       "            });\n",
       "\n",
       "            clickRegion.on(\"mouseover\", function (d) {\n",
       "                d3.select(this).style(\"cursor\", \"pointer\");\n",
       "            });\n",
       "        }\n",
       "\n",
       "        function renderDetailFrame(x, y, layerIndex) {\n",
       "            var detailFrame = config.svg.append(\"rect\")\n",
       "                .classed(\"detail\", true)\n",
       "                .attr(\"x\", x)\n",
       "                .attr(\"y\", y)\n",
       "                .attr(\"height\", config.detailHeight)\n",
       "                .attr(\"width\", DETAIL_WIDTH)\n",
       "                .style(\"opacity\", 1)\n",
       "                .attr(\"stroke-width\", 1.5)\n",
       "                .attr(\"stroke-opacity\", 0.7)\n",
       "                .attr(\"stroke\", getLayerColor(layerIndex));\n",
       "        }\n",
       "\n",
       "        function renderDetailAttn(x, y, att, layerIndex) {\n",
       "            var attnContainer = config.svg.append(\"svg:g\")\n",
       "                .classed(\"detail\", true)\n",
       "                .attr(\"pointer-events\", \"none\");\n",
       "            attnContainer.selectAll(\"g\")\n",
       "                .data(att)\n",
       "                .enter()\n",
       "                .append(\"g\") // Add group for each source token\n",
       "                .classed('attn-line-group', true)\n",
       "                .attr(\"source-index\", function (d, i) { // Save index of source token\n",
       "                    return i;\n",
       "                })\n",
       "                .selectAll(\"line\")\n",
       "                .data(function (d) { // Loop over all target tokens\n",
       "                    return d;\n",
       "                })\n",
       "                .enter()\n",
       "                .append(\"line\")\n",
       "                .attr(\"x1\", x + ATTN_PADDING)\n",
       "                .attr(\"y1\", function (d) {\n",
       "                    var sourceIndex = +this.parentNode.getAttribute(\"source-index\");\n",
       "                    return y + (sourceIndex + .5) * DETAIL_BOX_HEIGHT;\n",
       "                })\n",
       "                .attr(\"x2\", x + DETAIL_ATTENTION_WIDTH - ATTN_PADDING)\n",
       "                .attr(\"y2\", function (d, targetIndex) {\n",
       "                    return y + (targetIndex + .5) * DETAIL_BOX_HEIGHT;\n",
       "                })\n",
       "                .attr(\"stroke-width\", 2.2)\n",
       "                .attr(\"stroke\", getLayerColor(layerIndex))\n",
       "                .attr(\"stroke-opacity\", function (d) {\n",
       "                    return d;\n",
       "                });\n",
       "        }\n",
       "\n",
       "        function getLayerColor(layer) {\n",
       "          return LAYER_COLORS[config.layers[layer] % 10];\n",
       "        }\n",
       "\n",
       "        function getTextColor() {\n",
       "            return PALETTE[config.mode]['text']\n",
       "        }\n",
       "\n",
       "        function getBackgroundColor() {\n",
       "           return PALETTE[config.mode]['background']\n",
       "        }\n",
       "\n",
       "        function getHighlightColor() {\n",
       "           return PALETTE[config.mode]['highlight']\n",
       "        }\n",
       "\n",
       "        function initialize() {\n",
       "            config.attention = params['attention'];\n",
       "            config.filter = params['default_filter'];\n",
       "            config.mode = params['display_mode'];\n",
       "            config.layers = params['include_layers']\n",
       "            config.heads = params['include_heads']\n",
       "            config.totalHeads = params['total_heads']\n",
       "            config.rootDivId = params['root_div_id'];\n",
       "            $(`#${config.rootDivId} #filter`).on('change', function (e) {\n",
       "                config.filter = e.currentTarget.value;\n",
       "                render();\n",
       "            });\n",
       "        }\n",
       "\n",
       "        initialize();\n",
       "        render();\n",
       "\n",
       "    });"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, utils, AutoModelForCausalLM\n",
    "\n",
    "from bertviz import model_view\n",
    "utils.logging.set_verbosity_error()  # Suppress standard warnings\n",
    "\n",
    "model_name = 'openai-community/gpt2'\n",
    "input_text = \"No, I am your father\"  \n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, output_attentions=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "inputs = tokenizer.encode(input_text, return_tensors='pt')  # Tokenize input text\n",
    "outputs = model(inputs)  # Run model\n",
    "attention = outputs[-1]  # Retrieve attention from model outputs\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[0])  # Convert input ids to token strings\n",
    "model_view(attention, tokens)  # Display model view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFq78-kjbrWp"
   },
   "source": [
    "Last week, Carlo discussed token embedding, which is when words are encoded into a vocabulary. Now, we just discussed attention mechanisms which account for context between words. Another question we should ask is how do we account for the order of words in an input sentence\n",
    "\n",
    "Consider the following two sentences to see why this is important:\n",
    "\n",
    "``The man ate the sandwich.``\n",
    "\n",
    "``The sandwich ate the man.``\n",
    "\n",
    "Clearly, these are two vastly different situations even though they have the same words. The Transformer can \n",
    "\n",
    "Transformers differentiate between these situations by adding a **Positional encoding** vector to each input embedding. These vectors follow a specific pattern that the model learns, which helps it determine the position of each word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/positional_encoding.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "paegfAF27wCp"
   },
   "source": [
    "Image credit: https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up positional encoding similarly as token embedding using the ``nn.Embedding`` tool. We use a simple embedding here but there are more complex positional encodings used such as sinusoidal. \n",
    "\n",
    "For an explanation of different positional encodings, refer to this post: https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 65\n",
    "n_embd = 64\n",
    "\n",
    "token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "block_size = 32 # what is the maximum context length for predictions?\n",
    "position_embedding_table = nn.Embedding(block_size, n_embd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice the positional encoding size is `(block_size, n_embed)` because it encodes for the postion of a token within the sequence of size `block_size`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the position embedding used is simply added to the token embedding to apply positional embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at token embedding alone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-9.6630e-05, -1.4031e+00,  6.1625e-01,  3.0717e-02,  1.2290e-01,\n",
      "        -4.0682e-01,  1.9496e+00,  1.1764e+00, -1.5591e+00,  7.2791e-02,\n",
      "        -2.3081e+00, -5.0737e-01, -6.9863e-01, -1.3517e+00, -2.1065e-02,\n",
      "        -9.5309e-01, -1.0516e+00,  7.7541e-02,  4.4402e-01,  8.8709e-01,\n",
      "         1.8823e-01,  7.1672e-02, -3.4917e-01, -5.7223e-01,  3.5027e-01,\n",
      "         7.1300e-01, -4.1757e-01,  1.2332e+00, -1.0018e+00,  6.6873e-01,\n",
      "         9.4601e-03, -1.8759e+00,  3.9894e-01,  6.6391e-01,  6.4071e-02,\n",
      "         1.6804e+00,  6.2182e-01, -1.6898e+00, -3.4645e-01, -3.1754e+00,\n",
      "         9.4335e-01,  1.7508e+00, -7.7534e-01, -8.0301e-01,  2.6676e+00,\n",
      "         3.1534e-01, -5.9224e-01,  4.7193e-01,  6.4641e-01,  4.3199e-01,\n",
      "         1.4329e+00, -1.0546e+00,  1.6986e+00, -1.2204e+00, -1.2765e-02,\n",
      "        -1.3485e+00, -4.3946e-01, -1.3725e-01,  4.2354e-01, -4.0840e-01,\n",
      "        -7.1900e-01, -6.6362e-01, -8.9380e-02,  1.4980e-01],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,3,15,4,7,1,4,9])\n",
    "x = token_embedding_table(x)\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And token + positional embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.6103, -1.1454,  0.2832, -0.5627, -0.7867, -0.7475,  1.6190,  0.4168,\n",
      "        -2.4363,  0.1630, -2.2069,  0.1004,  0.3215, -0.9887, -0.2308,  0.1534,\n",
      "        -1.2566, -0.2798, -0.0496, -0.0997,  0.9740,  0.4581,  0.7802, -0.1746,\n",
      "         0.0531, -1.5154,  0.3336,  2.4084, -1.0335,  1.3728, -1.2628, -0.5919,\n",
      "         0.2460, -0.2431,  2.1009,  0.5958, -0.4106, -2.4724, -1.7571, -3.5932,\n",
      "         0.4605,  0.8671, -1.9192, -3.0066,  1.6024, -1.5752,  0.7494,  0.8431,\n",
      "         2.0244,  1.0557,  0.2076,  0.2220,  0.2793, -2.0823,  0.6992, -1.1937,\n",
      "        -0.3509,  0.8347,  1.0244,  0.5620, -0.3641, -1.3770, -0.1733, -1.4676],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,3,15,4,7,1,4,9])\n",
    "x= position_embedding_table(x) + token_embedding_table(x)\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see a clear offset between these two embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the training process, these embeddings will be learned to best encode the token and positional embeddings of the sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iF1HzH9xNJ7S"
   },
   "source": [
    "## Output layers\n",
    "\n",
    "At the end of our Transformer model, we are left with a vector, so how do we turn this into a word?\n",
    "\n",
    "<img src=\"images/transformer-decoder-intro.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "Using a final Linear layer and a Softmax Layer.\n",
    "The Linear layer projects the vector produced by the stack of decoders, into a larger vector called a logits vector.\n",
    "\n",
    "If our model knows 10,000 unique English words learned from its training dataset the logits vector is 10,000 cells wide ‚Äì each cell corresponds to the score of a unique word.\n",
    "\n",
    "The softmax layer turns those scores into probabilities. The cell with the highest probability is chosen, and the word associated with it is produced as the output for this time step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/transformer_decoder_output_softmax.png\" alt=\"Drawing\" style=\"width: 450px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HS6r-z8dN_RV"
   },
   "source": [
    "Image credit: https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XK8q67P03yr4"
   },
   "source": [
    "## Training\n",
    "\n",
    "How does an LLM improve over time?\n",
    "We want to compare the probabilitiy distribution for each token generated by our model to the ground truths. \n",
    "Our model produces a probability distribution for each token. We want to compare these probability distributions to the ground truths. \n",
    "For example, when translating the sentence: ‚Äúje suis √©tudiant‚Äù into ‚Äúi am a student‚Äù as can be seen in the example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/output_target_probability_distributions.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can calculate the loss between the vector it generates and the ground truth vector seen in this example. A commonly used loss function is cross entropy loss:\n",
    "\n",
    "$CE = -\\sum_{x \\in X} p(x) log q(x)$\n",
    "\n",
    "where p(x) represents the true distribution and q(x) represents the predicted distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9207)\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "logits = torch.tensor([0.5, 0.1, 0.3])\n",
    "targets = torch.tensor([0.5, 0.1, 0.3])\n",
    "loss = F.cross_entropy(logits, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important metric commonly used in LLMs is **perplexity**.\n",
    "\n",
    "Intuitively, perplexity means to be surprised. We measure how much the model is surprised by seeing new data. The lower the perplexity, the better the training is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, perplexity is just the exponent of the negative cross entropy loss:\n",
    "\n",
    "$\\text{perplexity} = exp(\\text{CE})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9207)\n",
      "tensor(2.5111)\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "logits = torch.tensor([0.5, 0.1, 0.3])\n",
    "targets = torch.tensor([0.5, 0.1, 0.3])\n",
    "loss = F.cross_entropy(logits, targets)\n",
    "print(loss)\n",
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we are using cross entropy loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's train a mini-LLM from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 32 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 10\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 64\n",
    "n_head = 4 ## so head_size = 16\n",
    "n_layer = 4\n",
    "dropout = 0.0\n",
    "# ------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in data and create train and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to be using the tiny Shakespeare dataset. \n",
    "Data is tokenized according to a simple character based tokenizer.\n",
    "Data is split into a train and test set so we have something to test after performing training (9:1 split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    #print(ix.shape)\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the components of the Decoder block: \n",
    "* MultiHeadAttention\n",
    "* FeedForward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C) 16,32,16\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        # mask the scores from words after each test word for training purpose\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T) \n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd), # Projection layer going back into the residual pathway\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine components into the Decoder block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))    # Communication\n",
    "        x = x + self.ffwd(self.ln2(x))  # Computation\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the full Transformer model \n",
    "This is a combination of the Token embeddings, Positional embeddings, a stack of Transformer blocks and an output block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# super simple bigram model\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "1. In this notebook, we learned the various components of an LLM. \n",
    "    Your homework this week is to take the mini LLM we created from scratch and run your own training loop. Show how the training and validation perplexity change over the steps.\n",
    "      \n",
    "    Hint: this function might be useful for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "n_embd = 64\n",
    "n_head = 4 ## so head_size = 16\n",
    "n_layer = 4\n",
    "\n",
    "\n",
    "epochs = 30\n",
    "model = BigramLanguageModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 0:\n",
      "Train Epoch 1:\n",
      "Train Epoch 2:\n",
      "Train Epoch 3:\n",
      "Train Epoch 4:\n",
      "Train Epoch 5:\n",
      "Train Epoch 6:\n",
      "Train Epoch 7:\n",
      "Train Epoch 8:\n",
      "Train Epoch 9:\n",
      "Train Epoch 10:\n",
      "Train Epoch 11:\n",
      "Train Epoch 12:\n",
      "Train Epoch 13:\n",
      "Train Epoch 14:\n",
      "Train Epoch 15:\n",
      "Train Epoch 16:\n",
      "Train Epoch 17:\n",
      "Train Epoch 18:\n",
      "Train Epoch 19:\n",
      "Train Epoch 20:\n",
      "Train Epoch 21:\n",
      "Train Epoch 22:\n",
      "Train Epoch 23:\n",
      "Train Epoch 24:\n",
      "Train Epoch 25:\n",
      "Train Epoch 26:\n",
      "Train Epoch 27:\n",
      "Train Epoch 28:\n",
      "Train Epoch 29:\n"
     ]
    }
   ],
   "source": [
    "perplexity=[]\n",
    "for j in range(epochs):\n",
    "    print(f\"Train Epoch {j}:\")\n",
    "    loss_vals=estimate_loss()\n",
    "    perplexity.append([torch.exp(i) for i in loss_vals.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), [i[0] for i in perplexity], marker='o')\n",
    "plt.ylabel('Perplexity values')\n",
    "plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Run the same training loop but modify one of the hyperparameters from this list: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 0:\n",
      "Train Epoch 1:\n",
      "Train Epoch 2:\n",
      "Train Epoch 3:\n",
      "Train Epoch 4:\n",
      "Train Epoch 5:\n",
      "Train Epoch 6:\n",
      "Train Epoch 7:\n",
      "Train Epoch 8:\n",
      "Train Epoch 9:\n",
      "Train Epoch 10:\n",
      "Train Epoch 11:\n",
      "Train Epoch 12:\n",
      "Train Epoch 13:\n",
      "Train Epoch 14:\n",
      "Train Epoch 15:\n",
      "Train Epoch 16:\n",
      "Train Epoch 17:\n",
      "Train Epoch 18:\n",
      "Train Epoch 19:\n",
      "Train Epoch 20:\n",
      "Train Epoch 21:\n",
      "Train Epoch 22:\n",
      "Train Epoch 23:\n",
      "Train Epoch 24:\n",
      "Train Epoch 25:\n",
      "Train Epoch 26:\n",
      "Train Epoch 27:\n",
      "Train Epoch 28:\n",
      "Train Epoch 29:\n"
     ]
    }
   ],
   "source": [
    "perplexity=[]\n",
    "n_layer = 8\n",
    "model=BigramLanguageModel()    \n",
    "for j in range(epochs):\n",
    "    print(f\"Train Epoch {j}:\")\n",
    "    loss_vals=estimate_loss()\n",
    "    perplexity.append([torch.exp(i) for i in loss_vals.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), [i[0] for i in perplexity], marker='o')\n",
    "plt.ylabel('Perplexity values')\n",
    "plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this at least 4 times with a different value and plot each perplexity over training step. Write a sentence on how the perplexity changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus 1: output some generated text from each model you trained. Did the output make more sense with some hyperparameters than others? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus 2: We saw a cool visualization of attention mechanisms with BertViz. Take a more complicated model than GPT2 such as \"meta-llama/Llama-2-7b-chat-hf\" and see how the attention mechanisms are different "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "nDXLTusqxXHf"
   },
   "outputs": [],
   "source": [
    "n_layer = 8\n",
    "model=BigramLanguageModel()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BigramLanguageModel(\n",
       "  (token_embedding_table): Embedding(65, 64)\n",
       "  (position_embedding_table): Embedding(32, 64)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (3): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedFoward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (3): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedFoward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (3): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedFoward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (3): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedFoward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (4): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (3): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedFoward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (3): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedFoward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (6): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (3): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedFoward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (7): Block(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (3): Head(\n",
       "            (key): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (query): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=16, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedFoward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (3): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (lm_head): Linear(in_features=64, out_features=65, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "datascience/conda-2023-01-10",
   "language": "python",
   "name": "conda-2023-01-10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
